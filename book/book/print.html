<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Firecracker</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="index.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="CHARTER.html"><strong aria-hidden="true">2.</strong> Firecracker Charter</a></li><li class="chapter-item expanded "><a href="CODE_OF_CONDUCT.html"><strong aria-hidden="true">3.</strong> Code of Conduct</a></li><li class="chapter-item expanded "><a href="SECURITY.html"><strong aria-hidden="true">4.</strong> Security</a></li><li class="chapter-item expanded "><a href="getting-started.html"><strong aria-hidden="true">5.</strong> Getting Started</a></li><li class="chapter-item expanded "><a href="CONTRIBUTING.html"><strong aria-hidden="true">6.</strong> Contributing</a></li><li class="chapter-item expanded "><a href="dev-machine-setup.html"><strong aria-hidden="true">7.</strong> Development Machine Setup</a></li><li class="chapter-item expanded "><a href="api-change-runbook.html"><strong aria-hidden="true">8.</strong> API Change Runbook</a></li><li class="chapter-item expanded "><a href="RELEASE_POLICY.html"><strong aria-hidden="true">9.</strong> Releases</a></li><li class="chapter-item expanded "><a href="design.html"><strong aria-hidden="true">10.</strong> Design</a></li><li class="chapter-item expanded "><a href="prod-host-setup.html"><strong aria-hidden="true">11.</strong> Production Host Setup</a></li><li class="chapter-item expanded "><a href="network-setup.html"><strong aria-hidden="true">12.</strong> Network Setup</a></li><li class="chapter-item expanded "><a href="kernel-policy.html"><strong aria-hidden="true">13.</strong> Kernel Support Policy</a></li><li class="chapter-item expanded "><a href="SPECIFICATION.html"><strong aria-hidden="true">14.</strong> Specification</a></li><li class="chapter-item expanded "><a href="network-performance.html"><strong aria-hidden="true">15.</strong> Network Performance</a></li><li class="chapter-item expanded "><a href="FAQ.html"><strong aria-hidden="true">16.</strong> FAQ</a></li><li class="chapter-item expanded "><a href="rootfs-and-kernel-setup.html"><strong aria-hidden="true">17.</strong> Creating Custom rootfs and kernel Images</a></li><li class="chapter-item expanded "><a href="ballooning.html"><strong aria-hidden="true">18.</strong> Ballooning</a></li><li class="chapter-item expanded "><a href="devctr-image.html"><strong aria-hidden="true">19.</strong> Development Container</a></li><li class="chapter-item expanded "><a href="device-api.html"><strong aria-hidden="true">20.</strong> Device API</a></li><li class="chapter-item expanded "><a href="entropy.html"><strong aria-hidden="true">21.</strong> Entropy</a></li><li class="chapter-item expanded "><a href="formal-verification.html"><strong aria-hidden="true">22.</strong> Formal Verification</a></li><li class="chapter-item expanded "><a href="initrd.html"><strong aria-hidden="true">23.</strong> initrd</a></li><li class="chapter-item expanded "><a href="jailer.html"><strong aria-hidden="true">24.</strong> Jailer</a></li><li class="chapter-item expanded "><a href="logger.html"><strong aria-hidden="true">25.</strong> Logger</a></li><li class="chapter-item expanded "><a href="metrics.html"><strong aria-hidden="true">26.</strong> Metrics</a></li><li class="chapter-item expanded "><a href="seccomp.html"><strong aria-hidden="true">27.</strong> Seccomp</a></li><li class="chapter-item expanded "><a href="seccompiler.html"><strong aria-hidden="true">28.</strong> Seccompiler</a></li><li class="chapter-item expanded "><a href="tracing.html"><strong aria-hidden="true">29.</strong> Tracing</a></li><li class="chapter-item expanded "><a href="vsock.html"><strong aria-hidden="true">30.</strong> VSock</a></li><li class="chapter-item expanded "><a href="api-requests.html"><strong aria-hidden="true">31.</strong> API Requests</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="actions.html"><strong aria-hidden="true">31.1.</strong> Actons</a></li><li class="chapter-item expanded "><a href="block-caching.html"><strong aria-hidden="true">31.2.</strong> Block Caching</a></li><li class="chapter-item expanded "><a href="block-io-engine.html"><strong aria-hidden="true">31.3.</strong> Block IO Engine</a></li><li class="chapter-item expanded "><a href="block-vhost-user.html"><strong aria-hidden="true">31.4.</strong> Block VHost User</a></li><li class="chapter-item expanded "><a href="patch-block.html"><strong aria-hidden="true">31.5.</strong> Patch Block</a></li><li class="chapter-item expanded "><a href="patch-network-interface.html"><strong aria-hidden="true">31.6.</strong> Patch Network Interface</a></li></ol></li><li class="chapter-item expanded "><a href="state-serialize.html"><strong aria-hidden="true">32.</strong> State Serialization Benchmarks</a></li><li class="chapter-item expanded "><a href="cpu-templates.html"><strong aria-hidden="true">33.</strong> CPU Templates</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="boot-protocol.html"><strong aria-hidden="true">33.1.</strong> Boot Protocol</a></li><li class="chapter-item expanded "><a href="cpu-template-helper.html"><strong aria-hidden="true">33.2.</strong> CPU Template Helper</a></li><li class="chapter-item expanded "><a href="cpuid-normalization.html"><strong aria-hidden="true">33.3.</strong> CPUID Normalization</a></li></ol></li><li class="chapter-item expanded "><a href="mmds.html"><strong aria-hidden="true">34.</strong> MMDS</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="mmds-design.html"><strong aria-hidden="true">34.1.</strong> MMDS Design</a></li><li class="chapter-item expanded "><a href="mmds-user-guide.html"><strong aria-hidden="true">34.2.</strong> MMDS User Guide</a></li></ol></li><li class="chapter-item expanded "><a href="snapshotting.html"><strong aria-hidden="true">35.</strong> Snapshotting</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="handling-page-faults-on-snapshot-resume.html"><strong aria-hidden="true">35.1.</strong> Handling Page Faults on Snapshot Resume</a></li><li class="chapter-item expanded "><a href="network-for-clones.html"><strong aria-hidden="true">35.2.</strong> Network For Clones</a></li><li class="chapter-item expanded "><a href="random-for-clones.html"><strong aria-hidden="true">35.3.</strong> Random For Clones</a></li><li class="chapter-item expanded "><a href="snapshot-editor.html"><strong aria-hidden="true">35.4.</strong> Snapshot Editor</a></li><li class="chapter-item expanded "><a href="snapshot-support.html"><strong aria-hidden="true">35.5.</strong> Snapshot Support</a></li><li class="chapter-item expanded "><a href="versioning.html"><strong aria-hidden="true">35.6.</strong> Versioning</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Firecracker</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <picture>
   <source media="(prefers-color-scheme: dark)" srcset="./images/fc_logo_full_transparent-bg_white-fg.png">
   <source media="(prefers-color-scheme: light)" srcset="./images/fc_logo_full_transparent-bg.png">
   <img alt="Firecracker Logo Title" width="750" src="./images/fc_logo_full_transparent-bg.png">
</picture>
<p>Our mission is to enable secure, multi-tenant, minimal-overhead execution of
container and function workloads.</p>
<p>Read more about the Firecracker Charter <a href="CHARTER.html">here</a>.</p>
<h2 id="what-is-firecracker"><a class="header" href="#what-is-firecracker">What is Firecracker?</a></h2>
<p>Firecracker is an open source virtualization technology that is purpose-built
for creating and managing secure, multi-tenant container and function-based
services that provide serverless operational models. Firecracker runs workloads
in lightweight virtual machines, called microVMs, which combine the security and
isolation properties provided by hardware virtualization technology with the
speed and flexibility of containers.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>The main component of Firecracker is a virtual machine monitor (VMM) that uses
the Linux Kernel Virtual Machine (KVM) to create and run microVMs. Firecracker
has a minimalist design. It excludes unnecessary devices and guest-facing
functionality to reduce the memory footprint and attack surface area of each
microVM. This improves security, decreases the startup time, and increases
hardware utilization. Firecracker has also been integrated in container runtimes,
for example
<a href="https://github.com/kata-containers/documentation/wiki/Initial-release-of-Kata-Containers-with-Firecracker-support">Kata Containers</a>
and <a href="https://github.com/weaveworks/ignite">Weaveworks Ignite</a>.</p>
<p>Firecracker was developed at Amazon Web Services to accelerate the speed and
efficiency of services like <a href="https://aws.amazon.com/lambda/">AWS Lambda</a> and
<a href="https://aws.amazon.com/fargate/">AWS Fargate</a>. Firecracker is open
sourced under <a href="LICENSE">Apache version 2.0</a>.</p>
<p>To read more about Firecracker, check out
<a href="https://firecracker-microvm.github.io">firecracker-microvm.io</a>.</p>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<p>To get started with Firecracker, download the latest
<a href="https://github.com/firecracker-microvm/firecracker/releases">release</a> binaries
or build it from source.</p>
<p>You can build Firecracker on any Unix/Linux system that has Docker running
(we use a development container) and <code>bash</code> installed, as follows:</p>
<pre><code class="language-bash">git clone https://github.com/firecracker-microvm/firecracker
cd firecracker
tools/devtool build
toolchain=&quot;$(uname -m)-unknown-linux-musl&quot;
</code></pre>
<p>The Firecracker binary will be placed at
<code>build/cargo_target/${toolchain}/debug/firecracker</code>. For more information on
building, testing, and running Firecracker, go to the
<a href="./getting-started.html">quickstart guide</a>.</p>
<p>The overall security of Firecracker microVMs, including the ability to meet the
criteria for safe multi-tenant computing, depends on a well configured Linux
host operating system. A configuration that we believe meets this bar is
included in <a href="./prod-host-setup.html">the production host setup document</a>.</p>
<h2 id="contributing"><a class="header" href="#contributing">Contributing</a></h2>
<p>Firecracker is already running production workloads within AWS, but it's still
Day 1 on the journey guided by our <a href="CHARTER.html">mission</a>. There's a lot more to
build and we welcome all contributions.</p>
<p>To contribute to Firecracker, check out the development setup section in the
<a href="./getting-started.html">getting started guide</a> and then the Firecracker
<a href="CONTRIBUTING.html">contribution guidelines</a>.</p>
<h2 id="releases"><a class="header" href="#releases">Releases</a></h2>
<p>New Firecracker versions are released via the GitHub repository
<a href="https://github.com/firecracker-microvm/firecracker/releases">releases</a> page,
typically every two or three months. A history of changes is recorded in our
<a href="CHANGELOG.html">changelog</a>.</p>
<p>The Firecracker release policy is detailed <a href="./RELEASE_POLICY.html">here</a>.</p>
<h2 id="design"><a class="header" href="#design">Design</a></h2>
<p>Firecracker's overall architecture is described in
<a href="./design.html">the design document</a>.</p>
<h2 id="features--capabilities"><a class="header" href="#features--capabilities">Features &amp; Capabilities</a></h2>
<p>Firecracker consists of a single micro Virtual Machine Manager process that
exposes an API endpoint to the host once started. The API is
<a href="src/api_server/swagger/firecracker.yaml">specified in OpenAPI format</a>. Read more
about it in the <a href="./api_requests">API docs</a>.</p>
<p>The <strong>API endpoint</strong> can be used to:</p>
<ul>
<li>Configure the microvm by:
<ul>
<li>Setting the number of vCPUs (the default is 1).</li>
<li>Setting the memory size (the default is 128 MiB).</li>
<li>Configuring a <a href="./cpu_templates/cpu-templates.html">CPU template</a>.</li>
</ul>
</li>
<li>Add one or more network interfaces to the microVM.</li>
<li>Add one or more read-write or read-only disks to the microVM, each represented
by a file-backed block device.</li>
<li>Trigger a block device re-scan while the guest is running. This enables the
guest OS to pick up size changes to the block device's backing file.</li>
<li>Change the backing file for a block device, before or after the guest boots.</li>
<li>Configure rate limiters for virtio devices which can limit the bandwidth,
operations per second, or both.</li>
<li>Configure the logging and metric system.</li>
<li><code>[BETA]</code> Configure the data tree of the guest-facing metadata service. The
service is only available to the guest if this resource is configured.</li>
<li>Add a <a href="./vsock.html">vsock socket</a> to the microVM.</li>
<li>Add a <a href="./entropy.html">entropy device</a> to the microVM.</li>
<li>Start the microVM using a given kernel image, root file system, and boot
arguments.</li>
<li>[x86_64 only] Stop the microVM.</li>
</ul>
<p><strong>Built-in Capabilities</strong>:</p>
<ul>
<li>Demand fault paging and CPU oversubscription enabled by default.</li>
<li>Advanced, thread-specific seccomp filters for enhanced security.</li>
<li><a href="./jailer.html">Jailer</a> process for starting Firecracker in production
scenarios; applies a cgroup/namespace isolation barrier and then
drops privileges.</li>
</ul>
<h2 id="tested-platforms"><a class="header" href="#tested-platforms">Tested platforms</a></h2>
<p>We test all combinations of:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left">Instance</th><th style="text-align: left">Host OS &amp; Kernel</th><th style="text-align: left">Guest Rootfs</th><th style="text-align: left">Guest Kernel</th></tr></thead><tbody>
<tr><td style="text-align: left">m5d.metal</td><td style="text-align: left">al2    linux_4.1</td><td style="text-align: left">ubuntu 22.04</td><td style="text-align: left">linux_4.14</td></tr>
<tr><td style="text-align: left">m6i.metal</td><td style="text-align: left">al2    linux_5.10</td><td style="text-align: left"></td><td style="text-align: left">linux_5.10</td></tr>
<tr><td style="text-align: left">m6a.metal</td><td style="text-align: left">al2023 linux_6.1</td><td style="text-align: left"></td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">m6g.metal</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">c7g.metal</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"></td></tr>
</tbody></table>
</div>
<h2 id="known-issues-and-limitations"><a class="header" href="#known-issues-and-limitations">Known issues and Limitations</a></h2>
<ul>
<li>The <code>pl031</code> RTC device on aarch64 does not support interrupts, so guest
programs which use an RTC alarm (e.g. <code>hwclock</code>) will not work.</li>
</ul>
<h2 id="performance"><a class="header" href="#performance">Performance</a></h2>
<p>Firecracker's performance characteristics are listed as part of the
<a href="SPECIFICATION.html">specification documentation</a>. All specifications are a part
of our commitment to supporting container and function workloads in serverless
operational models, and are therefore enforced via continuous integration
testing.</p>
<h2 id="policy-for-security-disclosures"><a class="header" href="#policy-for-security-disclosures">Policy for Security Disclosures</a></h2>
<p>The security of Firecracker is our top priority. If you suspect you have
uncovered a vulnerability, contact us privately, as outlined in our
<a href="SECURITY.html">security policy document</a>; we will immediately prioritize
your disclosure.</p>
<h2 id="faq--contact"><a class="header" href="#faq--contact">FAQ &amp; Contact</a></h2>
<p>Frequently asked questions are collected in our <a href="FAQ.html">FAQ doc</a>.</p>
<p>You can get in touch with the Firecracker community in the following ways:</p>
<ul>
<li>Security-related issues, see our <a href="SECURITY.html">security policy document</a>.</li>
<li>Chat with us on our
<a href="https://join.slack.com/t/firecracker-microvm/shared_invite/zt-1zlb87h4z-NED1rBhVqOQ1ygBgT76wlg">Slack workspace</a>
<em>Note: most of the maintainers are on a European time zone.</em></li>
<li>Open a GitHub issue in this repository.</li>
<li>Email the maintainers at
<a href="mailto:firecracker-maintainers@amazon.com">firecracker-maintainers@amazon.com</a>.</li>
</ul>
<p>When communicating within the Firecracker community, please mind our
<a href="CODE_OF_CONDUCT.html">code of conduct</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firecracker-charter"><a class="header" href="#firecracker-charter">Firecracker Charter</a></h1>
<h2 id="mission"><a class="header" href="#mission">Mission</a></h2>
<p>Our mission is to enable secure, multi-tenant, minimal-overhead
execution of container and function workloads.</p>
<h2 id="tenets-unless-you-know-better-ones"><a class="header" href="#tenets-unless-you-know-better-ones">Tenets (unless you know better ones)</a></h2>
<p>These tenets guide Firecracker's development:</p>
<ol>
<li><strong>Built-In Security</strong>: We provide compute security barriers that
enable multi-tenant workloads, and cannot be mistakenly disabled by
customers. Customer workloads are simultaneously considered sacred
(shall not be touched) and malicious (shall be defended against).
We continuously invest in defense in depth and maintain mechanisms
that ensure security best practices.</li>
<li><strong>Light-Weight Virtualization</strong>: We prioritize measuring
Firecracker's hardware overhead in the dimensions that are important
for our customers, and we strive to make this overhead negligible.</li>
<li><strong>Minimalist in Features</strong>: If it's not clearly required for our
mission, we won't build it. We maintain a single implementation per
capability, and deprecate obsolete implementations; resolving
exceptions is a high priority issue.</li>
<li><strong>Compute Oversubscription</strong>: All of the hardware compute resources
exposed by Firecracker to guests can be securely oversubscribed.</li>
</ol>
<h2 id="contributions--project-roles"><a class="header" href="#contributions--project-roles">Contributions &amp; Project Roles</a></h2>
<p>All contributions must align with this charter and follow Firecracker's
<a href="CONTRIBUTING.html">contribution process</a>.</p>
<p>Firecracker <a href="MAINTAINERS.html">maintainers</a> merge contributions into the
main branch and create Firecracker releases. Maintainers are also
subject to the mission and tenets outlined above. Anyone may submit
and review contributions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="code-of-conduct"><a class="header" href="#code-of-conduct">Code of Conduct</a></h1>
<p>This project has adopted the
<a href="https://aws.github.io/code-of-conduct">Amazon Open Source Code of Conduct</a>.
For more information see the
<a href="https://aws.github.io/code-of-conduct-faq">Code of Conduct FAQ</a> or contact
<a href="mailto:opensource-codeofconduct@amazon.com">opensource-codeofconduct@amazon.com</a>
with any additional questions or comments.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="reporting-security-issues"><a class="header" href="#reporting-security-issues">Reporting Security Issues</a></h2>
<p>We take all security reports seriously.
When we receive such reports,
we will investigate and subsequently address
any potential vulnerabilities as quickly as possible.
If you discover a potential security issue in this project,
please notify AWS/Amazon Security via our
<a href="http://aws.amazon.com/security/vulnerability-reporting/">vulnerability reporting page</a>
or directly via email to <a href="mailto:aws-security@amazon.com">AWS Security</a>.
Please do <em>not</em> create a public GitHub issue in this project.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-with-firecracker"><a class="header" href="#getting-started-with-firecracker">Getting Started with Firecracker</a></h1>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<p>You can check if your system meets the requirements by running
<code>firecracker/tools/devtool checkenv</code>.</p>
<p>An opinionated way to run Firecracker is to launch an
<a href="https://aws.amazon.com/ec2/">EC2</a> <code>c5.metal</code> instance with Ubuntu 22.04.</p>
<p>EC2 only supports nested virtualization on metal instances, which is why we use
<code>.metal</code> instances exclusively.</p>
<h3 id="architecture--os"><a class="header" href="#architecture--os">Architecture &amp; OS</a></h3>
<p>Firecracker supports <strong>x86_64</strong> and <strong>aarch64</strong> Linux, see
<a href="kernel-policy.html">specific supported kernels</a>.</p>
<h3 id="kvm"><a class="header" href="#kvm">KVM</a></h3>
<p>Firecracker requires <a href="https://www.linux-kvm.org/">the KVM Linux kernel module</a>.</p>
<p>The presence of the KVM module can be checked with:</p>
<pre><code class="language-bash">lsmod | grep kvm
</code></pre>
<p>An example output where it is enabled:</p>
<pre><code class="language-bash">kvm_intel             348160  0
kvm                   970752  1 kvm_intel
irqbypass              16384  1 kvm
</code></pre>
<p>Some Linux distributions use the <code>kvm</code> group to manage access to <code>/dev/kvm</code>,
while others rely on access control lists. If you have the ACL package for your
distro installed, you can grant Read+Write access with:</p>
<pre><code class="language-bash">sudo setfacl -m u:${USER}:rw /dev/kvm
</code></pre>
<p>Otherwise, if access is managed via the <code>kvm</code> group:</p>
<pre><code class="language-bash">[ $(stat -c &quot;%G&quot; /dev/kvm) = kvm ] &amp;&amp; sudo usermod -aG kvm ${USER} \
&amp;&amp; echo &quot;Access granted.&quot;
</code></pre>
<p>If none of the above works, you will need to either install the file
system ACL package for your distro and use the <code>setfacl</code> command as above,
or run Firecracker as <code>root</code> (via <code>sudo</code>).</p>
<p>You can check if you have access to <code>/dev/kvm</code> with:</p>
<pre><code class="language-bash">[ -r /dev/kvm ] &amp;&amp; [ -w /dev/kvm ] &amp;&amp; echo &quot;OK&quot; || echo &quot;FAIL&quot;
</code></pre>
<h2 id="running-firecracker"><a class="header" href="#running-firecracker">Running Firecracker</a></h2>
<p>In production, Firecracker is designed to be run inside
an execution jail, set up by the <a href="../src/jailer/"><code>jailer</code></a> binary. This is how
our <a href="getting-started.html#running-the-integration-test-suite">integration test suite</a> does it. This
guide will not use the <a href="../src/jailer/"><code>jailer</code></a>.</p>
<h3 id="getting-a-rootfs-and-guest-kernel-image"><a class="header" href="#getting-a-rootfs-and-guest-kernel-image">Getting a rootfs and Guest Kernel Image</a></h3>
<p>To successfully start a microVM with you will need an uncompressed Linux kernel binary,
and an ext4 file system image (to use as rootfs). This guide uses a 5.10 kernel image
with a Ubuntu 22.04 rootfs from our CI:</p>
<pre><code class="language-bash">ARCH=&quot;$(uname -m)&quot;

# Download a linux kernel binary
wget https://s3.amazonaws.com/spec.ccfc.min/firecracker-ci/v1.7/${ARCH}/vmlinux-5.10.204

# Download a rootfs
wget https://s3.amazonaws.com/spec.ccfc.min/firecracker-ci/v1.7/${ARCH}/ubuntu-22.04.ext4

# Download the ssh key for the rootfs
wget https://s3.amazonaws.com/spec.ccfc.min/firecracker-ci/v1.7/${ARCH}/ubuntu-22.04.id_rsa

# Set user read permission on the ssh key
chmod 400 ./ubuntu-22.04.id_rsa
</code></pre>
<h3 id="getting-a-firecracker-binary"><a class="header" href="#getting-a-firecracker-binary">Getting a Firecracker Binary</a></h3>
<p>There are two options for getting a firecracker binary:</p>
<ul>
<li>Downloading an official firecracker release from our
<a href="https://github.com/firecracker-microvm/firecracker/releases">release page</a>, or</li>
<li>Building firecracker from source.</li>
</ul>
<p>To download the latest firecracker release, run</p>
<pre><code class="language-bash">ARCH=&quot;$(uname -m)&quot;
release_url=&quot;https://github.com/firecracker-microvm/firecracker/releases&quot;
latest=$(basename $(curl -fsSLI -o /dev/null -w  %{url_effective} ${release_url}/latest))
curl -L ${release_url}/download/${latest}/firecracker-${latest}-${ARCH}.tgz \
| tar -xz

# Rename the binary to &quot;firecracker&quot;
mv release-${latest}-$(uname -m)/firecracker-${latest}-${ARCH} firecracker
</code></pre>
<p>To instead build firecracker from source, you will need to have <code>docker</code> installed:</p>
<pre><code class="language-bash">ARCH=&quot;$(uname -m)&quot;

# Clone the firecracker repository
git clone https://github.com/firecracker-microvm/firecracker firecracker_src

# Start docker
sudo systemctl start docker

# Build firecracker
#
# It is possible to build for gnu, by passing the arguments '-l gnu'.
#
# This will produce the firecracker and jailer binaries under
# `./firecracker/build/cargo_target/${toolchain}/debug`.
#
sudo ./firecracker_src/tools/devtool build

# Rename the binary to &quot;firecracker&quot;
sudo cp ./firecracker_src/build/cargo_target/${ARCH}-unknown-linux-musl/debug/firecracker firecracker
</code></pre>
<h3 id="starting-firecracker"><a class="header" href="#starting-firecracker">Starting Firecracker</a></h3>
<p>Running firecracker will require two terminals, the first one running the
firecracker binary, and a second one for communicating with the firecracker
process via HTTP requests:</p>
<pre><code class="language-bash">API_SOCKET=&quot;/tmp/firecracker.socket&quot;

# Remove API unix socket
sudo rm -f $API_SOCKET

# Run firecracker
sudo ./firecracker --api-sock &quot;${API_SOCKET}&quot;
</code></pre>
<p>In a new terminal (do not close the 1st one):</p>
<pre><code class="language-bash">TAP_DEV=&quot;tap0&quot;
TAP_IP=&quot;172.16.0.1&quot;
MASK_SHORT=&quot;/30&quot;

# Setup network interface
sudo ip link del &quot;$TAP_DEV&quot; 2&gt; /dev/null || true
sudo ip tuntap add dev &quot;$TAP_DEV&quot; mode tap
sudo ip addr add &quot;${TAP_IP}${MASK_SHORT}&quot; dev &quot;$TAP_DEV&quot;
sudo ip link set dev &quot;$TAP_DEV&quot; up

# Enable ip forwarding
sudo sh -c &quot;echo 1 &gt; /proc/sys/net/ipv4/ip_forward&quot;

HOST_IFACE=&quot;eth0&quot;

# Set up microVM internet access
sudo iptables -t nat -D POSTROUTING -o &quot;$HOST_IFACE&quot; -j MASQUERADE || true
sudo iptables -D FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT \
    || true
sudo iptables -D FORWARD -i tap0 -o &quot;$HOST_IFACE&quot; -j ACCEPT || true
sudo iptables -t nat -A POSTROUTING -o &quot;$HOST_IFACE&quot; -j MASQUERADE
sudo iptables -I FORWARD 1 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
sudo iptables -I FORWARD 1 -i tap0 -o &quot;$HOST_IFACE&quot; -j ACCEPT

API_SOCKET=&quot;/tmp/firecracker.socket&quot;
LOGFILE=&quot;./firecracker.log&quot;

# Create log file
touch $LOGFILE

# Set log file
curl -X PUT --unix-socket &quot;${API_SOCKET}&quot; \
    --data &quot;{
        \&quot;log_path\&quot;: \&quot;${LOGFILE}\&quot;,
        \&quot;level\&quot;: \&quot;Debug\&quot;,
        \&quot;show_level\&quot;: true,
        \&quot;show_log_origin\&quot;: true
    }&quot; \
    &quot;http://localhost/logger&quot;

KERNEL=&quot;./vmlinux-5.10.204&quot;
KERNEL_BOOT_ARGS=&quot;console=ttyS0 reboot=k panic=1 pci=off&quot;

ARCH=$(uname -m)

if [ ${ARCH} = &quot;aarch64&quot; ]; then
    KERNEL_BOOT_ARGS=&quot;keep_bootcon ${KERNEL_BOOT_ARGS}&quot;
fi

# Set boot source
curl -X PUT --unix-socket &quot;${API_SOCKET}&quot; \
    --data &quot;{
        \&quot;kernel_image_path\&quot;: \&quot;${KERNEL}\&quot;,
        \&quot;boot_args\&quot;: \&quot;${KERNEL_BOOT_ARGS}\&quot;
    }&quot; \
    &quot;http://localhost/boot-source&quot;

ROOTFS=&quot;./ubuntu-22.04.ext4&quot;

# Set rootfs
curl -X PUT --unix-socket &quot;${API_SOCKET}&quot; \
    --data &quot;{
        \&quot;drive_id\&quot;: \&quot;rootfs\&quot;,
        \&quot;path_on_host\&quot;: \&quot;${ROOTFS}\&quot;,
        \&quot;is_root_device\&quot;: true,
        \&quot;is_read_only\&quot;: false
    }&quot; \
    &quot;http://localhost/drives/rootfs&quot;

# The IP address of a guest is derived from its MAC address with
# `fcnet-setup.sh`, this has been pre-configured in the guest rootfs. It is
# important that `TAP_IP` and `FC_MAC` match this.
FC_MAC=&quot;06:00:AC:10:00:02&quot;

# Set network interface
curl -X PUT --unix-socket &quot;${API_SOCKET}&quot; \
    --data &quot;{
        \&quot;iface_id\&quot;: \&quot;net1\&quot;,
        \&quot;guest_mac\&quot;: \&quot;$FC_MAC\&quot;,
        \&quot;host_dev_name\&quot;: \&quot;$TAP_DEV\&quot;
    }&quot; \
    &quot;http://localhost/network-interfaces/net1&quot;

# API requests are handled asynchronously, it is important the configuration is
# set, before `InstanceStart`.
sleep 0.015s

# Start microVM
curl -X PUT --unix-socket &quot;${API_SOCKET}&quot; \
    --data &quot;{
        \&quot;action_type\&quot;: \&quot;InstanceStart\&quot;
    }&quot; \
    &quot;http://localhost/actions&quot;

# API requests are handled asynchronously, it is important the microVM has been
# started before we attempt to SSH into it.
sleep 0.015s

# SSH into the microVM
ssh -i ./ubuntu-22.04.id_rsa root@172.16.0.2

# Use `root` for both the login and password.
# Run `reboot` to exit.
</code></pre>
<p>Issuing a <code>reboot</code> command inside the guest will gracefully shutdown Firecracker.
This is due to the fact that Firecracker doesn't implement guest power management.</p>
<h3 id="configuring-the-microvm-without-sending-api-requests"><a class="header" href="#configuring-the-microvm-without-sending-api-requests">Configuring the microVM without sending API requests</a></h3>
<p>You can boot a guest without using the API socket by passing the parameter
<code>--config-file</code> to the Firecracker process.
E.g.:</p>
<pre><code class="language-wrap">./firecracker --api-sock /tmp/firecracker.socket --config-file &lt;path_to_the_configuration_file&gt;
</code></pre>
<p><code>path_to_the_configuration_file</code> is the path to a JSON file with the
configuration for all of the microVM's resources. The JSON <strong>must</strong> contain the
configuration for the guest kernel and rootfs, all of the other resources are
optional. This configuration method will also start the microVM, as such you
need to specify all desired pre-boot configurable resources in the JSON. The
names of the resources can be seen in
<a href="../src/api_server/swagger/firecracker.yaml"><code>firecracker.yaml</code></a> and the
names of their fields are the same that are used in the API requests.</p>
<p>An example of configuration file is provided:
<a href="../tests/framework/vm_config.json"><code>tests/framework/vm_config.json</code></a>.</p>
<p>Once the guest is booted, refer <a href="./network-setup.html#in-the-guest">network-setup</a>
to bring up the network in the guest machine.</p>
<p>After the microVM is started you can still use the socket to send API requests
for post-boot operations.</p>
<h3 id="building-firecracker"><a class="header" href="#building-firecracker">Building Firecracker</a></h3>
<p>SSH can be used to work with libraries from private git repos by passing
the <code>--ssh-keys</code> flag to specify the paths to your public and private SSH keys
on the host. Both are required for git authentication when fetching the
repositories.</p>
<pre><code class="language-bash">tools/devtool build --ssh-keys ~/.ssh/id_rsa.pub ~/.ssh/id_rsa
</code></pre>
<p>Only a single set of credentials is supported. <code>devtool</code> cannot fetch multiple
private repos which rely on different credentials.</p>
<p><code>tools/devtool build</code> builds in <code>debug</code> to build release binaries pass
<code>--release</code> e.g. <code>tools/devtool build --release</code></p>
<p>Documentation on <code>devtool</code> can be seen with <code>tools/devtool --help</code>.</p>
<h2 id="running-the-integration-test-suite"><a class="header" href="#running-the-integration-test-suite">Running the Integration Test Suite</a></h2>
<p>Integration tests can be run with <code>tools/devtool test</code>.</p>
<p>The test suite is designed to ensure our <a href="../SPECIFICATION.html">SLA parameters</a>
as measured on EC2 .metal instances, as such performance tests may fail when not
run on these machines. Specifically, don't be alarmed if you see
<code>tests/integration_tests/performance/test_process_startup_time.py</code> failing when
not run on an EC2 .metal instance. You can skip performance tests with:</p>
<pre><code class="language-bash">./tools/devtool test -- --ignore integration_tests/performance
</code></pre>
<p>If you run the integration tests on an EC2 .metal instance, and encounter
failures such as the following</p>
<p><code>FAILED integration_tests/style/test_markdown.py::test_markdown_style - requests.exceptions.ReadTimeout: HTTPConnectionPool(host='169.254.169.254', port=80): Read timed out. (read timeout=2)</code></p>
<p>try running <code>aws ec2 modify-instance-metadata-options --instance-id i-&lt;your instance id&gt; --http-put-response-hop-limit 2</code>. The integration tests framework
uses IMDSv2 to determine information such as instance type. The additional hop
is needed because the IMDS requests will pass through docker.</p>
<h2 id="errors-while-using-curl-to-access-the-api"><a class="header" href="#errors-while-using-curl-to-access-the-api">Errors while using <code>curl</code> to access the API</a></h2>
<p>Points to check to confirm the API socket is running and accessible:</p>
<ul>
<li>Check that the user running the Firecracker process and the user using <code>curl</code>
have equivalent privileges. For example, if you run Firecracker with <strong>sudo</strong>
that you run <code>curl</code> with <strong>sudo</strong> as well.</li>
<li><a href="https://man7.org/linux/man-pages/man8/selinux.8.html">SELinux</a> can regulate
access to sockets on RHEL based distributions. How user's permissions are
configured is environmentally specific, but for the purposes of
troubleshooting you can check if it is enabled in <code>/etc/selinux/config</code>.</li>
<li>With the Firecracker process running using <code>--api-sock /tmp/firecracker.socket</code>,
confirm that the socket is open:
<ul>
<li><code>ss -a | grep '/tmp/firecracker.socket'</code></li>
<li>If you have socat available, try <code>socat - UNIX-CONNECT:/tmp/firecracker.socket</code>
This will throw an explicit error if the socket is inaccessible, or it will pause
and wait for input to continue.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contributions-welcome"><a class="header" href="#contributions-welcome">Contributions Welcome</a></h1>
<p>Firecracker is running serverless workloads at scale within AWS, but it's still
day 1 on the journey guided by our <a href="CHARTER.html">mission</a>. There's a lot more to
build and we welcome all contributions.</p>
<p>There's a lot to contribute to in Firecracker. We've opened issues for all the
features we want to build and improvements we want to make. Good first issues
are labeled accordingly. We're also keen to hearing about your use cases and how
we can support them, your ideas, and your feedback for what's already here.</p>
<p>If you're just looking for quick feedback for an idea or proposal, open an
<a href="https://github.com/firecracker-microvm/firecracker/issues">issue</a> or chat with
us on the <a href="https://firecracker-microvm.slack.com">Firecracker Slack workgroup</a>.</p>
<p>Follow the <a href="CONTRIBUTING.html#contribution-workflow">contribution workflow</a> for submitting your
changes to the Firecracker codebase. If you want to receive high-level but still
commit-based feedback for a contribution, follow the
<a href="CONTRIBUTING.html#request-for-comments">request for comments</a> steps instead.</p>
<h2 id="contribution-workflow"><a class="header" href="#contribution-workflow">Contribution Workflow</a></h2>
<p>Firecracker uses the “fork-and-pull” development model. Follow these steps if
you want to merge your changes to Firecracker:</p>
<ol>
<li>Within your fork of
<a href="https://github.com/firecracker-microvm/firecracker">Firecracker</a>, create a
branch for your contribution. Use a meaningful name.</li>
<li>Create your contribution, meeting all
<a href="CONTRIBUTING.html#contribution-quality-standards">contribution quality standards</a></li>
<li><a href="https://help.github.com/articles/creating-a-pull-request-from-a-fork/">Create a pull request</a>
against the main branch of the Firecracker repository.</li>
<li>Add two reviewers to your pull request (a maintainer will do that for you if
you're new). Work with your reviewers to address any comments and obtain a
minimum of 2 approvals, at least one of which must be provided by
<a href="MAINTAINERS.html">a maintainer</a>.
To update your pull request amend existing commits whenever applicable and
then push the new changes to your pull request branch.</li>
<li>Once the pull request is approved, one of the maintainers will merge it.</li>
</ol>
<h2 id="request-for-comments"><a class="header" href="#request-for-comments">Request for Comments</a></h2>
<p>If you just want to receive feedback for a contribution proposal, open an “RFC”
(“Request for Comments”) pull request:</p>
<ol>
<li>On your fork of
<a href="https://github.com/firecracker-microvm/firecracker">Firecracker</a>, create a
branch for the contribution you want feedback on. Use a meaningful name.</li>
<li>Create your proposal based on the existing codebase.</li>
<li><a href="https://help.github.com/articles/creating-a-pull-request-from-a-fork/">Create a pull request</a>
against the main branch of the Firecracker repository. Prefix your pull
request name with <code>[RFC]</code>.</li>
<li>Discuss your proposal with the community on the pull request page (or on any
other channel). Add the conclusion(s) of this discussion to the pull request
page.</li>
</ol>
<h2 id="contribution-quality-standards"><a class="header" href="#contribution-quality-standards">Contribution Quality Standards</a></h2>
<p>Most quality and style standards are enforced automatically during integration
testing. For ease of use you can setup a git pre-commit hook by running the
following in the Firecracker root directory:</p>
<pre><code>cargo install rusty-hook
rusty-hook init
</code></pre>
<p>Your contribution needs to meet the following standards:</p>
<ul>
<li>
<p>Separate each <strong>logical change</strong> into its own commit.</p>
</li>
<li>
<p>Each commit must pass all unit &amp; code style tests, and the full pull request
must pass all integration tests. See <a href="tests/README.html">tests/README.md</a> for
information on how to run tests.</p>
</li>
<li>
<p>Unit test coverage must <em>increase</em> the overall project code coverage.</p>
</li>
<li>
<p>Include integration tests for any new functionality in your pull request.</p>
</li>
<li>
<p>Document all your public functions.</p>
</li>
<li>
<p>Add a descriptive message for each commit. Follow
<a href="https://github.com/erlang/otp/wiki/writing-good-commit-messages">commit message best practices</a>.</p>
</li>
<li>
<p>A good commit message may look like</p>
<pre><code>A descriptive title of 72 characters or fewer

A concise description where each line is 72 characters or fewer.

Signed-off-by: &lt;A full name&gt; &lt;A email&gt;
Co-authored-by: &lt;B full name&gt; &lt;B email&gt;
</code></pre>
</li>
<li>
<p><strong>Usage of <code>unsafe</code> is heavily discouraged</strong>. If <code>unsafe</code> is required,
it should be accompanied by a comment detailing its...</p>
<ul>
<li>Justification, potentially including quantifiable reasons why safe
alternatives were not used (e.g. via a benchmark showing a valuable<sup class="footnote-reference"><a href="#1">1</a></sup>
performance improvements).</li>
<li>Safety, as per <a href="https://rust-lang.github.io/rust-clippy/master/#undocumented_unsafe_blocks"><code>clippy::undocumented_unsafe_blocks</code></a>.
This comment must list all invariants of the called function, and
explain why there are upheld. If relevant, it must also prove that
<a href="https://doc.rust-lang.org/reference/behavior-considered-undefined.html">undefined behavior</a>
is not possible.</li>
</ul>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Performance improvements in non-hot paths are unlikely to be considered valuable.</p>
</div>
<p>E.g.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Test creating a resource.
// JUSTIFICATION: This cannot be accomplished without unsafe as
// `external_function()` returns `RawFd`. An alternative here still uses
// unsafe e.g. `drop(unsafe { OwnedFd::from_raw_fd(external_function()) });`.
// SAFETY: `external_function()` returns a valid file descriptor.
unsafe {
    libc::close(external_function());
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Document your pull requests. Include the reasoning behind each change, and
the testing done.</p>
</li>
<li>
<p>Acknowledge Firecracker's <a href="LICENSE">Apache 2.0 license</a> and certify that no
part of your contribution contravenes this license by signing off on all your
commits with <code>git -s</code>. Ensure that every file in your pull request has a
header referring to the repository license file.</p>
</li>
</ul>
<h2 id="developer-certificate-of-origin"><a class="header" href="#developer-certificate-of-origin">Developer Certificate of Origin</a></h2>
<p>Firecracker is an open source product released under the <a href="LICENSE">Apache 2.0 license</a>.</p>
<p>We respect intellectual property rights of others and we want to make sure all
incoming contributions are correctly attributed and licensed.
A Developer Certificate of Origin (DCO) is a lightweight mechanism to do that.</p>
<p>The DCO is a declaration attached to every contribution made by every
developer. In the commit message of the contribution, the developer simply adds
a <code>Signed-off-by</code> statement and thereby agrees to the DCO, which you can find
below or at DeveloperCertificate.org (<a href="http://developercertificate.org/">http://developercertificate.org/</a>).</p>
<pre><code>Developer's Certificate of Origin 1.1

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I
    have the right to submit it under the open source license
    indicated in the file; or

(b) The contribution is based upon previous work that, to the
    best of my knowledge, is covered under an appropriate open
    source license and I have the right under that license to
    submit that work with modifications, whether created in whole
    or in part by me, under the same open source license (unless
    I am permitted to submit under a different license), as
    Indicated in the file; or

(c) The contribution was provided directly to me by some other
    person who certified (a), (b) or (c) and I have not modified
    it.

(d) I understand and agree that this project and the contribution
    are public and that a record of the contribution (including
    all personal information I submit with it, including my
    sign-off) is maintained indefinitely and may be redistributed
    consistent with this project or the open source license(s)
    involved.
</code></pre>
<p>We require that every contribution to Firecracker is signed with a Developer
Certificate of Origin. DCO checks are enabled via <a href="https://github.com/apps/dco">https://github.com/apps/dco</a>,
and your PR will fail CI without it.</p>
<p>Additionally, we kindly ask you to use your real name. We do not accept
anonymous contributors, nor those utilizing pseudonyms.
Each commit must include a DCO which looks like this:</p>
<pre><code>Signed-off-by: Jane Smith &lt;jane.smith@email.com&gt;
</code></pre>
<p>You may type this line on your own when writing your commit messages.
However, if your <code>user.name</code> and <code>user.email</code> are set in your git config,
you can use <code>-s</code> or <code>--signoff</code> to add the <code>Signed-off-by</code> line to the end of
the commit message automatically.</p>
<p>Forgot to add DCO to a commit? Amend it with <code>git commit --amend -s</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="setting-up-a-development-environment-for-firecracker"><a class="header" href="#setting-up-a-development-environment-for-firecracker">Setting up a Development Environment for Firecracker</a></h1>
<p>Firecracker uses KVM for the actual resource virtualization, hence setting up
a development environment requires either a bare-metal machine (with hardware
virtualization), or a virtual machine that supports nested virtualization.
The different options are outlined below. Once the environment is set up, one
can continue with the specific steps of setting up Firecracker (e.g., as
outlined in the <a href="getting-started.html">Getting Started</a> instructions).</p>
<h2 id="local"><a class="header" href="#local">Local</a></h2>
<h3 id="local-bare-metal-machine"><a class="header" href="#local-bare-metal-machine">Local Bare-Metal Machine</a></h3>
<p><code>[TODO]</code></p>
<h3 id="local-virtual-machine"><a class="header" href="#local-virtual-machine">Local Virtual Machine</a></h3>
<h4 id="macos-with-vmware-fusion"><a class="header" href="#macos-with-vmware-fusion">macOS with VMware Fusion</a></h4>
<p>Note that Firecracker development on macOS has no hard dependency on VMware
Fusion or Ubuntu. All that is required is a Linux VM that supports nested
virtualization. This is but one example of that setup:</p>
<ol>
<li>Download and install <a href="https://www.vmware.com/products/fusion/fusion-evaluation.html">VMware Fusion</a>.</li>
<li>Download an <a href="https://www.ubuntu.com/download/desktop">Ubuntu 18.04.2 LTS</a>
ISO image.</li>
<li>Open VMware Fusion, open the <strong>File</strong> menu, and select <strong>New...</strong> to bring up
the <strong>Select the Installation Method</strong> window.</li>
<li>Find the ISO image you downloaded in step 2, and drag it onto the VMware
window opened in step 3.</li>
<li>You should now be at the <strong>Create a New Virtual Machine</strong> window. Ensure the
Ubuntu 18.04.2 image is highlighted, and click <strong>Continue</strong>.</li>
<li>On the <strong>Linux Easy Install</strong> window, leave the <strong>Use Easy Install</strong> option
checked, enter a password, and click <strong>Continue</strong>.</li>
<li>On the <strong>Finish</strong> window, click <strong>Finish</strong>, and save the <code>.vmwarevm</code> file if
prompted.</li>
<li>After the VM starts up, open the <strong>Virtual Machine</strong> menu,
and select <strong>Shut Down</strong>.</li>
<li>After the VM shuts down, open the <strong>Virtual Machine</strong> menu, and select
<strong>Settings...</strong>.</li>
<li>From the settings window, select <strong>Processors &amp; Memory</strong>, and then unfurl
the <strong>Advanced options</strong> section.</li>
<li>Check the <strong>Enable hypervisor applications in this virtual machine</strong> option,
close the settings window, open the <strong>Virtual Machine</strong> menu, and select <strong>Start
Up</strong>.</li>
<li>If you receive a <strong>Cannot connect the virtual device sata0:1 because no
corresponding device is available on the host.</strong> error, you can respond <strong>No</strong>
to the prompt.</li>
<li>Once the VM starts up, log in as the user you created in step 6.</li>
<li>After logging in, open the <strong>Terminal</strong> app, and run
<code>sudo apt install curl -y</code> to install cURL.</li>
<li>Now you can continue with the Firecracker <a href="getting-started.html">Getting Started</a>
instructions to install and configure Firecracker in the new VM.</li>
</ol>
<h2 id="cloud"><a class="header" href="#cloud">Cloud</a></h2>
<h3 id="aws"><a class="header" href="#aws">AWS</a></h3>
<p>Firecracker development environment on AWS can be setup using bare metal instances.
Follow these steps to create a bare metal instance.</p>
<ol>
<li>
<p>If you don't already have an AWS account, create one using the <a href="https://portal.aws.amazon.com/billing/signup">AWS Portal</a>.</p>
</li>
<li>
<p>Login to <a href="https://console.aws.amazon.com/console/home">AWS console</a>. You must
select a region that offers bare metal EC2 instances. To check which regions
support bare-metal, visit <a href="https://aws.amazon.com/ec2/pricing/on-demand/">Amazon EC2 On-Demand Pricing</a>
and look for <code>*.metal</code> instance types.</p>
</li>
<li>
<p>Click on <code>Launch a virtual machine</code> in <code>Build Solution</code> section.</p>
</li>
<li>
<p>Firecracker requires a relatively new kernel, so you should use a recent
Linux distribution - such as <code>Ubuntu Server 18.04 LTS (HVM), SSD Volume Type</code>.</p>
</li>
<li>
<p>In <code>Step 2</code>, scroll to the bottom and select <code>i3.metal</code> instance type. Click
on <code>Next: Configure Instance Details</code>.</p>
</li>
<li>
<p>In <code>Step 3</code>, click on <code>Next: Add Storage</code>.</p>
</li>
<li>
<p>In <code>Step 4</code>, click on <code>Next: Add Tags</code>.</p>
</li>
<li>
<p>In <code>Step 5</code>, click on <code>Next: Configure Security Group</code>.</p>
</li>
<li>
<p>In <code>Step 6</code>, take the default security group. This opens up port 22 and is
needed so that you can ssh into the machine later. Click on <code>Review and Launch</code>.</p>
</li>
<li>
<p>Verify the details and click on <code>Launch</code>. If you do not have an existing
key pair, then you can select <code>Create a new key pair</code> to create a key pair.
This is needed so that you can use it later to ssh into the machine.</p>
</li>
<li>
<p>Click on the instance id in the green box. Copy <code>Public DNS</code> from the
<code>Description</code> tab of the selected instance.</p>
</li>
<li>
<p>Login to the newly created instance:</p>
<pre><code class="language-console">ssh -i &lt;ssh-key&gt; ubuntu@&lt;public-ip&gt;
</code></pre>
</li>
</ol>
<p>Now you can continue with the Firecracker <a href="getting-started.html">Getting Started</a>
instructions to use Firecracker to create a microVM.</p>
<h3 id="gcp"><a class="header" href="#gcp">GCP</a></h3>
<p>One of the options to set up Firecracker for development purposes is to use a
VM on Google Compute Engine (GCE), which supports nested virtualization and
allows to run KVM. If you don't have a Google Cloud Platform (GCP) account,
you can find brief instructions in the Addendum <a href="dev-machine-setup.html#addendum">below</a>.</p>
<p>Here is a brief summary of steps to create such a setup (full instructions to
set up a Ubuntu-based VM on GCE with nested KVM enablement can be found in GCE
<a href="https://cloud.google.com/compute/docs/instances/enable-nested-virtualization-vm-instances">documentation</a>).</p>
<ol>
<li>
<p>Select a GCP project and zone</p>
<pre><code class="language-console">$ FC_PROJECT=your_name-firecracker
$ FC_REGION=us-east1
$ FC_ZONE=us-east1-b
</code></pre>
<details><summary>Click here for instructions to create a new project</summary>
 <p>
 It might be convenient to keep your Firecracker-related GCP resources in
 a separate project, so that you can keep track of resources more easily
 and remove everything easily once your are done.
<p>For convenience, give the project a unique name (e.g.,
your_name-firecracker), so that GCP does not need to create a project
id different than project name (by appending randomized numbers to the
name you provide).</p>
<pre><code class="language-console">$ gcloud projects create ${FC_PROJECT} --enable-cloud-apis --set-as-default
</code></pre>
</p>
 </details>
<pre><code class="language-console">$ gcloud config set project ${FC_PROJECT}
$ gcloud config set compute/region ${FC_REGION}
$ gcloud config set compute/zone ${FC_ZONE}
</code></pre>
</li>
<li>
<p>The next step is to create a VM image able to run nested KVM (as outlined
<a href="https://cloud.google.com/compute/docs/instances/nested-virtualization/enabling">here</a>).</p>
</li>
<li>
<p>Now we create the VM:</p>
<p>Keep in mind that you will need an instance type that supports nested
virtualization. <code>E2</code> and <code>N2D</code> instances will not work. If you want to use
a <code>N1</code> instance (default in some regions), make sure it uses at least a
processor of the <code>Haswell</code> architecture by specifying
<code>--min-cpu-platform=&quot;Intel Haswell&quot;</code> when you create the instance.
Alternatively, use <code>N2</code> instances (such as with
`--machine-type=&quot;n2-standard-2&quot;).</p>
<pre><code class="language-console">$ FC_VM=firecracker-vm
$ gcloud compute instances create ${FC_VM} --enable-nested-virtualization \
--zone=${FC_ZONE} --min-cpu-platform=&quot;Intel Haswell&quot; \
--machine-type=n1-standard-2
</code></pre>
</li>
<li>
<p>Connect to the VM via SSH.</p>
<pre><code class="language-console">$ gcloud compute ssh ${FC_VM}
</code></pre>
<p>When doing it for the first time, a key-pair will be created for you
(you will be propmpted for a passphrase - can just keep it empty) and
uploaded to GCE. Done! You should see the prompt of the new VM:</p>
<pre><code class="language-console">[YOUR_USER_NAME]@firecracker-vm:~$
</code></pre>
</li>
<li>
<p>Verify that VMX is enabled, enable KVM</p>
<pre><code class="language-console">$ grep -cw vmx /proc/cpuinfo
1
$ apt-get update
$ apt-get install acl
$ sudo setfacl -m u:${USER}:rw /dev/kvm
$ [ -r /dev/kvm ] &amp;&amp; [ -w /dev/kvm ] &amp;&amp; echo &quot;OK&quot; || echo &quot;FAIL&quot;
OK
</code></pre>
</li>
</ol>
<p>Depending on your machine you will get a different number, but anything except 0
means <code>KVM</code> is enabled.</p>
<p>Now you can continue with the Firecracker <a href="getting-started.html">Getting Started</a>
instructions to install and configure Firecracker in the new VM.</p>
<h4 id="addendum"><a class="header" href="#addendum">Addendum</a></h4>
<h5 id="setting-up-a-google-cloud-platform-account"><a class="header" href="#setting-up-a-google-cloud-platform-account">Setting up a Google Cloud Platform account</a></h5>
<p>In a nutshell, setting up a GCP account involves the following steps:</p>
<ol>
<li>
<p>Log in to GCP <a href="https://console.cloud.google.com/">console</a> with your
Google credentials. If you don't have account, you will be prompted to join
the trial.</p>
</li>
<li>
<p>Install GCP CLI &amp; SDK (full instructions can be found
<a href="https://cloud.google.com/sdk/docs/quickstart-debian-ubuntu">here</a>).</p>
<pre><code class="language-console">$ export CLOUD_SDK_REPO=&quot;cloud-sdk-$(lsb_release -c -s)&quot;
$ echo &quot;deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main&quot; \
| sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
$ curl https://packages.cloud.google.com/apt/doc/apt-key.gpg \
| sudo apt-key add -
$ sudo apt-get update &amp;&amp; sudo apt-get install -y google-cloud-sdk
</code></pre>
</li>
<li>
<p>Configure the <code>gcloud</code> CLI by running:</p>
<pre><code class="language-console">$ gcloud init --console-only
</code></pre>
<p>Follow the prompts to authenticate (open the provided link, authenticate,
copy the token back to console) and select the default project.</p>
</li>
</ol>
<h3 id="microsoft-azure"><a class="header" href="#microsoft-azure">Microsoft Azure</a></h3>
<p><code>[TODO]</code></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="runbook-for-firecracker-api-changes"><a class="header" href="#runbook-for-firecracker-api-changes">Runbook for Firecracker API changes</a></h1>
<p>This runbook will cover triaging API changes and ways to implement them
appropriately.</p>
<h2 id="definitions"><a class="header" href="#definitions">Definitions</a></h2>
<ul>
<li><em>Deprecated</em> - We will consider a deprecated API element (endpoint and/or
parts of an endpoint) to be an element which still provides users with
access to its backing functionality and can be used, but will soon be
removed completely along with said functionality in an upcoming version.</li>
<li><em>Mandatory endpoint</em> - We will consider an endpoint mandatory if Firecracker
cannot operate normally without performing a request to it.</li>
<li><em>Optional endpoint</em> - We will consider an endpoint optional if Firecracker
can operate normally without performing a request to it and the
functionality behind it is not essential.</li>
<li><em>Mandatory header/field</em> - We will consider a header/field mandatory in an
HTTP message if the request will fail without specifying said header/field.</li>
<li><em>Optional header/field</em> - We will consider a header/field optional in an
HTTP message if the request will succeeds without specifying said
header/field.</li>
</ul>
<h2 id="triaging-api-changes"><a class="header" href="#triaging-api-changes">Triaging API changes</a></h2>
<p>For the purposes of this document, there are 2 main categories for API changes,
namely <em>breaking</em> and <em>non-breaking</em>.</p>
<h3 id="what-is-a-breaking-change"><a class="header" href="#what-is-a-breaking-change">What is a breaking change?</a></h3>
<p>A breaking change in the API is a change that makes the API incompatible with
the previous version (backwards incompatible). In an effort to avoid a breaking
change, we may take the route of deprecation and incrementing the minor
version in an effort to preserve backwards compatibility, but breaking changes
will always ultimately result in incrementing the major version. Here is a
non-exhaustive list of such changes:</p>
<ol>
<li>Adding a new mandatory endpoint/HTTP method.</li>
<li>Removing an endpoint/method.</li>
<li>Adding a mandatory request header/field.</li>
<li>Removing a request header/field.</li>
<li>Adding a mandatory response field.</li>
<li>Removing a response header/field.</li>
</ol>
<h3 id="what-is-not-a-breaking-change"><a class="header" href="#what-is-not-a-breaking-change">What is NOT a breaking change?</a></h3>
<p>A change in the API is not a breaking change if the version resulting from it
is compatible with the previous one (backwards compatible). The outcome of a
non-breaking change should always include incrementing the minor version but
must not lead to incrementing the major version by itself. Here is a
non-exhaustive list of such changes:</p>
<ol>
<li>Deprecating an endpoint/method/field.</li>
<li>Adding a new optional endpoint/method.</li>
<li>Adding an optional request header/field.</li>
<li>Adding a response header.</li>
<li>Adding additional valid inputs for fields in API requests.</li>
<li>Making mandatory headers/fields optional.</li>
<li>Making mandatory endpoints optional.</li>
<li>Changing the URI of an endpoint.</li>
<li>Changing the metrics output format.</li>
</ol>
<h2 id="implementing-api-changes"><a class="header" href="#implementing-api-changes">Implementing API changes</a></h2>
<p>API changes result in version increases. As Firecracker’s support policy is
based on <a href="https://semver.org/spec/v2.0.0.html">semantic versioning 2.0.0</a>, we will look at API changes from this
point of view.</p>
<blockquote>
<p>Given a version number MAJOR.MINOR.PATCH, increment the:
MAJOR version when you make incompatible API changes;
MINOR version when you add functionality in a backwards compatible manner;
PATCH version when you make backwards compatible bug fixes.</p>
</blockquote>
<p><img src="images/api_change_flowchart.png?raw=true" alt="Flowchart for changing the Firecracker API" title="Flowchart for changing the Firecracker API" /></p>
<p><em>All deprecated endpoints are supported until at least the next major version
release, where they may be <em>removed</em>.</em></p>
<h3 id="how-to-follow-the-flowchart---with-examples"><a class="header" href="#how-to-follow-the-flowchart---with-examples">How to follow the flowchart - with examples</a></h3>
<p>We will go through multiple types of API changes and provide ways to ensure we
don’t break our backwards compatibility promise to our customers. The list is
split into categories of components changed.</p>
<ul>
<li><em>Entire endpoints</em>
<ul>
<li>Adding an optional endpoint with new functionality - Increment minor
version.</li>
<li>Adding a command line parameter - Increment minor version.</li>
<li>Removing an endpoint - Deprecate endpoint and increment minor version →
Remove endpoint when incrementing major version.</li>
<li>Adding a mandatory endpoint - Increment major version.</li>
</ul>
</li>
<li><em>Request</em>
<ul>
<li>Adding an optional header/field - Increment minor version.</li>
<li>Renaming a header/field - Accept both names and deprecate the old one →
Remove old name when incrementing major version.</li>
<li>Removing a header/field - Make said header/field optional → Remove
header/field when incrementing major version.</li>
<li>Changing the URI of an endpoint - Redirect the old endpoint to the new
one and deprecate the old one → Remove old endpoint when incrementing
major version.</li>
<li>Adding a mandatory header/field - Increment major version.</li>
</ul>
</li>
<li><em>Response</em>
<ul>
<li>Adding a header/field - Create a new, separate endpoint with the changes
and deprecate the old one → Remove old endpoint when incrementing major
version.</li>
<li>Removing a header/field - Create a new, separate endpoint with the
changes and deprecate the old one → Remove old endpoint when incrementing
major version.</li>
</ul>
</li>
<li><em>Command line parameter</em>
<ul>
<li>Renaming a command line parameter - Accept both names and deprecate the
old one → Remove old name when incrementing major version.</li>
<li>Changing expected value taken by a command line parameter - Accept both
names and deprecate the old one → Remove old name when incrementing major
version.</li>
</ul>
</li>
</ul>
<p>In case the outlined solution for your case is not feasible (e.g. because of
security concerns), break the glass and increment the major version.</p>
<h2 id="how-to-deprecate"><a class="header" href="#how-to-deprecate">How to deprecate</a></h2>
<p>As outlined in the diagram above, sometimes we have to deprecate endpoints
partially or entirely. In this section we will go through different situations
where we have to deprecate something and ways of avoiding common pitfalls when
doing so.</p>
<h3 id="deprecating-endpoints"><a class="header" href="#deprecating-endpoints">Deprecating endpoints</a></h3>
<p>Some paths in the flowchart above lead to deprecation. Based on the initial
conditions, there are 2 major cases where we need to deprecate an endpoint:</p>
<ul>
<li><em>Changing an existing endpoint</em>
<ul>
<li>Often happens because directly changing the endpoint would be a breaking
change.</li>
<li>We usually create a clone of the old endpoint we want to deprecate and
make the necessary changes to it.</li>
<li>We usually expose both endpoints in the next minor version while marking
the old one as deprecated.</li>
<li>The old endpoint retains its previous name. When naming the new endpoint:
<ul>
<li>for HTTP endpoints we follow a “per-endpoint versioning” scheme; in
cases where we can’t find a fitting name for the new endpoint, the
simplest way forward is to take the old URI and append <code>/v2</code> to it.</li>
<li>for command line endpoints, we can usually find a different name for
the new endpoint.</li>
</ul>
</li>
</ul>
</li>
<li><em>Deprecating an endpoint without adding a replacement to it</em>
<ul>
<li>Often happens when we want to phase out a certain feature or
functionality, but doing so immediately would be a breaking change.</li>
<li>We just mark the endpoint as deprecated.</li>
</ul>
</li>
</ul>
<h3 id="keeping-swagger-updated"><a class="header" href="#keeping-swagger-updated">Keeping Swagger updated</a></h3>
<p>Make sure that any changes you make in the code are also reflected in the
swagger specification.</p>
<p>Some tips:</p>
<ul>
<li>There is nothing in the swagger file that shows whether an endpoint is
mandatory or optional, it’s all code logic.</li>
<li>Mandatory fields in a request or response body are marked with
<code>required: true</code> in the swagger definition. All other fields are optional.</li>
<li>If you need to redirect an endpoint, you have to clone the old one under the
new URI in the swagger specification.</li>
</ul>
<h3 id="marking-endpoints-as-deprecated"><a class="header" href="#marking-endpoints-as-deprecated">Marking endpoints as deprecated</a></h3>
<p>When marking:</p>
<ul>
<li>an HTTP endpoint as deprecated:
<ul>
<li>Add a comment for the parsing function of the endpoint stating that it
is deprecated.</li>
<li>Log a <code>warn!</code> message stating that the user accessed a deprecated
endpoint.</li>
<li>Increment the <code>deprecatedHttpApi</code> metric.</li>
<li>Include the <code>Deprecated</code> header in the response.</li>
</ul>
</li>
<li>a header field in an HTTP endpoint as deprecated:
<ul>
<li>Add a comment in the parsing function where we check the presence of the
header stating that it is deprecated.</li>
<li>If the header is present, log a <code>warn!</code> message stating that the user
used a deprecated field.</li>
<li>Increment the <code>deprecatedHttpApi</code> metric.</li>
<li>Include the Deprecated header in the response.</li>
</ul>
</li>
<li>a command line parameter as deprecated:
<ul>
<li>Mention it is deprecated in the help message of the parameter in the
argument parser.</li>
<li>Add it in the <code>warn_deprecated_parameters</code> function where we log it
and increment the <code>deprecatedCmdLineApi</code> metric.</li>
</ul>
</li>
</ul>
<h3 id="removing-deprecated-endpoints-on-a-major-release"><a class="header" href="#removing-deprecated-endpoints-on-a-major-release">Removing deprecated endpoints on a major release</a></h3>
<p>When doing a major release, the API can have breaking changes. This is the
<em>only time</em> where we can safely remove deprecated elements of the API.
To remove a deprecated element of the API:</p>
<ul>
<li>Remove the associated functionality from the codebase (usually in <code>vmm</code> or
<code>mmds</code>);</li>
<li>Remove the parsing logic in <code>api_server</code>;</li>
<li>Remove any unit and integration tests associated with this element.</li>
</ul>
<h2 id="practical-example-of-an-api-change"><a class="header" href="#practical-example-of-an-api-change">Practical example of an API change</a></h2>
<p>In this guide we set out to remove the <code>vsock_id</code> field in <code>PUT</code>s on <code>/vsock</code>.
This was implemented in <a href="https://github.com/firecracker-microvm/firecracker/pull/2763">PR #2763</a> and we will go step by step through the
changes in order to understand the process of changing something in the
Firecracker API.</p>
<ul>
<li>We go through the flowchart; we want to remove a field in the body of a
HTTP request. So we follow the flowchart like this:
<ul>
<li>→ Change an existing endpoint</li>
<li>→ Request</li>
<li>→ Remove header or field</li>
<li>→ Make it optional</li>
<li>→ Deprecate</li>
<li>→ Increment minor version.</li>
</ul>
</li>
<li>Now that we know we need to make the field optional and deprecate it, it’s
time for the code changes (reference implementation in <a href="https://github.com/firecracker-microvm/firecracker/commit/83aa098245a42ad93a6b70ccd70ad593cf453a3c">this commit</a>).
We go to the function in <code>api_server/src/requests</code> which is responsible for
parsing this request, which is <code>parse_put_vsock</code> in this case, and do the
following.
<ul>
<li>We find the associated <code>vmm_config</code> struct which <code>serde_json</code> uses for
deserialization, in this case <code>VsockDeviceConfig</code>.</li>
<li>In the struct referenced above, we make the parameter optional by
encapsulating it in an <code>Option</code> with <code>#[serde(default)]</code> and
<code>#[serde(skip_serializing_if = &quot;Option::is_none&quot;)]</code> so that we don’t break
existing implementations, but we follow the new, desired usage of the
endpoint.</li>
<li>After deserializing the body of the request into the struct, we check
for the existence of the field we want to deprecate, in this case by
calling <code>vsock_cfg.vsock_id.is_some()</code>.</li>
<li>If the field is there, we must mark this request as being deprecated,
so we craft a deprecation message
(<code>&quot;PUT /vsock: vsock_id field is deprecated.&quot;</code>) and increment the
deprecated HTTP API metric
(<code>METRICS.deprecated_api.deprecated_http_api_calls.inc()</code>).</li>
<li>We create a new <code>ParsedRequest</code> where, if we marked the request as
deprecated, we append the deprecation message into its <code>parsing_info</code>
structure, in this case by calling
<code>parsed_req.parsing_info().append_deprecation_message(msg)</code>.</li>
<li>Don’t forget to comment your code! Comments should reflect what is
deprecated and clearly describe the code paths where you handle the
deprecation case.</li>
<li>Add a unit test where you test your new code paths.</li>
<li>Fix all other failing unit tests.</li>
<li>Update the swagger file to reflect the change, in this case by removing
the <code>vsock_id</code> field from the required parameter list in the <code>Vsock</code>
definition and adding a description to it stating that it is deprecated
since the current version.</li>
<li>Update any relevant documentation.</li>
</ul>
</li>
<li>We update the python integration tests to reflect the change (reference
implementation in <a href="https://github.com/firecracker-microvm/firecracker/commit/472a81dbccd89562578919b76d87c30ee7db17aa">this commit</a>).
<ul>
<li>We refactor the relevant
<code>tests/integration_tests/functional/test_api.py</code> test to use the artifact
model instead of the fixture one. If the test already uses the artifact
model, you can skip this step.</li>
<li>We make sure to run the test with the current build, as well as with
future Firecracker versions by specifying the unreleased version in the
<code>min_version</code> parameter of <code>artifacts.firecrackers()</code>. We do this in order
to ensure that, when we create patch releases on older branches, we test
the API with future binaries to enforce backwards compatibility.
<em>Disclaimer</em>: This test will fail when running with the binary artifact
fetched from S3 until you update the binary there with your current build.
You should only do this once your PR has all necessary approves and this
test is the last thing keeping it from getting merged.</li>
<li>We check that, when the deprecated field is present in the request, the
<code>Deprecation</code> header is also present in the response by asserting
<code>response.headers['deprecation']</code>. We do not also check that the header is
not present when the field is not present because, in a future version,
some other field may be deprecated in the same request and would return
the header anyway, resulting in a fail in our test when it shouldn’t.</li>
<li>Fix all other failing integration tests.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firecracker-release-policy"><a class="header" href="#firecracker-release-policy">Firecracker Release Policy</a></h1>
<p>This document describes Firecracker release planning, API support, and the
Firecracker release lifetime. Firecracker provides this Release Policy to help
customers effectively plan their Firecracker based operations.</p>
<h2 id="firecracker-releases"><a class="header" href="#firecracker-releases">Firecracker releases</a></h2>
<p>Firecracker uses <a href="https://semver.org/spec/v2.0.0.html">semantic versioning 2.0.0</a>
for all releases. By definition, the API version implemented by a Firecracker
binary is equivalent to that binary’s version. Semantic versions are comprised
of three fields in the form: <code>vMAJOR.MINOR.PATCH</code>. Additional labels for
pre-release and build metadata are available as extensions to the
MAJOR.MINOR.PATCH format.</p>
<p>For example: v0.20.0, v0.22.0-beta5, and v99.123.77+foo.bar.baz.5.</p>
<p>Firecracker publishes major, minor and patch releases:</p>
<ul>
<li>Patch release - The <code>PATCH</code> field is incremented whenever critical bugs and/or
security issues are found in a supported release. The fixes in a PATCH release
do not change existing behavior or the user interface. Upgrade is recommended.</li>
<li>Minor release - When the <code>MINOR</code> field is incremented, the new release adds
new features, bug fixes, or both without changing the existing user interface
or user facing functionality. Adding new APIs can be done in a <code>MINOR</code>
Firecracker release as long as it doesn’t change the functionality of the APIs
available in the previous release. Minor releases are shipped when features
are ready for production. Multiple features may be bundled in the same
release.</li>
<li>Major release -  When the <code>MAJOR</code> field is incremented, the new release adds
new features and/or bug fixes, changing the existing user interface or user
facing functionality. This may make the new release it incompatible with
previous ones. A major release will likely require changes from other
components interacting with Firecracker, e.g. API request, commands, or
guest components. The changes will be detailed in the release notes.
Major releases are published whenever features or bug fixes that changes
the existing user interface, or user facing functionality, are ready for
production.</li>
</ul>
<h2 id="release-support"><a class="header" href="#release-support">Release support</a></h2>
<p>The Firecracker maintainers will only provide support for Firecracker releases
under our <a href="https://github.com/firecracker-microvm/firecracker/releases">repository's release page</a>.</p>
<p>The Firecracker maintainers will provide patch releases for critical bugs and
security issues when they are found, for:</p>
<ul>
<li>the last two Firecracker <code>vMAJOR.MINOR</code> releases for up to 1 year from
release date;</li>
<li>any Firecracker <code>vMAJOR.MINOR</code> release for at least 6 months from release date;</li>
<li>for each <code>vMAJOR</code>, the latest <code>MINOR</code> for 1 year since release date;</li>
</ul>
<p>Starting with release v1.0, for each major and minor release, we will
also be specifying the supported kernel versions.</p>
<h3 id="examples"><a class="header" href="#examples">Examples</a></h3>
<ol>
<li>Considering an example where the last Firecracker releases are:</li>
</ol>
<ul>
<li>v2.10.0 released on 2022-05-01</li>
<li>v2.11.0 released on 2022-07-10</li>
<li>v2.12.0 released on 2022-09-11</li>
</ul>
<p>In case of an event occurring in 2022-10-03, all three releases will be
patched since less than 6 months elapsed from their MINOR release time.</p>
<ol>
<li>Considering an example where the last Firecracker releases are:</li>
</ol>
<ul>
<li>v2.10.0 released on 2022-05-01</li>
<li>v2.11.0 released on 2022-07-10</li>
<li>v2.12.0 released on 2022-09-11</li>
</ul>
<p>In case of of an event occurring in 2023-05-04, v2.11 and v2.12 will be
patched since those were the last 2 Firecracker major releases and less than
an year passed since their release time.</p>
<ol>
<li>Considering an example where the last Firecracker releases are:</li>
</ol>
<ul>
<li>v2.14.0 released on 2022-05-01</li>
<li>v3.0.0 released on 2022-07-10</li>
<li>v3.1.0 released on 2022-09-11</li>
</ul>
<p>In case of of an event occurring in 2023-01-13, v2.14 will be patched since
is the last minor of v2 and has less than one year since release while v3.0
and v3.1 will be patched since were the last two Firecracker releases and
less than 6 months have passed since release time.</p>
<h2 id="release-status"><a class="header" href="#release-status">Release Status</a></h2>
<div class="table-wrapper"><table><thead><tr><th style="text-align: right">Release</th><th style="text-align: right">Release Date</th><th style="text-align: right">Latest Patch</th><th style="text-align: right">Min. end of support</th><th style="text-align: left">Official end of Support</th></tr></thead><tbody>
<tr><td style="text-align: right">v1.6</td><td style="text-align: right">2023-12-20</td><td style="text-align: right">v1.6.0</td><td style="text-align: right">2024-06-20</td><td style="text-align: left">Supported</td></tr>
<tr><td style="text-align: right">v1.5</td><td style="text-align: right">2023-10-09</td><td style="text-align: right">v1.5.1</td><td style="text-align: right">2024-04-09</td><td style="text-align: left">Supported</td></tr>
<tr><td style="text-align: right">v1.4</td><td style="text-align: right">2023-07-20</td><td style="text-align: right">v1.4.1</td><td style="text-align: right">2024-01-20</td><td style="text-align: left">Supported</td></tr>
<tr><td style="text-align: right">v1.3</td><td style="text-align: right">2023-03-02</td><td style="text-align: right">v1.3.3</td><td style="text-align: right">2023-09-02</td><td style="text-align: left">2023-10-09 (v1.5 released)</td></tr>
<tr><td style="text-align: right">v1.2</td><td style="text-align: right">2022-11-30</td><td style="text-align: right">v1.2.1</td><td style="text-align: right">2023-05-30</td><td style="text-align: left">2023-07-20 (v1.4 released)</td></tr>
<tr><td style="text-align: right">v1.1</td><td style="text-align: right">2022-05-06</td><td style="text-align: right">v1.1.4</td><td style="text-align: right">2022-11-06</td><td style="text-align: left">2023-03-02 (v1.3 released)</td></tr>
<tr><td style="text-align: right">v1.0</td><td style="text-align: right">2022-01-31</td><td style="text-align: right">v1.0.2</td><td style="text-align: right">2022-07-31</td><td style="text-align: left">2022-11-30 (v1.2 released)</td></tr>
<tr><td style="text-align: right">v0.25</td><td style="text-align: right">2021-03-13</td><td style="text-align: right">v0.25.2</td><td style="text-align: right">2021-09-13</td><td style="text-align: left">2022-03-13 (end of 1y support)</td></tr>
</tbody></table>
</div>
<h2 id="api-support"><a class="header" href="#api-support">API support</a></h2>
<p>The Firecracker API follows the semantic versioning standard. For a new
release, we will increment the:</p>
<ul>
<li>MAJOR version when we make breaking changes in our API;</li>
<li>MINOR version when we add or change functionality in a backwards compatible
manner;</li>
<li>PATCH version when we make backwards compatible bug fixes.</li>
</ul>
<p>Given a Firecracker version X.Y.Z user-generated client, it is guaranteed to
work as expected with all Firecracker binary versions X.V.W, where V &gt;= Y.</p>
<h3 id="deprecation-of-elements-in-the-api"><a class="header" href="#deprecation-of-elements-in-the-api">Deprecation of elements in the API</a></h3>
<p>Firecracker uses <a href="https://semver.org/spec/v2.0.0.html">semantic versioning 2.0.0</a>
in terms of deprecating and removing API elements. We will consider a deprecated
API element to be an element which still has backing functionality and will be
supported at least until the next MAJOR version, where they <em>will be removed</em>.
The support period of deprecated API elements is tied to
<a href="https://github.com/firecracker-microvm/firecracker/blob/main/docs/RELEASE_POLICY.md#release-support">the Firecracker release support</a>.</p>
<h2 id="developer-preview-features"><a class="header" href="#developer-preview-features">Developer preview features</a></h2>
<p>A feature is &quot;in&quot; developer preview if it’s marked as such in the
<a href="https://github.com/firecracker-microvm/firecracker/projects/13">Firecracker roadmap</a>
and/or in the <a href="https://github.com/firecracker-microvm/firecracker/releases">Firecracker release notes</a>.</p>
<p>Features in developer preview should not be used in production as they
are not supported. Firecracker team may not provide patch releases for critical
bug fixes or security issues found in features marked as developer preview.</p>
<p>Features in developer preview may be subject to changes at any time.
Changes in existing user interface or user facing functionality of a feature
marked as developer preview can be released without changing the major version.</p>
<h2 id="release-planning"><a class="header" href="#release-planning">Release planning</a></h2>
<p>Firecracker feature planning is outlined in the <a href="https://github.com/firecracker-microvm/firecracker/projects">Firecracker roadmap</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firecracker-design"><a class="header" href="#firecracker-design">Firecracker Design</a></h1>
<h2 id="scope"><a class="header" href="#scope">Scope</a></h2>
<h3 id="what-is-firecracker-1"><a class="header" href="#what-is-firecracker-1">What is Firecracker</a></h3>
<p>Firecracker is a new virtualization technology that enables customers to deploy
lightweight <em>micro</em> Virtual Machines or microVMs. Firecracker microVMs combine
the security and workload isolation properties of traditional VMs with the
speed, agility and resource efficiency enabled by containers. They provide a
secure, trusted environment for multi-tenant services, while maintaining
minimal overhead.</p>
<p>The scope of this document is to describe the features and architecture of the
Firecracker virtual machine manager (VMM).</p>
<h3 id="features"><a class="header" href="#features">Features</a></h3>
<ol>
<li>Firecracker can safely run workloads from different customers on the same
machine.</li>
<li>Customers can create microVMs with any combination of vCPU (up to 32)
and memory to match their application requirements.</li>
<li>Firecracker microVMs can oversubscribe host CPU and memory. The degree of
oversubscription is controlled by customers, who may factor in workload
correlation and load in order to ensure smooth host system operation.</li>
<li>With a microVM configured with a minimal Linux kernel, single-core CPU, and
128 MiB of RAM, Firecracker supports a steady mutation rate of 5 microVMs
per host core per second (e.g., one can create 180 microVMs per second on a
host with 36 physical cores).</li>
<li>The number of Firecracker microVMs running simultaneously on a host is
limited only by the availability of hardware resources.</li>
<li>Each microVM exposes a host-facing API via an in-process HTTP server.</li>
<li>Each microVM provides guest-facing access to host-configured metadata via
the <code>/mmds</code> API.</li>
</ol>
<h3 id="specifications"><a class="header" href="#specifications">Specifications</a></h3>
<p>Firecracker's technical specifications are available in the
<a href="../SPECIFICATION.html">Specifications document</a>.</p>
<h2 id="host-integration"><a class="header" href="#host-integration">Host Integration</a></h2>
<p>The following diagram depicts an example host running Firecracker microVMs.</p>
<p><img src="images/firecracker_host_integration.png?raw=true" alt="Firecracker Host Integration" title="Firecracker Host Integration" /></p>
<p>Firecracker runs on Linux hosts and with Linux guest OSs (from this point on,
referred to as guests). For a complete list of currently supported kernel
versions, check out the <a href="kernel-policy.html">kernel support policy</a>.</p>
<p>In production environments, Firecracker should be started only via the <code>jailer</code> binary.
See <a href="design.html#Sandboxing">Sandboxing</a> for more details.</p>
<p>After launching the process, users interact with the Firecracker API to
configure the microVM, before issuing the <code>InstanceStart</code> command.</p>
<h3 id="host-networking-integration"><a class="header" href="#host-networking-integration">Host Networking Integration</a></h3>
<p>Firecracker emulated network devices are backed by TAP devices on the host. To
make use of Firecracker, we expect our customers to leverage on-host networking
solutions.</p>
<h3 id="storage"><a class="header" href="#storage">Storage</a></h3>
<p>Firecracker emulated block devices are backed by files on the host. To be able
to mount block devices in the guest, the backing files need to be pre-formatted
with a filesystem that the guest kernel supports.</p>
<h2 id="internal-architecture"><a class="header" href="#internal-architecture">Internal Architecture</a></h2>
<p>Each Firecracker process encapsulates one and only one microVM. The process
runs the following threads: API, VMM and vCPU(s). The API thread is responsible
for Firecracker's API server and associated control plane. It's never in the
fast path of the virtual machine. The VMM thread exposes the machine model,
minimal legacy device model, microVM metadata service (MMDS) and VirtIO device
emulated Net, Block and Vsock devices, complete with I/O rate limiting. In
addition to them, there are one or more vCPU threads (one per guest CPU core).
They are created via KVM and run the <code>KVM_RUN</code> main loop. They execute
synchronous I/O and memory-mapped I/O operations on devices models.</p>
<h3 id="threat-containment"><a class="header" href="#threat-containment">Threat Containment</a></h3>
<p>From a security perspective, all vCPU threads are considered to be running
malicious code as soon as they have been started; these malicious threads need
to be contained. Containment is achieved by nesting several trust zones which
increment from least trusted or least safe (guest vCPU threads) to most trusted
or safest (host). These trusted zones are separated by barriers that enforce
aspects of Firecracker security. For example, all outbound network traffic data
is copied by the Firecracker I/O thread from the emulated network interface to
the backing host TAP device, and I/O rate limiting is applied at this point.
These barriers are marked in the diagram below.</p>
<p><img src="images/firecracker_threat_containment.png?raw=true" alt="Firecracker Threat Containment" title="Firecracker Threat Containment" /></p>
<h2 id="components-and-features"><a class="header" href="#components-and-features">Components and Features</a></h2>
<h3 id="machine-model"><a class="header" href="#machine-model">Machine Model</a></h3>
<h4 id="layout"><a class="header" href="#layout">Layout</a></h4>
<p>Firecracker provides guests with storage and network access via emulated VirtIO
Net and VirtIO Block devices. It also exposes a serial console and partial
keyboard controller, the latter being used by guests to reset the VM (either
soft or hard reset). Within Firecracker, the purpose of the I8042 device is to
signal the microVM that the guest has requested a reboot.</p>
<p>In addition to the Firecracker provided device models, guests also see the
Programmable Interrupt Controllers (PICs), the I/O Advanced Programmable
Interrupt Controller (IOAPIC), and the Programmable Interval Timer (PIT) that
KVM supports.</p>
<h4 id="exposing-the-cpu-to-the-guest"><a class="header" href="#exposing-the-cpu-to-the-guest">Exposing the CPU to the guest</a></h4>
<p>Firecracker allows control of what processor information is exposed
to the guest by using <a href="cpu_templates/cpu-templates.html">CPU templates</a>.
CPU templates can be set via the Firecracker API. Users can choose from
existing static CPU templates and/or creating their own custom CPU templates.</p>
<h4 id="clocksources-available-to-guests"><a class="header" href="#clocksources-available-to-guests">Clocksources available to guests</a></h4>
<p>Firecracker only exposes kvm-clock to customers.</p>
<h3 id="io-storage-networking-and-rate-limiting"><a class="header" href="#io-storage-networking-and-rate-limiting">I/O: Storage, Networking and Rate Limiting</a></h3>
<p>Firecracker provides VirtIO/block and VirtIO/net emulated devices, along with
the application of rate limiters to each volume and network interface to make
sure host hardware resources are used fairly by multiple microVMs. These are
implemented using a token bucket algorithm based on two buckets. One is
associated with the number of operations per second and the other one with the
bandwidth. The customer can create and configure rate limiters via the API by
specifying token bucket configurations for ingress and egress. Each token
bucket is defined via the bucket size, I/O cost, refill rate, maximum burst,
and initial value. This enables the customer to define flexible rate limiters
that support bursts or specific bandwidth/operations limitations.
For vhost-user devices, customers should implement rate limiting on the
side of the vhost-user backend that they provide.</p>
<h3 id="microvm-metadata-service"><a class="header" href="#microvm-metadata-service">MicroVM Metadata Service</a></h3>
<p>Firecracker microVMs expose access to a minimal MicroVM-Metadata Service
(MMDS) to the guest through the API endpoint. The metadata stored by the
service is fully configured by users.</p>
<h3 id="sandboxing"><a class="header" href="#sandboxing">Sandboxing</a></h3>
<h4 id="firecracker-process"><a class="header" href="#firecracker-process"><strong>Firecracker process</strong></a></h4>
<p>Firecracker is designed to assure secure isolation using multiple layers.
The first layer of isolation is provided by the Linux KVM and the Firecracker
virtualization boundary. To assure defense in depth, Firecracker should only
run constrained at the process level. This is achieved by the following:
seccomp filters for disallowing unwanted system calls, cgroups and namespaces
for resource isolation, and dropping privileges by jailing the process. Seccomp
filters are automatically installed by Firecracker, while for the latter, we
recommend starting Firecracker with the <code>jailer</code> binary that's part of each
Firecracker release.</p>
<h5 id="seccomp"><a class="header" href="#seccomp">Seccomp</a></h5>
<p>Seccomp filters are used by default to limit the host system calls Firecracker
can use. The default filters only allow the bare minimum set of system calls
and parameters that Firecracker needs in order to function correctly.</p>
<p>The filters are loaded in the Firecracker process, on a per-thread basis,
before executing any guest code.</p>
<p>For more information, check out the <a href="seccomp.html">seccomp documentation</a>.</p>
<h4 id="jailer-process"><a class="header" href="#jailer-process"><strong>Jailer process</strong></a></h4>
<p>The Firecracker process can be started by another <code>jailer</code> process. The jailer
sets up system resources that require elevated permissions (e.g., cgroup,
chroot), drops privileges, and then exec()s into the Firecracker binary, which
then runs as an unprivileged process. Past this point, Firecracker can only
access resources that a privileged third-party grants access to (e.g., by
copying a file into the chroot, or passing a file descriptor).</p>
<h5 id="cgroups-and-quotas"><a class="header" href="#cgroups-and-quotas">Cgroups and Quotas</a></h5>
<p>Each Firecracker microVM can be further encapsulated into a cgroup. By setting the
affinity of the Firecracker microVM to a node via the cpuset subsystem, one
can prevent the migration of said microVM from one node to another, something
that would impair performance and cause unnecessary contention on shared
resources. In addition to setting the affinity, each Firecracker microVM can
have its own dedicated quota of the CPU time via the cpu subsystem, thus
guaranteeing that resources are fairly shared across Firecracker microVMs.</p>
<h3 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h3>
<p>Firecracker emits logs and metric counters, each on a named pipe that is passed
via the API. Logs are flushed line by line, whereas metrics are emitted when the
instance starts, then every 60 seconds while it's running, and on panic.
Firecracker customers are responsible for collecting data in the Firecracker
log files. In production builds, Firecracker does not expose the serial console
port, since it may contain guest data that the host should not see.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="production-host-setup-recommendations"><a class="header" href="#production-host-setup-recommendations">Production Host Setup Recommendations</a></h1>
<p>Firecracker relies on KVM and on the processor virtualization features for
workload isolation. The host and guest kernels and host microcode must be
regularly patched in accordance with your distribution's security advisories
such as <a href="https://alas.aws.amazon.com/alas2023.html">ALAS</a> for Amazon Linux.</p>
<p>Security guarantees and defense in depth can only be upheld, if the following
list of recommendations are implemented in production.</p>
<h2 id="firecracker-configuration"><a class="header" href="#firecracker-configuration">Firecracker Configuration</a></h2>
<h3 id="seccomp-1"><a class="header" href="#seccomp-1">Seccomp</a></h3>
<p>Firecracker uses
<a href="https://www.kernel.org/doc/Documentation/prctl/seccomp_filter.txt">seccomp</a>
filters to limit the system calls allowed by the host OS to the required
minimum.</p>
<p>By default, Firecracker uses the most restrictive filters, which is the
recommended option for production usage.</p>
<p>Production usage of the <code>--seccomp-filter</code> or <code>--no-seccomp</code> parameters is not
recommended.</p>
<h3 id="8250-serial-device"><a class="header" href="#8250-serial-device">8250 Serial Device</a></h3>
<p>Firecracker implements the 8250 serial device, which is visible from the guest
side and is tied to the Firecracker/non-daemonized jailer process stdout.
Without proper handling, because the guest has access to the serial device,
this can lead to unbound memory or storage usage on the host side. Firecracker
does not offer users the option to limit serial data transfer, nor does it
impose any restrictions on stdout handling. Users are responsible for handling
the memory and storage usage of the Firecracker process stdout. We suggest
using any upper-bounded forms of storage, such as fixed-size or ring buffers,
using programs like <code>journald</code> or <code>logrotate</code>, or redirecting to <code>/dev/null</code>
or a named pipe. Furthermore, we do not recommend that users enable the serial
device in production. To disable it in the guest kernel, use the
<code>8250.nr_uarts=0</code> boot argument when configuring the boot source. Please be
aware that the device can be reactivated from within the guest even if it was
disabled at boot.</p>
<p>If Firecracker's <code>stdout</code> buffer is non-blocking and full (assuming it has a
bounded size), any subsequent writes will fail, resulting in data loss, until
the buffer is freed.</p>
<h3 id="log-files"><a class="header" href="#log-files">Log files</a></h3>
<p>Firecracker outputs logging data into a named pipe, socket, or file using the
path specified in the <code>log_path</code> field of logger configuration. Firecracker can
generate log data as a result of guest operations and therefore the guest can
influence the volume of data written in the logs. Users are responsible
for consuming and storing this data safely. We suggest using any upper-bounded
forms of storage, such as fixed-size or ring buffers, programs like <code>journald</code>
or <code>logrotate</code>, or redirecting to a named pipe.</p>
<h3 id="logging-and-performance"><a class="header" href="#logging-and-performance">Logging and performance</a></h3>
<p>We recommend adding <code>quiet loglevel=1</code> to the host kernel command line to limit
the number of messages written to the serial console. This is because some host
configurations can have an effect on Firecracker's performance as the process
will generate host kernel logs during normal operations.</p>
<p>The most recent example of this was the addition of <code>console=ttyAMA0</code> host
kernel command line argument on one of our testing setups. This enabled console
logging, which degraded the snapshot restore time from 3ms to 8.5ms on
<code>aarch64</code>. In this case, creating the tap device for snapshot restore
generated host kernel logs, which were very slow to write.</p>
<h3 id="logging-and-signal-handlers"><a class="header" href="#logging-and-signal-handlers">Logging and signal handlers</a></h3>
<p>Firecracker installs custom signal handlers for some of the POSIX signals, such
as SIGSEGV, SIGSYS, etc.</p>
<p>The custom signal handlers used by Firecracker are not async-signal-safe, since
they write logs and flush the metrics, which use locks for synchronization.
While very unlikely, it is possible that the handler will intercept a signal on
a thread which is already holding a lock to the log or metrics buffer.
This can result in a deadlock, where the specific Firecracker thread becomes
unresponsive.</p>
<p>While there is no security impact caused by the deadlock, we recommend that
customers have an overwatcher process on the host, that periodically looks
for Firecracker processes that are unresponsive, and kills them, by SIGKILL.</p>
<h2 id="jailer-configuration"><a class="header" href="#jailer-configuration">Jailer Configuration</a></h2>
<p>For assuring secure isolation in production deployments, Firecracker should be
started using the <code>jailer</code> binary that's part of each Firecracker release, or
executed under process constraints equal or more restrictive than those in the jailer.
For more about Firecracker sandboxing please see
<a href="design.html">Firecracker design</a></p>
<p>The Jailer process applies
<a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt">cgroup</a>,
namespace isolation and drops privileges of the Firecracker process.</p>
<p>To set up the jailer correctly, you'll need to:</p>
<ul>
<li>Create a dedicated non-privileged POSIX user and group to run Firecracker
under. Use the created POSIX user and group IDs in Jailer's <code>--uid &lt;uid&gt;</code>
and <code>--gid &lt;gid&gt;</code> flags, respectively. This will run the Firecracker as
the created non-privileged user and group. All file system resources used for
Firecracker should be owned by this user and group. Apply least privilege to
the resource files owned by this user and group to prevent other accounts from
unauthorized file access.
When running multiple Firecracker instances it is recommended that each runs
with its unique <code>uid</code> and <code>gid</code> to provide an extra layer of security for
their individually owned resources in the unlikely case where any one of the
jails is broken out of.</li>
</ul>
<p>Firecracker's customers are strongly advised to use the provided
<code>resource-limits</code> and <code>cgroup</code> functionalities encapsulated within jailer,
in order to control Firecracker's resource consumption in a way that makes
the most sense to their specific workload. While aiming to provide as much
control as possible, we cannot enforce aggressive default constraints
resources such as memory or CPU because these are highly dependent on the
workload type and usecase.</p>
<p>Here are some recommendations on how to limit the process's resources:</p>
<h3 id="disk"><a class="header" href="#disk">Disk</a></h3>
<ul>
<li>
<p><code>cgroup</code> provides a
<a href="https://www.kernel.org/doc/Documentation/cgroup-v1/blkio-controller.txt">Block IO Controller</a>
which allows users to control I/O operations through the following files:</p>
<ul>
<li><code>blkio.throttle.io_serviced</code> - bounds the number of I/Os issued to disk</li>
<li><code>blkio.throttle.io_service_bytes</code> - sets a limit on the number of bytes
transferred to/from the disk</li>
</ul>
</li>
<li>
<p>Jailer's <code>resource-limit</code> provides control on the disk usage through:</p>
<ul>
<li><code>fsize</code> - limits the size in bytes for files created by the process</li>
<li><code>no-file</code> - specifies a value greater than the maximum file
descriptor number that can be opened by the process. If not specified,
it defaults to 4096.</li>
</ul>
</li>
</ul>
<h3 id="memory"><a class="header" href="#memory">Memory</a></h3>
<ul>
<li><code>cgroup</code> provides a
<a href="https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt">Memory Resource Controller</a>
to allow setting upper limits to memory usage:
<ul>
<li><code>memory.limit_in_bytes</code> - bounds the memory usage</li>
<li><code>memory.memsw.limit_in_bytes</code> - limits the memory+swap usage</li>
<li><code>memory.soft_limit_in_bytes</code> -  enables flexible sharing of memory. Under
normal circumstances, control groups are allowed to use as much of the
memory as needed, constrained only by their hard limits set with the
<code>memory.limit_in_bytes</code> parameter. However, when the system detects
memory contention or low memory, control groups are forced to restrict
their consumption to their soft limits.</li>
</ul>
</li>
</ul>
<h3 id="vcpu"><a class="header" href="#vcpu">vCPU</a></h3>
<ul>
<li><code>cgroup</code>’s
<a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cpuacct.txt">CPU Controller</a>
can guarantee a minimum number of CPU shares when a system is busy and
provides CPU bandwidth control through:
<ul>
<li><code>cpu.shares</code> - limits the amount of CPU that each group it is expected to
get. The percentage of CPU assigned is the value of shares divided by the
sum of all shares in all <code>cgroups</code> in the same level</li>
<li><code>cpu.cfs_period_us</code> - bounds the duration in us of each scheduler period,
for bandwidth decisions. This defaults to 100ms</li>
<li><code>cpu.cfs_quota_us</code> - sets the maximum time in microseconds during each
<code>cfs_period_us</code> for which the current group will be allowed to run</li>
<li><code>cpuacct.usage_percpu</code> - limits the CPU time, in ns, consumed by the
process in the group, separated by CPU</li>
</ul>
</li>
</ul>
<p>Additional details of Jailer features can be found in the
<a href="jailer.html">Jailer documentation</a>.</p>
<h2 id="host-security-configuration"><a class="header" href="#host-security-configuration">Host Security Configuration</a></h2>
<h3 id="constrain-cpu-overhead-caused-by-kvm-pit-kernel-threads"><a class="header" href="#constrain-cpu-overhead-caused-by-kvm-pit-kernel-threads">Constrain CPU overhead caused by kvm-pit kernel threads</a></h3>
<p>The current implementation results in host CPU usage increase on x86 CPUs when
a guest injects timer interrupts with the help of kvm-pit kernel thread.
kvm-pit kthread is by default part of the root cgroup.</p>
<p>To mitigate the CPU overhead we recommend two system level configurations.</p>
<ol>
<li>Use an external agent to move the <code>kvm-pit/&lt;pid of firecracker&gt;</code> kernel
thread in the microVM’s cgroup (e.g., created by the Jailer).
This cannot be done by Firecracker since the thread is created by the Linux
kernel after guest start, at which point Firecracker is de-privileged.</li>
<li>Configure the kvm limit to a lower value. This is a system-wide
configuration available to users without Firecracker or Jailer changes.
However, the same limit applies to APIC timer events, and users will need
to test their workloads in order to apply this mitigation.</li>
</ol>
<p>To modify the kvm limit for interrupts that can be injected in a second.</p>
<ol>
<li><code>sudo modprobe -r (kvm_intel|kvm_amd) kvm</code></li>
<li><code>sudo modprobe kvm min_timer_period_us={new_value}</code></li>
<li><code>sudo modprobe (kvm_intel|kvm_amd)</code></li>
</ol>
<p>To have this change persistent across boots we can append the option to
<code>/etc/modprobe.d/kvm.conf</code>:</p>
<p><code>echo &quot;options kvm min_timer_period_us=&quot; &gt;&gt; /etc/modprobe.d/kvm.conf</code></p>
<h3 id="mitigating-network-flooding-issues"><a class="header" href="#mitigating-network-flooding-issues">Mitigating Network flooding issues</a></h3>
<p>Network can be flooded by creating connections and sending/receiving a
significant amount of requests. This issue can be mitigated either by
configuring rate limiters for the network interface as explained within
<a href="api_requests/patch-network-interface.html">Network Interface documentation</a>,
or by using one of the tools presented below:</p>
<ul>
<li><code>tc qdisc</code> - manipulate traffic control settings by configuring filters.</li>
</ul>
<p>When traffic enters a classful qdisc, the filters are consulted and the
packet is enqueued into one of the classes within. Besides
containing other qdiscs, most classful qdiscs perform rate control.</p>
<ul>
<li><code>netnamespace</code> and <code>iptables</code>
<ul>
<li><code>--pid-owner</code> -  can be used to match packets based on the PID that was
responsible for them</li>
<li><code>connlimit</code> - restricts the number of connections for a destination IP
address/from a source IP address, as well as limit the bandwidth</li>
</ul>
</li>
</ul>
<h3 id="mitigating-noisy-neighbour-storage-device-contention"><a class="header" href="#mitigating-noisy-neighbour-storage-device-contention">Mitigating Noisy-Neighbour Storage Device Contention</a></h3>
<p>Data written to storage devices is managed in Linux with a page cache.
Updates to these pages are written through to their mapped storage
devices asynchronously at the host operating system's discretion.
As a result, high storage output can result in this cache being
filled quickly resulting in a backlog which can slow down I/O of
other guests on the host.</p>
<p>To protect the resource access of the guests, make sure to tune each Firecracker
process via the following tools:</p>
<ul>
<li><a href="jailer.html">Jailer</a>: A wrapper environment designed to contain Firecracker
and strictly control what the process and its guest has
access to. Take note of the
<a href="jailer.html#jailer-operation">jailer operations guide</a>,
paying particular note to the <code>--resource-limit</code> parameter.</li>
<li>Rate limiting: Rate limiting functionality is supported for both networking
and storage devices and is configured by the operator of the
environment that launches the Firecracker process and its
associated guest.
See the <a href="api_requests/patch-block.html">block device documentation</a>
for examples of calling the API to configure rate limiting.</li>
</ul>
<h3 id="disabling-swapping-to-disk-or-enabling-secure-swap"><a class="header" href="#disabling-swapping-to-disk-or-enabling-secure-swap">Disabling swapping to disk or enabling secure swap</a></h3>
<p>Memory pressure on a host can cause memory to be written to drive storage when
swapping is enabled. Disabling swap mitigates data remanence issues related to
having guest memory contents on microVM storage devices.</p>
<p>Verify that swap is disabled by running:</p>
<pre><code class="language-bash">grep -q &quot;/dev&quot; /proc/swaps &amp;&amp; \
echo &quot;swap partitions present (Recommendation: no swap)&quot; \
|| echo &quot;no swap partitions (OK)&quot;
</code></pre>
<h3 id="mitigating-hardware-vulnerabilities"><a class="header" href="#mitigating-hardware-vulnerabilities">Mitigating hardware vulnerabilities</a></h3>
<blockquote>
<p><strong>Note</strong> Firecracker is not able to mitigate host's hardware vulnerabilities.
Adequate mitigations need to be put in place when configuring the host.</p>
</blockquote>
<blockquote>
<p><strong>Note</strong> Firecracker is designed to provide isolation boundaries between
microVMs running in different Firecracker processes. It is strongly recommended
that each Firecracker process corresponds to a workload of a single tenant.</p>
</blockquote>
<blockquote>
<p><strong>Note</strong> For security and stability reasons it is highly recommended to load
updated microcode as soon as possible. Aside from keeping the system firmware
up-to-date, when the kernel is used to load updated microcode of the CPU this
should be done as early as possible in the boot process.</p>
</blockquote>
<h4 id="side-channel-attacks"><a class="header" href="#side-channel-attacks">Side channel attacks</a></h4>
<p>It is strongly recommended that users follow the
<a href="https://docs.kernel.org/admin-guide/hw-vuln/index.html">Linux kernel documentation on hardware vulnerabilities</a>
when configuring mitigations against side channel attacks including &quot;Spectre&quot;
and &quot;Meltdown&quot; attacks
(see <a href="https://docs.kernel.org/arch/x86/pti.html">Page Table Isolation</a>
and <a href="https://docs.kernel.org/userspace-api/spec_ctrl.html">Speculation Control</a>).</p>
<p>Additionally users should consider disabling
<a href="https://www.kernel.org/doc/html/latest/admin-guide/mm/ksm.html">Kernel Samepage Merging</a>
to mitigate <a href="https://eprint.iacr.org/2013/448.pdf">side channel issues</a>
relying on the page deduplication for revealing what memory pages are
accessed by another process.</p>
<h5 id="use-memory-with-rowhammer-mitigation-support"><a class="header" href="#use-memory-with-rowhammer-mitigation-support">Use memory with Rowhammer mitigation support</a></h5>
<p>Rowhammer is a memory side-channel issue that can lead to unauthorized cross-
process memory changes.</p>
<p>Using DDR4 memory that supports Target Row Refresh (TRR) with error-correcting
code (ECC) is recommended. Use of pseudo target row refresh (pTRR) for systems
with pTRR-compliant DDR3 memory can help mitigate the issue, but it also
incurs a performance penalty.</p>
<h5 id="vendor-specific-recommendations"><a class="header" href="#vendor-specific-recommendations">Vendor-specific recommendations</a></h5>
<p>For vendor-specific recommendations, please consult the resources below:</p>
<ul>
<li>Intel: <a href="https://www.intel.com/content/www/us/en/developer/topic-technology/software-security-guidance/overview.html">Software Security Guidance</a></li>
<li>AMD: <a href="https://www.amd.com/en/resources/product-security.html">AMD Product Security</a></li>
<li>ARM: <a href="https://developer.arm.com/support/arm-security-updates/speculative-processor-vulnerability">Speculative Processor Vulnerability</a></li>
</ul>
<h5 id="arm-only-physical-counter-directly-passed-through-to-the-guest"><a class="header" href="#arm-only-physical-counter-directly-passed-through-to-the-guest">[ARM only] Physical counter directly passed through to the guest</a></h5>
<p>On ARM, the physical counter (i.e <code>CNTPCT</code>) it is returning the
<a href="https://elixir.free-electrons.com/linux/v4.14.203/source/virt/kvm/arm/hyp/timer-sr.c#L63">actual EL1 physical counter value of the host</a>. From the discussions before
merging this change <a href="https://lists.cs.columbia.edu/pipermail/kvmarm/2017-January/023323.html">upstream</a>, this seems like a conscious design decision
of the ARM code contributors, giving precedence to performance over the ability
to trap and control this in the hypervisor.</p>
<h5 id="verification"><a class="header" href="#verification">Verification</a></h5>
<p><a href="https://github.com/speed47/spectre-meltdown-checker">spectre-meltdown-checker script</a>
can be used to assess host's resilience against several transient execution
CVEs and receive guidance on how to mitigate them.</p>
<p>The script is used in integration tests by the Firecracker team. It can be
downloaded and executed like:</p>
<pre><code class="language-bash"># Read https://meltdown.ovh before running it.
wget -O - https://meltdown.ovh | bash
</code></pre>
<h3 id="linux-61-boot-time-regressions"><a class="header" href="#linux-61-boot-time-regressions">Linux 6.1 boot time regressions</a></h3>
<p>Linux 6.1 introduced some regressions in the time it takes to boot a VM, for the
x86_64 architecture. They can be mitigated depending on the CPU and the version
of cgroups in use.</p>
<h4 id="explanation"><a class="header" href="#explanation">Explanation</a></h4>
<p>The regression happens in the <code>KVM_CREATE_VM</code> ioctl and there are two factors
that cause the issue:</p>
<ol>
<li>In the implementation of the mitigation for the iTLB multihit vulnerability,
KVM creates a worker thread called <code>kvm-nx-lpage-recovery</code>. This thread is
responsible for recovering huge pages split when the mitigation kicks-in. In
the process of creating this thread, KVM calls <code>cgroup_attach_task_all()</code> to
move it to the same cgroup used by the hypervisor thread</li>
<li>In kernel v4.4, upstream converted a cgroup per process read-write semaphore
into a per-cpu read-write semaphore to allow to perform operations across
multiple processes
(<a href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit/?&amp;id=1ed1328792ff46e4bb86a3d7f7be2971f4549f6c">commit</a>).
It was found that this conversion introduced high latency for write paths,
which mainly includes moving tasks between cgroups. This was fixed in kernel
v4.9 by
<a href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit/?&amp;id=3942a9bd7b5842a924e99ee6ec1350b8006c94ec">commit</a>
which chose to favor writers over readers since moving tasks between cgroups
is a common operation for Android. However, In kernel 6.0, upstream decided
to revert back again and favor readers over writers re-introducing the
original behavior of the rw semaphore
(<a href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit/?&amp;id=6a010a49b63ac8465851a79185d8deff966f8e1a">commit</a>).
At the same time, this commit provided an option called favordynmods to favor
writers over readers.</li>
<li>Since the <code>kvm-nx-lpage-recovery</code> thread creation and its cgroup change is done
in the <code>KVM_CREATE_VM</code> call, the high latency we observe in 6.1 is due to the
upstream decision to favor readers over writers for this per-cpu rw
semaphore. While the 4.14 and 5.10 kernels favor writers over readers.</li>
</ol>
<p>The first step is to check if the host is vulnerable to iTLB multihit. Look at
the value of <code>cat /sys/devices/system/cpu/vulnerabilities/itlb_multihit</code>. If it
does says <code>Not affected</code>, the host is not vulnerable and you can apply
mitigation 2, and optionally 1 for best results. Otherwise it is vulnerable and
you can only apply mitigation 1.</p>
<h4 id="mitigation-1-favordynmods"><a class="header" href="#mitigation-1-favordynmods">Mitigation 1: <code>favordynmods</code></a></h4>
<p>The mitigation in this case is to enable <code>favordynmods</code> in cgroupsv1 or
cgroupsv2. This changes the behavior of all cgroups in the host, and makes it
closer to the performance of Linux 5.10 and 4.14.</p>
<p>For cgroupsv2, run this command:</p>
<pre><code class="language-sh">sudo mount -o remount,favordynmods /sys/fs/cgroup
</code></pre>
<p>For cgroupsv1, remounting with <code>favordynmods</code> is not supported, so it has to be
done at boot time, through a kernel command line option<sup class="footnote-reference"><a href="#1">1</a></sup>. Add
<code>cgroup_favordynmods=true</code> to your kernel command line in GRUB. Refer to your
distribution's documentation for where to make this change<sup class="footnote-reference"><a href="#2">2</a></sup></p>
<p><sup class="footnote-reference"><a href="#2">2</a></sup> Look for <code>GRUB_CMDLINE_LINUX</code> in file <code>/etc/default/grub</code> in RPM-based
systems, and <a href="https://wiki.ubuntu.com/Kernel/KernelBootParameters">this doc for
Ubuntu</a>.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>this command line option is still unreleased at the moment of writing, but
will be part of 6.7 and may be backported to 6.1:
<a href="https://lore.kernel.org/lkml/ZR2zsZIung0-mWii@slm.duckdns.org/">https://lore.kernel.org/lkml/ZR2zsZIung0-mWii@slm.duckdns.org/</a></p>
</div>
<h4 id="mitigation-2-kvmnx_huge_pagesnever"><a class="header" href="#mitigation-2-kvmnx_huge_pagesnever">Mitigation 2: <code>kvm.nx_huge_pages=never</code></a></h4>
<p>This mitigation is preferred to the previous one as it is less invasive (it
doesn't affect other cgroups), but it can also be combined with the cgroups
mitigation.</p>
<pre><code class="language-sh">KVM_VENDOR_MOD=$(lsmod |grep -P &quot;^kvm_(amd|intel)&quot; | awk '{print $1}')
sudo modprobe -r $KVM_VENDOR_MOD kvm
sudo modprobe kvm nx_huge_pages=never
sudo modprobe $KVM_VENDOR_MOD
</code></pre>
<p>To validate that the change took effect, the file
<code>/sys/module/kvm/parameters/nx_huge_pages</code> should say <code>never</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-firecracker-network-setup"><a class="header" href="#getting-started-firecracker-network-setup">Getting Started Firecracker Network Setup</a></h1>
<p>This is a very simple quick-start guide to getting a Firecracker guest connected
to the network. If you're using Firecracker in production, or even want to run
multiple guests, you'll need to adapt this setup.</p>
<p><strong>Note</strong>
Currently firecracker supports only TUN/TAP network backend with no multi queue support.</p>
<p>The simple steps in this guide assume that your internet-facing interface is
<code>eth0</code>, you have nothing else using <code>tap0</code> and no other <code>iptables</code> rules.
Check out the <em>Advanced:</em> sections if that doesn't work for you.</p>
<h2 id="on-the-host"><a class="header" href="#on-the-host">On The Host</a></h2>
<p>The first step on the host is to create a <code>tap</code> device:</p>
<pre><code class="language-bash">sudo ip tuntap add tap0 mode tap
</code></pre>
<p>Then you have a few options for routing traffic out of the tap device, through
your host's network interface. One option is NAT, set up like this:</p>
<pre><code class="language-bash">sudo ip addr add 172.16.0.1/24 dev tap0
sudo ip link set tap0 up
sudo sh -c &quot;echo 1 &gt; /proc/sys/net/ipv4/ip_forward&quot;
sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
sudo iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
sudo iptables -A FORWARD -i tap0 -o eth0 -j ACCEPT
</code></pre>
<p><em>Note:</em> The IP of the TAP device should be chosen such that it's not in the same
subnet as the IP address of the host.</p>
<p><em>Advanced:</em> If you are running multiple Firecracker MicroVMs in parallel, or
have something else on your system using <code>tap0</code> then you need to create a <code>tap</code>
for each one, with a unique name.</p>
<p><em>Advanced:</em> You also need to do the <code>iptables</code> set up for each new <code>tap</code>. If
you have <code>iptables</code> rules you care about on your host, you may want to save
those rules before starting.</p>
<pre><code class="language-bash">sudo iptables-save &gt; iptables.rules.old
</code></pre>
<h2 id="setting-up-firecracker"><a class="header" href="#setting-up-firecracker">Setting Up Firecracker</a></h2>
<p>Before starting the guest, configure the network interface using Firecracker's
API:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
  -X PUT 'http://localhost/network-interfaces/eth0' \
  -H 'Accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
      &quot;iface_id&quot;: &quot;eth0&quot;,
      &quot;guest_mac&quot;: &quot;AA:FC:00:00:00:01&quot;,
      &quot;host_dev_name&quot;: &quot;tap0&quot;
    }'
</code></pre>
<p>If you are using a configuration file instead of the API, add a section
to your configuration file like this:</p>
<pre><code class="language-json">&quot;network-interfaces&quot;: [
  {
    &quot;iface_id&quot;: &quot;eth0&quot;,
    &quot;guest_mac&quot;: &quot;AA:FC:00:00:00:01&quot;,
    &quot;host_dev_name&quot;: &quot;tap0&quot;
  }
],
</code></pre>
<p>Alternatively, if you are using firectl, add
--tap-device=tap0/AA:FC:00:00:00:01` to your command line.</p>
<h2 id="in-the-guest"><a class="header" href="#in-the-guest">In The Guest</a></h2>
<p>Once you have booted the guest, bring up networking within the guest:</p>
<pre><code class="language-bash">ip addr add 172.16.0.2/24 dev eth0
ip link set eth0 up
ip route add default via 172.16.0.1 dev eth0
</code></pre>
<p>Now your guest should be able to route traffic to the internet (assuming that
your host can get to the internet). To do anything useful, you probably want
to resolve DNS names. In production, you'd want to use the right DNS server for
your environment. For testing, you can add a public DNS server to
<code>/etc/resolv.conf</code> by adding a line like this:</p>
<pre><code class="language-console">nameserver 8.8.8.8
</code></pre>
<h2 id="advanced-setting-up-a-bridge-interface"><a class="header" href="#advanced-setting-up-a-bridge-interface">[Advanced] Setting Up a Bridge Interface</a></h2>
<h3 id="on-the-host-1"><a class="header" href="#on-the-host-1">On The Host</a></h3>
<ol>
<li>
<p>Create a bridge interface</p>
<pre><code class="language-bash">sudo ip link add name br0 type bridge
</code></pre>
</li>
<li>
<p>Add tap interface <a href="network-setup.html#on-the-host">created above</a> to the bridge</p>
<pre><code class="language-bash">sudo ip link set dev tap0 master br0
</code></pre>
</li>
<li>
<p>Define an IP address in your network for the bridge.</p>
<p>For example, if your gateway were on <code>192.168.1.1</code> and you wanted to use this
for getting dynamic IPs, you would want to give the bridge an unused IP address
in the <code>192.168.1.0/24</code> subnet.</p>
<pre><code class="language-bash">sudo ip address add 192.168.1.7/24 dev br0
</code></pre>
</li>
<li>
<p>Add firewall rules to allow traffic to be routed to the guest</p>
<pre><code class="language-bash">sudo iptables -t nat -A POSTROUTING -o br0 -j MASQUERADE
</code></pre>
</li>
</ol>
<h3 id="on-the-guest"><a class="header" href="#on-the-guest">On The Guest</a></h3>
<ol>
<li>
<p>Define an unused IP address in the bridge's subnet e.g., <code>192.168.1.169/24</code>.</p>
<p><em>Note: Alternatively, you could rely on DHCP for getting a dynamic IP address
from your gateway.</em></p>
<pre><code class="language-bash">ip addr add 192.168.1.169/24 dev eth0
</code></pre>
</li>
<li>
<p>Set the interface up.</p>
<pre><code class="language-bash">ip link set eth0 up
</code></pre>
</li>
<li>
<p>Create a route to the bridge device</p>
<pre><code class="language-bash">ip r add 192.168.1.1 via 192.168.1.7 dev eth0
</code></pre>
</li>
<li>
<p>Create a route to the internet via the bridge</p>
<pre><code class="language-bash">ip r add default via 192.168.1.7 dev eth0
</code></pre>
<p>When done, your route table should look similar to the following:</p>
<pre><code class="language-bash">ip r
default via 192.168.1.7 dev eth0
192.168.1.0/24 dev eth0 scope link
192.168.1.1 via 192.168.1.7 dev eth0
</code></pre>
</li>
<li>
<p>Add your nameserver to <code>resolve.conf</code></p>
<pre><code class="language-bash"># cat /etc/resolv.conf
nameserver 192.168.1.1
</code></pre>
</li>
</ol>
<h2 id="cleaning-up"><a class="header" href="#cleaning-up">Cleaning up</a></h2>
<p>The first step to cleaning up is deleting the tap device:</p>
<pre><code class="language-bash">sudo ip link del tap0
</code></pre>
<p>If you don't have anything else using <code>iptables</code> on your machine, clean up those
rules:</p>
<pre><code class="language-bash">sudo iptables -F
sudo sh -c &quot;echo 0 &gt; /proc/sys/net/ipv4/ip_forward&quot; # usually the default
</code></pre>
<p>If you have an existing iptables setup, you'll want to be more careful about
cleaning up.</p>
<p><em>Advanced:</em> If you saved your iptables rules in the first step, then you can
restore them like this:</p>
<pre><code class="language-bash">if [ -f iptables.rules.old ]; then
    sudo iptables-restore &lt; iptables.rules.old
fi
</code></pre>
<p><em>Advanced:</em> If you created a bridge interface, delete it using the following:</p>
<pre><code class="language-bash">sudo ip link del br0
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firecrackers-kernel-support-policy"><a class="header" href="#firecrackers-kernel-support-policy">Firecracker's Kernel Support Policy</a></h1>
<p>Once officially supported kernel versions are supported for a <strong>minimum of 2 years</strong>.</p>
<p>We are validating the currently supported Firecracker releases as per
<a href="../docs/RELEASE_POLICY.html">Firecracker’s release policy</a>. Starting with release
<code>v1.0</code> each major and minor release will specify the supported kernel versions.
Adding support for a new kernel version will result in a Firecracker release
only if compatibility changes are required.</p>
<p>The guest kernel configs used in our validation pipelines
can be found <a href="../resources/guest_configs/">here</a> while a breakdown
of the relevant guest kernel modules can be found in the next section.</p>
<h2 id="guest-kernel-configuration-items"><a class="header" href="#guest-kernel-configuration-items">Guest kernel configuration items</a></h2>
<p>Some configuration items that may be of interest are:</p>
<ul>
<li>serial console - <code>CONFIG_SERIAL_8250_CONSOLE</code>, <code>CONFIG_PRINTK</code></li>
<li>initrd support - <code>CONFIG_BLK_DEV_INITRD</code></li>
<li>virtio devices - <code>CONFIG_VIRTIO_MMIO</code>
<ul>
<li>balloon - <code>CONFIG_MEMORY_BALLOON</code>, <code>CONFIG_VIRTIO_BALLOON</code></li>
<li>block - <code>CONFIG_VIRTIO_BLK</code>
<ul>
<li>partuuid support - <code>CONFIG_MSDOS_PARTITION</code></li>
</ul>
</li>
<li>network - <code>CONFIG_VIRTIO_NET</code></li>
<li>vsock - <code>CONFIG_VIRTIO_VSOCKETS</code></li>
<li>entropy - <code>CONFIG_HW_RANDOM_VIRTIO</code></li>
</ul>
</li>
<li>guest RNG - <code>CONFIG_RANDOM_TRUST_CPU</code>
<ul>
<li>use CPU RNG instructions (if present) to initialize RNG. Available for &gt;= 5.10</li>
</ul>
</li>
</ul>
<p>There are also guest config options which are dependant on the platform
on which Firecracker is run:</p>
<h3 id="arm"><a class="header" href="#arm">ARM</a></h3>
<ul>
<li>timekeeping - <code>CONFIG_ARM_AMBA</code>, <code>CONFIG_RTC_DRV_PL031</code></li>
<li>serial console - <code>CONFIG_SERIAL_OF_PLATFORM</code></li>
</ul>
<h3 id="x86_64"><a class="header" href="#x86_64">x86_64</a></h3>
<ul>
<li>timekeeping - <code>CONFIG_KVM_GUEST</code> (which enables CONFIG_KVM_CLOCK)</li>
<li>high precision timekeeping - <code>CONFIG_PTP_1588_CLOCK</code>, <code>CONFIG_PTP_1588_CLOCK_KVM</code></li>
<li>external clean shutdown - <code>CONFIG_SERIO_I8042</code>, <code>CONFIG_KEYBOARD_ATKBD</code></li>
<li>virtio devices - <code>CONFIG_VIRTIO_MMIO_CMDLINE_DEVICES</code></li>
</ul>
<h4 id="minimal-boot-requirements"><a class="header" href="#minimal-boot-requirements">Minimal boot requirements</a></h4>
<p>Depending on the source of boot (either from a block device or from an initrd),
the minimal configuration for a guest kernel for a successful microVM boot is:</p>
<ul>
<li>
<p>Booting with initrd:</p>
<ul>
<li><code>CONFIG_BLK_DEV_INITRD=y</code>
<ul>
<li>aarch64 <code>CONFIG_VIRTIO_MMIO=y</code> (for the serial device).</li>
<li>x86_64 <code>CONFIG_KVM_GUEST=y</code>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Booting with root block device:</p>
<ul>
<li>aarch64
<ul>
<li><code>CONFIG_VIRTIO_BLK=y</code></li>
</ul>
</li>
<li>x86_64
<ul>
<li><code>CONFIG_VIRTIO_BLK=y</code></li>
<li><code>CONFIG_VIRTIO_MMIO_CMDLINE_DEVICES=y</code></li>
<li><code>CONFIG_KVM_GUEST=y</code>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><em>Optional</em>: To enable boot logs set <code>CONFIG_SERIAL_8250_CONSOLE=y</code> and
<code>CONFIG_PRINTK=y</code> in the guest kernel config.</p>
<h2 id="caveats"><a class="header" href="#caveats">Caveats</a></h2>
<ul>
<li>When using a 4.14 host and a 5.10 guest, we disable the SVE extension in the
guest. This is due to the introduction of the SVE extension in Graviton3,
which causes the default 5.10 guest (with SVE support enabled), to crash if
run with a 4.14 host which does not support SVE.</li>
<li><a href="snapshotting/snapshot-support.html#snapshot-compatibility-across-kernel-versions">Snapshot compatibility across kernel versions</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="specification"><a class="header" href="#specification">Specification</a></h1>
<p>The specifications below quantify Firecracker's promise to enable
minimal-overhead execution of container and serverless workloads. These
specifications are enforced by integration tests (that run for each PR and
main branch merge).</p>
<p>On an <a href="https://aws.amazon.com/ec2/instance-types/m5/">M5D.metal instance</a> (with hyperthreading disabled) and an
<a href="https://aws.amazon.com/ec2/instance-types/m6/">M6G.metal instance</a> and given host system resources are available
(e.g., there are enough free CPU cycles, there is
enough RAM, etc.), customers can rely on the following:</p>
<ol>
<li><strong>Stability:</strong> The Firecracker virtual machine manager starts (up to API
socket availability) within <code>8 CPU ms</code><sup>1</sup> and never crashes/halts/terminates
for internal reasons once started. <em>Note</em>: The wall-clock time has a large
standard deviation, spanning <code>6 ms to 60 ms</code>, with typical durations around
<code>12 ms</code>.</li>
<li><strong>Failure Information:</strong> When failures occur due to external circumstances,
they are logged<sup>2</sup> by the Firecracker process.</li>
<li><strong>API Stability:</strong> The API socket is always available and the API conforms
to the in-tree
<a href="src/api_server/swagger/firecracker.yaml">Open API specification</a>. API failures
are logged in the Firecracker log.</li>
<li><strong>Overhead:</strong> For a Firecracker virtual machine manager running a microVM
with <code>1 CPUs and 128 MiB of RAM</code>, and a guest OS with the Firecracker-tuned
kernel:
<ul>
<li>
<p>Firecracker's virtual machine manager threads have a memory overhead
<code>&lt;= 5 MiB</code>. The memory overhead is dependent on the <strong>workload</strong> (e.g. a
workload with multiple <a href="docs/vsock.html">vsock</a> connections might generate a
memory overhead &gt; 5MiB) and on the VMM <strong>configuration</strong> (the overhead
does not include the memory used by the <a href="docs/mmds/mmds-design.html">MMDS</a>
data store.</p>
<p>The overhead is tested as part of the Firecracker CI using a
<a href="tests/host_tools/memory.py">memory cop</a>.</p>
</li>
<li>
<p>It takes <code>&lt;= 125 ms</code> to go from receiving the Firecracker InstanceStart
API call to the start of the Linux guest user-space <code>/sbin/init</code> process.
The boot time is measured using a VM with the serial console disabled
and a minimal kernel and root file system. For more details check the
<a href="tests/integration_tests/performance/test_boottime.py">boot time</a>
integration tests.</p>
</li>
<li>
<p>The compute-only guest CPU performance is <code>&gt; 95%</code> of the equivalent
bare-metal performance. <em><code>[integration test pending]</code></em></p>
</li>
</ul>
</li>
<li><strong>IO Performance:</strong> With a host CPU core dedicated to the Firecracker device
emulation thread,
<ul>
<li>the guest achieves up to <code>14.5 Gbps</code> network throughput by using <code>&lt;= 80%</code>
of the host CPU core for emulation. <em><code>[integration test pending]</code></em></li>
<li>the guest achieves up to <code>25 Gbps</code> network throughput by using <code>100%</code>
of the host CPU core for emulation. <em><code>[integration test pending]</code></em></li>
<li>the virtualization layer adds on average <code>0.06ms</code> of latency.
<em><code>[integration test pending]</code></em>
<a href="docs/network-performance.html">See further details on network performance</a></li>
<li>the guest achieves up to <code>1 GiB/s</code> storage throughput by using <code>&lt;= 70%</code>
of the host CPU core for emulation. <em><code>[integration test pending]</code></em></li>
</ul>
</li>
<li><strong>Telemetry:</strong> Firecracker emits logs and metrics to the named pipes passed
to the logging API. Any logs and metrics emitted while their respective
pipes are full will be lost. Any such events will be signaled through the
<code>lost-logs</code> and <code>lost-metrics</code> counters.</li>
</ol>
<p><sup>1</sup> CPU ms are actual ms of a user space thread's on-CPU runtime;
useful for getting consistent measurements for some performance metrics.</p>
<p><sup>2</sup> No logs are currently produced in the span of time between the <code>jailer</code>
process start-up and the logging system initialization in the <code>firecracker</code> process.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firecracker-network-performance-numbers"><a class="header" href="#firecracker-network-performance-numbers">Firecracker network performance numbers</a></h1>
<p>This document provides details about Firecracker network performance.
The numbers presented are dependent on the hardware (CPU, networking card,
etc.), OS version and settings.
Scope of the measurements is to illustrate the limits for the emulation thread.</p>
<h2 id="tcp-throughput"><a class="header" href="#tcp-throughput">TCP Throughput</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Segment size/ Direction</th><th>1460bytes</th><th>256bytes</th><th>128bytes</th><th>96bytes</th></tr></thead><tbody>
<tr><td>Ingress</td><td>25Gbps</td><td>23Gbps</td><td>20Gbps</td><td>18Gbps</td></tr>
<tr><td>Egress</td><td>25Gbps</td><td>23Gbps</td><td>20Gbps</td><td>18Gbps</td></tr>
<tr><td>Bidirectional</td><td>18Gbps</td><td>18Gbps</td><td>18Gbps</td><td>18Gbps</td></tr>
</tbody></table>
</div>
<p><strong>Setup and test description</strong>
Throughput measurements were done using <a href="https://iperf.fr/">iperf3</a>. The target
is to fully saturate the emulation thread and keep it at 100% utilization.
No adjustments were done to socket buffer, or any other network related kernel parameters.</p>
<p>To identify the limit of emulation thread, TCP throughput was measured between
host and guest. An EC2 <a href="https://aws.amazon.com/ec2/instance-types/m5/">M5d.metal</a>
instance, running <a href="https://aws.amazon.com/amazon-linux-ami/">Amazon Linux 2</a>,
was used as a host.</p>
<p>For ingress or egress throughput measurements, a Firecracker microVM running
Kernel 4.14 with 4GB of Ram, 8 vCPUs and one network interface was used.
The measurements were taken using 6 iperf3 clients running on host and 6 iperf3
serves running on guest and vice versa.</p>
<p>For bidirectional throughput measurements, a Firecracker microVM running Amazon
Linux 2, Kernel 4.14 with 4GB of Ram, 12 vCPUs and one network interface was used.
The measurements were taken using 4 iperf3 clients and 4 iperf3 servers running
on both host and guest.</p>
<h2 id="latency"><a class="header" href="#latency">Latency</a></h2>
<p>The virtualization layer, Firecracker emulation thread plus host kernel stack,
is responsible for adding on average 0.06ms of network latency.</p>
<p><strong>Setup and test description</strong>
Latency measurements were done using ping round trip times.
2 x EC2 M5d.metal instances running Amazon Linux 2 within the same<a href="https://aws.amazon.com/vpc/">VPC</a>
were used, with a security group configured so that it would allow traffic
from instances using private IPs. A 10Mbps background traffic was running
between instances.</p>
<p>Round trip time between instances was measured.</p>
<p><code>rtt min/avg/max/mdev = 0.101/0.198/0.237/0.044 ms</code></p>
<p>On one of the instances, a Firecracker microVM running Kernel 4.14, with 1 GB
of RAM, 2 vCPUs, one network interface running was used.
Round trip between the microVM and the other instance was measured, while a
10Mbps background traffic was running.</p>
<p><code>rtt min/avg/max/mdev = 0.191/0.321/0.519/0.058  ms</code></p>
<p>From the difference between those we can conclude that ~0.06ms are the
virtualization overhead.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firecracker-frequently-asked-questions"><a class="header" href="#firecracker-frequently-asked-questions">Firecracker Frequently Asked Questions</a></h1>
<h2 id="about-firecracker"><a class="header" href="#about-firecracker">About Firecracker</a></h2>
<h3 id="what-is-firecracker-2"><a class="header" href="#what-is-firecracker-2">What is Firecracker?</a></h3>
<p>Firecracker is an open source Virtual Machine Monitor (VMM) that
enables secure, multi-tenant, minimal-overhead execution of container
and function workloads.</p>
<h3 id="who-developed-firecracker"><a class="header" href="#who-developed-firecracker">Who developed Firecracker?</a></h3>
<p>Firecracker was built by developers at Amazon Web Services to enable services
such as <a href="https://aws.amazon.com/lambda/">AWS Lambda</a> and <a href="https://aws.amazon.com/fargate/">AWS
Fargate</a> to improve resource utilization and
customer experience, while providing the security and isolation required of
public cloud infrastructure. Firecracker started from Chromium OS's Virtual
Machine Monitor,
<a href="https://github.com/google/crosvm">crosvm</a>, an open
source VMM written in Rust. Today, crosvm and Firecracker have diverged to
serve very different customer needs. <a href="https://github.com/rust-vmm">Rust-vmm</a> is
an open source community where we collaborate with the crosvm maintainers and
other groups and individuals to build and share quality Rust virtualization
components.</p>
<h3 id="why-did-you-develop-firecracker"><a class="header" href="#why-did-you-develop-firecracker">Why did you develop Firecracker?</a></h3>
<p>When we launched Lambda in November of 2014, we were focused on providing a
secure <a href="https://aws.amazon.com/serverless/">serverless</a> experience. At launch we
used per-customer EC2 instances to provide strong security and isolation between
customers. As Lambda grew, we saw the need for technology to provide a highly
secure, flexible, and efficient runtime environment for services like Lambda and
Fargate. Using our experience building isolated EC2 instances with hardware
virtualization technology, we started an effort to build a VMM that was tailored
to integrate with container ecosystems.</p>
<h3 id="what-processors-does-firecracker-support"><a class="header" href="#what-processors-does-firecracker-support">What processors does Firecracker support?</a></h3>
<p>The Firecracker VMM is built to be processor agnostic. Intel, AMD and 64 bit ARM
processors are supported for production workloads.</p>
<p>You can find more details <a href="README.html#supported-platforms">here</a>.</p>
<h3 id="can-firecracker-be-used-within-the-container-ecosystem"><a class="header" href="#can-firecracker-be-used-within-the-container-ecosystem">Can Firecracker be used within the container ecosystem?</a></h3>
<p>Yes. Firecracker is integrated with
<a href="https://github.com/kata-containers/documentation/wiki/Initial-release-of-Kata-Containers-with-Firecracker-support">Kata Containers</a>,
<a href="https://www.weave.works/oss/firekube/">Weave FireKube</a> (via
<a href="https://github.com/weaveworks/ignite">Weave Ignite</a>), and containerd via
<a href="https://github.com/firecracker-microvm/firecracker-containerd">firecracker-containerd</a>.
We welcome contributions that enable Firecracker to integrate naturally with the
container ecosystem and provide more choices in how container workloads are
isolated.</p>
<h3 id="what-is-the-difference-between-firecracker-and-qemu"><a class="header" href="#what-is-the-difference-between-firecracker-and-qemu">What is the difference between Firecracker and QEMU?</a></h3>
<p>Firecracker is an
<a href="https://www.redhat.com/en/blog/all-you-need-know-about-kvm-userspace">alternative to QEMU</a>
that is purpose-built for running serverless functions and containers safely and
efficiently, and nothing more. Firecracker is written in Rust, provides a
minimal required device model to the guest operating system while excluding
non-essential functionality (only 6 emulated devices are available: virtio-net,
virtio-balloon, virtio-block, virtio-vsock, serial console, and a minimal
keyboard controller used only to stop the microVM). This, along with a
streamlined kernel loading process enables a &lt; 125 ms startup time and a &lt; 5
MiB memory footprint. The Firecracker process also provides a RESTful control
API, handles resource rate limiting for microVMs, and provides a microVM
metadata service to enable the sharing of configuration data between the host
and guest.</p>
<h3 id="what-operating-systems-are-supported-by-firecracker"><a class="header" href="#what-operating-systems-are-supported-by-firecracker">What operating systems are supported by Firecracker?</a></h3>
<p>Firecracker supports Linux host and guest operating systems as well as
<a href="http://blog.osv.io/blog/2019/04/19/making-OSv-run-on-firecraker/">OSv</a> guests.
Currently supported host/guest kernel versions can be found in the
<a href="docs/kernel-policy.html">kernel support policy</a>.</p>
<h3 id="what-is-the-open-source-license-for-firecracker"><a class="header" href="#what-is-the-open-source-license-for-firecracker">What is the open source license for Firecracker?</a></h3>
<p>Firecracker is licensed under the Apache License, version 2.0, allowing you to
freely use, copy, and distribute your changes under the terms of your choice.
<a href="https://www.apache.org/licenses/LICENSE-2.0">Read more about Apache 2.0</a>.
Crosvm code sections are licensed under a
<a href="https://opensource.org/licenses/BSD-3-Clause">BSD-3-Clause license</a> that also
allows you to use, copy, and distribute your changes under the terms of your
choice.</p>
<h3 id="how-can-i-contribute"><a class="header" href="#how-can-i-contribute">How can I contribute?</a></h3>
<p>Firecracker is an AWS open source project that encourages contributions from
customers and the developer community. Any contribution is welcome as long as it
aligns with our <a href="CHARTER.html">charter</a>. You can learn more about how to
contribute in <a href="CONTRIBUTING.html">CONTRIBUTING.md</a>. You can chat with others in
the community on the <a href="https://firecracker-microvm.slack.com">Firecracker Slack
workspace</a>.</p>
<h3 id="how-is-firecracker-project-governed"><a class="header" href="#how-is-firecracker-project-governed">How is Firecracker project governed?</a></h3>
<p>The Firecracker <a href="MAINTAINERS.html">team at Amazon Web Services</a> owns project
maintainer responsibilities, permissions to merge pull requests, and the ability
to create new Firecracker releases.</p>
<h2 id="technical-faq--troubleshooting"><a class="header" href="#technical-faq--troubleshooting">Technical FAQ &amp; Troubleshooting</a></h2>
<h3 id="can-i-emulate-a-different-architecture-in-the-guest-than-the-one-on-the-host"><a class="header" href="#can-i-emulate-a-different-architecture-in-the-guest-than-the-one-on-the-host">Can I emulate a different architecture in the guest than the one on the host?</a></h3>
<p>Guest operating systems must be built for the same CPU architecture as the
host on which it will run. Firecracker does not support running microVMs on
any architecture other than the one the host is running on. In other words,
running an OS built for a <code>x86_64</code> on an <code>aarch64</code> system will not work, and
vice versa.</p>
<h3 id="i-tried-using-an-initrd-for-boot-but-it-doesnt-seem-to-be-used-is-initrd-supported"><a class="header" href="#i-tried-using-an-initrd-for-boot-but-it-doesnt-seem-to-be-used-is-initrd-supported">I tried using an initrd for boot but it doesn't seem to be used. Is initrd supported?</a></h3>
<p>Initrds are only recently supported in Firecracker. If your release predates
issue <a href="https://github.com/firecracker-microvm/firecracker/issues/208">#228</a>
being resolved, please update.</p>
<h3 id="firecracker-is-not-showing-any-output-on-the-console"><a class="header" href="#firecracker-is-not-showing-any-output-on-the-console">Firecracker is not showing any output on the console.</a></h3>
<p>In order to debug the issue, check the response of the <code>InstanceStart</code> API
request. Possible responses:</p>
<ul>
<li><strong>Error</strong>: Submit a new issue with the label &quot;Support: Failure&quot;.</li>
<li><strong>Success</strong>: If the boot was successful, you should get a response with 204
as the status code.</li>
</ul>
<p>If you have no output in the console, most likely you will have to update the
kernel command line. By default, Firecracker starts with the serial console
disabled for boot time performance reasons.</p>
<p>Example of a kernel valid command
line that enables the serial console (which goes in the <code>boot_args</code> field of
the <code>/boot-source</code> Firecracker API resource):</p>
<pre><code class="language-console">console=ttyS0 reboot=k panic=1 pci=off nomodule
</code></pre>
<h3 id="how-can-i-configure-multiple-ethernet-devices-through-the-kernel-command-line"><a class="header" href="#how-can-i-configure-multiple-ethernet-devices-through-the-kernel-command-line">How can I configure multiple Ethernet devices through the kernel command line?</a></h3>
<p>The <code>ip=</code> boot param in the linux kernel only actually supports configuring a
single interface. Multiple interfaces can be set up in Firecracker using the
API, but guest IP configuration at boot time through boot arguments can only be
done for a single interface.</p>
<h3 id="my-guest-wall-clock-is-drifting-how-can-i-fix-it"><a class="header" href="#my-guest-wall-clock-is-drifting-how-can-i-fix-it">My guest wall-clock is drifting, how can I fix it?</a></h3>
<p>The canonical solution is to use NTP in your guests.</p>
<p>However, if you want to run Firecracker at scale, we suggest using a PTP emulated
device as the guest's NTP time source so as to minimize network traffic and
resource overhead. With this solution the guests will constantly update time
to stay in sync with host wall-clock. They do so using cheap para-virtualized
calls into kvm ptp instead of actual network NTP traffic.</p>
<p>To be able to do this you need to have a guest kernel compiled with <code>KVM_PTP</code>
support:</p>
<pre><code class="language-console">CONFIG_PTP_1588_CLOCK=y
CONFIG_PTP_1588_CLOCK_KVM=y
</code></pre>
<p>Our <a href="resources/guest_configs">recommended x86_64 guest kernel config</a>
already has these included.</p>
<p>Now <code>/dev/ptp0</code> should be available in the guest. Next you need to configure
<code>/dev/ptp0</code> as a NTP time source.</p>
<p>For example when using <code>chrony</code>:</p>
<ol>
<li>Add <code>refclock PHC /dev/ptp0 poll 3 dpoll -2 offset 0</code> to the chrony conf
file (<code>/etc/chrony/chrony.conf</code>)</li>
<li>Restart the <code>chrony</code> daemon.</li>
</ol>
<p>You can see more info about the <code>refclock</code> parameters
<a href="https://chrony-project.org/doc/3.4/chrony.conf.html#refclock">here</a>.
Adjust them according to your needs.</p>
<h3 id="each-firecracker-opens-20-file-descriptors-is-this-an-issue"><a class="header" href="#each-firecracker-opens-20-file-descriptors-is-this-an-issue">Each Firecracker opens 20+ file descriptors. Is this an issue?</a></h3>
<p>The relatively high FD usage is expected and correct. Firecracker heavily
relies on event file descriptors to drive device emulation.</p>
<h3 id="how-does-network-interface-numbering-work"><a class="header" href="#how-does-network-interface-numbering-work">How does network interface numbering work?</a></h3>
<p>There is no relation between the numbering of the <code>/network-interface</code> API calls
and the number of the network interface in the guest. Rather, it is usually
the order of network interface creation that determines the number in the guest
(but this depends on the distribution).</p>
<p>For example, when you create two network interfaces by calling
<code>/network-interfaces/1</code> and then <code>/network-interfaces/0</code>, it may result in this
mapping:</p>
<pre><code class="language-console">/network-interfaces/1 -&gt; eth0
/network-interfaces/0 -&gt; eth1
</code></pre>
<h3 id="how-can-i-gracefully-reboot-the-guest-how-can-i-gracefully-poweroff-the-guest"><a class="header" href="#how-can-i-gracefully-reboot-the-guest-how-can-i-gracefully-poweroff-the-guest">How can I gracefully reboot the guest? How can I gracefully poweroff the guest?</a></h3>
<p>Firecracker does not implement ACPI and PM devices, therefore operations like
gracefully rebooting or powering off the guest are supported in unconventional ways.</p>
<p>Running the <code>poweroff</code> or <code>halt</code> commands inside a Linux guest will bring it
down but Firecracker process remains unaware of the guest shutdown so it lives
on.</p>
<p>Running the <code>reboot</code> command in a Linux guest will gracefully bring down the guest
system and also bring a graceful end to the Firecracker process.</p>
<p>On <code>x86_64</code> systems, issuing a <code>SendCtrlAltDel</code> action command through the
Firecracker API will generate a <code>Ctrl + Alt + Del</code> keyboard event in the guest
which triggers a behavior identical to running the <code>reboot</code> command. This is,
however, not supported on <code>aarch64</code> systems.</p>
<h3 id="how-can-i-create-my-own-rootfs-or-kernel-images"><a class="header" href="#how-can-i-create-my-own-rootfs-or-kernel-images">How can I create my own rootfs or kernel images?</a></h3>
<p>Check out our <a href="docs/rootfs-and-kernel-setup.html">rootfs and kernel image creation guide</a>.</p>
<h3 id="we-are-seeing-page-allocation-failures-from-firecracker-in-the-dmesg-output"><a class="header" href="#we-are-seeing-page-allocation-failures-from-firecracker-in-the-dmesg-output">We are seeing page allocation failures from Firecracker in the <code>dmesg</code> output.</a></h3>
<p>If you see errors like ...</p>
<pre><code class="language-console">[&lt;TIMESTAMP&gt;] fc_vmm: page allocation failure: order:6, mode:0x140c0c0
(GFP_KERNEL|__GFP_COMP|__GFP_ZERO), nodemask=(null)
[&lt;TIMESTAMP&gt;] fc_vmm cpuset=&lt;GUID&gt; mems_allowed=0
</code></pre>
<p>... then your host is running out of memory. KVM is attempting to do an
allocation of 2^<code>order</code> bytes (in this case, 6) and there aren't sufficient
contiguous pages.</p>
<p>Possible mitigations are:</p>
<ul>
<li>Reduce memory pressure on the host.</li>
<li>Maybe the host has memory but it's too fragmented for the kernel to use. The
allocation above of order 6 means the kernel could not find 2^6
<strong>consecutive</strong> pages. One way to mitigate memory fragmentation is to <a href="https://linuxhint.com/vm_min_free_kbytes_sysctl/">set a
higher value</a> for <code>vm.min_free_kbytes</code>
<ul>
<li>Or investigate other <a href="https://savvinov.com/2019/10/14/memory-fragmentation-the-silent-performance-killer/">mitigations</a></li>
</ul>
</li>
</ul>
<h3 id="how-can-i-configure-and-start-a-microvm-without-sending-api-calls"><a class="header" href="#how-can-i-configure-and-start-a-microvm-without-sending-api-calls">How can I configure and start a microVM without sending API calls?</a></h3>
<p>Passing an optional command line parameter, <code>--config-file</code>, to the Firecracker
process allows this type of configuration. This parameter must be the path to a
file that contains the JSON specification that will be used to configure and start
the microVM. One example of such file can be found at <code>tests/framework/vm_config.json</code>.</p>
<h3 id="firecracker-fails-to-start-and-returns-an-out-of-memory-error"><a class="header" href="#firecracker-fails-to-start-and-returns-an-out-of-memory-error">Firecracker fails to start and returns an Out of Memory error</a></h3>
<p>If the Firecracker process exits with <code>12</code> exit code (<code>Out of memory</code> error),
the root cause is that there is not enough memory on the host to be used by the
Firecracker microVM.</p>
<p>If the microVM was not configured in terms of memory size through an API request,
the host needs to meet the minimum requirement in terms of free memory size,
namely 128 MB of free memory which the microVM defaults to.</p>
<p>This may be related to &quot;We are seeing page allocation failures ...&quot; above. To
validate, run this:</p>
<pre><code class="language-sh">sudo dmesg | grep &quot;page allocation failure&quot;
</code></pre>
<h3 id="firecracker-fails-to-start-and-returns-resource-busy-error"><a class="header" href="#firecracker-fails-to-start-and-returns-resource-busy-error">Firecracker fails to start and returns &quot;Resource busy&quot; error</a></h3>
<p>If another hypervisor like VMware or VirtualBox is running on the host and
locks <code>/dev/kvm</code>, Firecracker process will fail to start with &quot;Resource busy&quot;
error.</p>
<p>This issue can be resolved by terminating the other hypervisor running on the host,
and allowing Firecracker to start.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="creating-custom-rootfs-and-kernel-images"><a class="header" href="#creating-custom-rootfs-and-kernel-images">Creating Custom rootfs and kernel Images</a></h1>
<h2 id="creating-a-kernel-image"><a class="header" href="#creating-a-kernel-image">Creating a kernel Image</a></h2>
<h3 id="manual-compilation"><a class="header" href="#manual-compilation">Manual compilation</a></h3>
<p>Currently, Firecracker supports uncompressed ELF kernel images on x86_64 while on
aarch64 it supports PE formatted images.</p>
<p>Here's a quick step-by-step guide to building your own kernel that Firecracker
can boot:</p>
<ol>
<li>
<p>Get the Linux source code:</p>
<pre><code class="language-bash">git clone https://github.com/torvalds/linux.git linux.git
cd linux.git
</code></pre>
</li>
<li>
<p>Check out the Linux version you want to build (e.g. we'll be using v4.20
here):</p>
<pre><code class="language-bash">git checkout v4.20
</code></pre>
</li>
<li>
<p>You will need to configure your Linux build. You can start from our
recommended  <a href="../resources/guest_configs/">guest kernel configurations</a>
by copying the relevant one to <code>.config</code> (under the Linux sources dir).
You can make interactive config adjustments using:</p>
<pre><code class="language-bash">make menuconfig
</code></pre>
<p><em>Note</em>: there are many ways of building a kernel config file, other than
<code>menuconfig</code>. You are free to use whichever one you choose.</p>
</li>
<li>
<p>Build the kernel image:</p>
<pre><code class="language-bash">arch=$(uname -m)
if [ &quot;$arch&quot; = &quot;x86_64&quot; ]; then
     make vmlinux
elif [ &quot;$arch&quot; = &quot;aarch64&quot; ]; then
     make Image
fi
</code></pre>
</li>
<li>
<p>Upon a successful build, you can find the kernel image under <code>./vmlinux</code>
(for x86) or <code>./arch/arm64/boot/Image</code> (for aarch64).</p>
</li>
</ol>
<p>For a list of currently supported kernel versions, check out the
<a href="kernel-policy.html">kernel support policy</a>.</p>
<h3 id="use-the-provided-recipe"><a class="header" href="#use-the-provided-recipe">Use the provided recipe</a></h3>
<p>The kernel images used in our CI to test Firecracker's features are obtained by
using the recipe inside devtool:</p>
<pre><code class="language-bash">config=&quot;resources/guest_configs/microvm-kernel-x86_64-4.14.config&quot;
./tools/devtool build_kernel -c $config -n 8
</code></pre>
<p>or</p>
<pre><code class="language-bash">config=&quot;resources/guest_configs/microvm-kernel-arm64-4.14.config&quot;
./tools/devtool build_kernel -c $config -n 8
</code></pre>
<p>on an aarch64 machine.</p>
<h2 id="creating-a-rootfs-image"><a class="header" href="#creating-a-rootfs-image">Creating a rootfs Image</a></h2>
<p>A rootfs image is just a file system image, that hosts at least an init system.
For instance, our getting started guide uses an ext4 filesystem image. Note
that, whichever file system you choose to use, support for it will have to be
compiled into the kernel, so it can be mounted at boot time.</p>
<p>In order to obtain an ext4 image that you can use with Firecracker, you have the
following options:</p>
<h3 id="manual-build"><a class="header" href="#manual-build">Manual build</a></h3>
<ol>
<li>
<p>Prepare a properly-sized file. We'll use 50MiB here, but this depends
on how much data you'll want to fit inside:</p>
<pre><code class="language-bash">dd if=/dev/zero of=rootfs.ext4 bs=1M count=50
</code></pre>
</li>
<li>
<p>Create an empty file system on the file you created:</p>
<pre><code class="language-bash">mkfs.ext4 rootfs.ext4
</code></pre>
</li>
</ol>
<p>You now have an empty EXT4 image in <code>rootfs.ext4</code>, so let's prepare to
populate it. First, you'll need to mount this new file system, so you
can easily access its contents:</p>
<pre><code class="language-bash">mkdir /tmp/my-rootfs
sudo mount rootfs.ext4 /tmp/my-rootfs
</code></pre>
<p>The minimal init system would be just an ELF binary, placed at <code>/sbin/init</code>.
The final step in the Linux boot process executes <code>/sbin/init</code> and expects it
to never exit. More complex init systems build on top of this, providing
service configuration files, startup / shutdown scripts for various services,
and many other features.</p>
<p>For the sake of simplicity, let's set up an Alpine-based rootfs, with OpenRC
as an init system. To that end, we'll use the official Docker image for
Alpine Linux:</p>
<ol>
<li>
<p>First, let's start the Alpine container, bind-mounting the EXT4 image
created earlier, to <code>/my-rootfs</code>:</p>
<pre><code class="language-bash">docker run -it --rm -v /tmp/my-rootfs:/my-rootfs alpine
</code></pre>
</li>
<li>
<p>Then, inside the container, install the OpenRC init system, and some basic
tools:</p>
<pre><code class="language-bash">apk add openrc
apk add util-linux
</code></pre>
</li>
<li>
<p>And set up userspace init (still inside the container shell):</p>
<pre><code class="language-bash"># Set up a login terminal on the serial console (ttyS0):
ln -s agetty /etc/init.d/agetty.ttyS0
echo ttyS0 &gt; /etc/securetty
rc-update add agetty.ttyS0 default

# Make sure special file systems are mounted on boot:
rc-update add devfs boot
rc-update add procfs boot
rc-update add sysfs boot

# Then, copy the newly configured system to the rootfs image:
for d in bin etc lib root sbin usr; do tar c &quot;/$d&quot; | tar x -C /my-rootfs; done

# The above command may trigger the following message:
# tar: Removing leading &quot;/&quot; from member names
# However, this is just a warning, so you should be able to
# proceed with the setup process.

for dir in dev proc run sys var; do mkdir /my-rootfs/${dir}; done

# All done, exit docker shell.
exit
</code></pre>
</li>
<li>
<p>Finally, unmount your rootfs image:</p>
<pre><code class="language-bash">sudo umount /tmp/my-rootfs
</code></pre>
</li>
</ol>
<h3 id="use-the-provided-recipe-1"><a class="header" href="#use-the-provided-recipe-1">Use the provided recipe</a></h3>
<p>The disk images used in our CI to test Firecracker's features are obtained by
using the recipe (in a Ubuntu 22.04 host):</p>
<pre><code class="language-bash">./resources/rebuild.sh
</code></pre>
<p>The images resulting using this method are minimized Ubuntu 22.04. Feel free to
adjust the script(s) to suit your use case.</p>
<p>You should now have a kernel image (<code>vmlinux</code>) and a rootfs image
(<code>rootfs.ext4</code>), that you can boot with Firecracker.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="using-the-balloon-device-with-firecracker"><a class="header" href="#using-the-balloon-device-with-firecracker">Using the balloon device with Firecracker</a></h1>
<h2 id="what-is-the-balloon-device"><a class="header" href="#what-is-the-balloon-device">What is the balloon device</a></h2>
<p>A memory balloon device is a virtio device that can be used to reclaim and
give back guest memory through API commands issued by the host. It does this
by allocating memory in the guest, and then sending the
addresses of that memory to the host; the host may then remove that memory at
will. The device is configured through a number of options, and an integer,
which represents the target size of the balloon, in MiB. The options cannot be
changed during operation, but the target size can be changed.</p>
<p>The behaviour of the balloon is the following: while the actual size of the
balloon (i.e. the memory it has allocated) is smaller than the target size,
it continually tries to allocate new memory -- if it fails, it prints an
error message (<code>Out of puff! Can't get %d pages</code>), sleeps for 0.2 seconds, and
then tries again. While the actual size of the balloon is larger than the
target size, it will free memory until it hits the target size.</p>
<p>The device can be configured with the following options:</p>
<ul>
<li><code>deflate_on_oom</code>: if this is set to <code>true</code> and a guest process wants to
allocate some memory which would make the guest enter an out-of-memory state,
the kernel will take some pages from the balloon and give them to said
process instead asking the OOM killer process to kill some processes to free
memory. Note that this applies to physical page allocations in the kernel
which belong to guest processes. This does not apply to instances when the
kernel needs memory for its activities (i.e. constructing caches), when the
user requests more memory than the currently available to the balloon for
releasing, or when guest processes try to allocate large amounts of memory
that are refused by the guest memory manager, which is possible when the
guest runs with <code>vm.overcommit_memory=0</code> and the allocation does not pass
the MM basic checks. Setting <code>vm.memory_overcommit</code> to 1 would make the MM
approve all allocations, no matter how large, and using the memory mapped
for those allocations will always deflate the balloon instead of making the
guest enter an OOM state. Note: we do not recommend running with
<code>vm.overcommit_memory=1</code> because it requires complete control over what
allocations are done in the guest and can easily result in unexpected OOM
scenarios.</li>
<li><code>stats_polling_interval_s</code>: unsigned integer value which if set to 0
disables the virtio balloon statistics and otherwise represents the interval
of time in seconds at which the balloon statistics are updated.</li>
</ul>
<h2 id="security-disclaimer"><a class="header" href="#security-disclaimer">Security disclaimer</a></h2>
<p><strong>The balloon device is a paravirtualized virtio device that requires cooperation
from a driver in the guest.</strong></p>
<p>In normal conditions, the balloon device will:</p>
<ul>
<li>not change the target size, which is set directly by the host</li>
<li>consume exactly as many pages as required to achieve the target size</li>
<li>correctly update the value of the actual size of the balloon seen by the host</li>
<li>not use pages that were previously inflated if they were not returned to the
guest via a deflate operation (unless the <code>deflate_on_oom</code> flag was set and the
guest is in an out of memory state)</li>
<li>provide correct statistics when available</li>
</ul>
<p>However, Firecracker does not and cannot introspect into the guest to check the
integrity of the balloon driver. As the guest is not trusted, if the driver in
the guest becomes compromised, the above statements are
<strong>no longer guaranteed</strong>.</p>
<p>This means that even though users use the balloon to impose restrictions on
memory usage, they can be broken by a compromised driver in the guest. The
balloon device operates on a best effort model and users should always ensure
the host is prepared to handle a situation in which the Firecracker process
uses all of the memory it was given at boot even if the balloon was used to
restrict the amount of memory available to the guest. It is also the users'
responsibility to monitor the memory consumption of the VM and, in case
unexpected increases in memory usage are observed, we recommend the following
options:</p>
<ul>
<li>migrate the VM to a machine with higher memory availability through
snapshotting at the cost of disrupting the workload;</li>
<li>kill the Firecracker process that exceeds memory restrictions;</li>
<li>enable swap with a sufficient amount of memory to handle the demand at the
cost of memory access speed;</li>
</ul>
<p>Users should also never rely solely on the statistics provided by the balloon
when controlling the Firecracker process as they are provided directly by the
guest driver and should always be viewed as an indication rather than a
guarantee of what the memory state looks like in the guest.</p>
<p>Please note that even in the case where the driver is not working properly,
the balloon will never leak memory from one Firecracker process to another,
nor can a guest within Firecracker access information in memory outside its
own guest memory. In other words, memory cannot leak in or out of Firecracker
if the driver becomes corrupted. This is guaranteed by the fact that the page
frame numbers coming from the driver are checked to be inside the guest
memory, then <code>madvise</code>d with the <code>MADV_DONTNEED</code> flag, which breaks the
mappings between host physical memory (where the information is ultimately
stored) and Firecracker virtual memory, which is what Firecracker uses to
build the guest memory. On subsequent accesses on previously <code>madvise</code>d
memory addresses, the memory is zeroed. Furthermore, the guest memory is
<code>mmap</code>ped with the <code>MAP_PRIVATE</code> and <code>MAP_ANONYMOUS</code> flags, which ensure that
even if a Firecracker yields some information through an inflate and that
same physical page containing the information is mapped onto another
Firecracker process, reads on that address space will see zeroes.</p>
<h2 id="prerequisites-1"><a class="header" href="#prerequisites-1">Prerequisites</a></h2>
<p>To support memory ballooning, you must use a kernel that has the memory
ballooning driver installed (on Linux 4.14.193, the relevant settings are
<code>CONFIG_MEMORY_BALLOON=y</code>, <code>CONFIG_VIRTIO_BALLOON=y</code>). Other than that, only
the requirements mentioned in the <code>getting-started</code> document are needed.</p>
<h2 id="installing-the-balloon-device"><a class="header" href="#installing-the-balloon-device">Installing the balloon device</a></h2>
<p>In order to use a balloon device, you must install it during virtual machine
setup (i.e. before starting the virtual machine). This can be done either
through a PUT request on &quot;/balloon&quot; or by inserting the balloon into the JSON
configuration file given as a command line argument to the Firecracker process.</p>
<p>Here is an example command on how to install the balloon through the API:</p>
<pre><code class="language-console">socket_location=...
amount_mib=...
deflate_on_oom=...
polling_interval=...

curl --unix-socket $socket_location -i \
    -X PUT 'http://localhost/balloon' \
    -H 'Accept: application/json' \
    -H 'Content-Type: application/json' \
    -d &quot;{
        \&quot;amount_mib\&quot;: $amount_mib, \
        \&quot;deflate_on_oom\&quot;: $deflate_on_oom, \
        \&quot;stats_polling_interval_s\&quot;: $polling_interval \
    }&quot;
</code></pre>
<p>To use this, set <code>socket_location</code> to the location of the firecracker socket
(by default, at <code>/run/firecracker.socket</code>. Then, set <code>amount_mib</code>,
<code>deflate_on_oom</code> and <code>stats_polling_interval_s</code> as desired: <code>amount_mib</code>
represents the target size of the balloon, and <code>deflate_on_oom</code> and
<code>stats_polling_interval_s</code> represent the options mentioned before.</p>
<p>To install the balloon via the JSON config file, insert the following JSON
object into your configuration file:</p>
<pre><code class="language-console">&quot;balloon&quot;: {
    &quot;amount_mib&quot;: 0,
    &quot;deflate_on_oom&quot;: false,
    &quot;stats_polling_interval_s&quot;: 1
},
</code></pre>
<p>After installing the balloon device, users can poll the configuration of the
device at any time by sending a GET request on &quot;/balloon&quot;. Here is an example
of such a request:</p>
<pre><code class="language-console">socket_location=...

curl --unix-socket $socket_location -i \
    -X GET 'http://localhost/balloon' \
    -H 'Accept: application/json'
</code></pre>
<p>On success, this request returns a JSON object of the same structure as the
one used to configure the device (via a PUT request on &quot;/balloon&quot;).</p>
<h2 id="operating-the-balloon-device"><a class="header" href="#operating-the-balloon-device">Operating the balloon device</a></h2>
<p>After it has been installed, the balloon device can only be operated via the
API through the following command:</p>
<pre><code class="language-console">socket_location=...
amount_mib=...
polling_interval=...

curl --unix-socket $socket_location -i \
    -X PATCH 'http://localhost/balloon' \
    -H 'Accept: application/json' \
    -H 'Content-Type: application/json' \
    -d &quot;{
        \&quot;amount_mib\&quot;: $amount_mib, \
        \&quot;stats_polling_interval_s\&quot;: $polling_interval \
    }&quot;
</code></pre>
<p>This will update the target size of the balloon to <code>amount_mib</code> and the
statistics polling interval to <code>polling_interval</code>.</p>
<h2 id="virtio-balloon-statistics"><a class="header" href="#virtio-balloon-statistics">Virtio balloon statistics</a></h2>
<p>The statistics are enabled by setting the <code>stats_polling_interval_s</code> field
in the balloon configuration to a non-zero value. If enabled, users can receive
the latest balloon statistics by issuing a GET request on &quot;/balloon&quot;. Here is
an example of such a request:</p>
<pre><code class="language-console">socket_location=...

curl --unix-socket $socket_location -i \
    -X GET 'http://localhost/balloon/statistics' \
    -H 'Accept: application/json'
</code></pre>
<p>The request, if successful, will return a JSON object containing the latest
statistics. The JSON object contains information about the target and actual
sizes of the balloon as well as virtio traditional memory balloon statistics.</p>
<p>The target and actual sizes of the balloon are expressed as follows:</p>
<ul>
<li><code>target_pages</code>: The target size of the balloon, in 4K pages.</li>
<li><code>actual_pages</code>: The number of 4K pages the device is currently holding.</li>
<li><code>target_mib</code>: The target size of the balloon, in MiB.</li>
<li><code>actual_mib</code>: The number of MiB the device is currently holding.</li>
</ul>
<p>These values are taken directly from the config space of the device and are
always up to date, in the sense that they are exactly what the Firecracker
process reads when polling the config space. The <code>actual</code> fields being
accurate are subject to the guest driver working correctly.</p>
<p>As defined in the virtio 1.1 specification, the traditional virtio balloon
device has support for the following statistics:</p>
<ul>
<li><code>VIRTIO_BALLOON_S_SWAP_IN</code>: The amount of memory that has been swapped in
(in bytes).</li>
<li><code>VIRTIO_BALLOON_S_SWAP_OUT</code>: The amount of memory that has been swapped out
to disk (in bytes).</li>
<li><code>VIRTIO_BALLOON_S_MAJFLT</code>: The number of major page faults that have
occurred.</li>
<li><code>VIRTIO_BALLOON_S_MINFLT</code>: The number of minor page faults that have
occurred.</li>
<li><code>VIRTIO_BALLOON_S_MEMFREE</code>: The amount of memory not being used for any
purpose (in bytes).</li>
<li><code>VIRTIO_BALLOON_S_MEMTOT</code>: The total amount of memory available (in bytes).</li>
<li><code>VIRTIO_BALLOON_S_AVAIL</code>: An estimate of how much memory is available (in
bytes) for starting new applications, without pushing the system to swap.</li>
<li><code>VIRTIO_BALLOON_S_CACHES</code>: The amount of memory, in bytes, that can be
quickly reclaimed without additional I/O. Typically these pages are used for
caching files from disk.</li>
<li><code>VIRTIO_BALLOON_S_HTLB_PGALLOC</code>: The number of successful hugetlb page
allocations in the guest.</li>
<li><code>VIRTIO_BALLOON_S_HTLB_PGFAIL</code>: The number of failed hugetlb page allocations
in the guest.</li>
</ul>
<p>The driver is querried for updated statistics every time the amount
of time specified in that field passes. The driver may not provide all the
statistics when querried, in which case the old values of the missing
statistics are preserved.</p>
<p>To change the statistics polling interval, users can sent a PATCH request
on &quot;/balloon/statistics&quot;. Here is an example of such a request:</p>
<pre><code class="language-console">socket_location=...
polling_interval=...

curl --unix-socket $socket_location -i \
    -X PATCH 'http://localhost/balloon' \
    -H 'Accept: application/json' \
    -H 'Content-Type: application/json' \
    -d &quot;{ \&quot;stats_polling_interval_s\&quot;: $polling_interval }&quot;
</code></pre>
<p>This will change the statistics polling interval to <code>polling_interval</code>. Note
that if the balloon was configured without statistics pre-boot, the statistics
cannot be enabled later by providing a <code>polling_interval</code> non-zero value.
Furthermore, if the balloon was configured with statistics pre-boot through a
non-zero <code>stats_polling_interval_s</code> value, the statistics cannot be
disabled through a <code>polling_interval</code> value of zero post-boot.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="publishing-a-new-container-image"><a class="header" href="#publishing-a-new-container-image">Publishing a New Container Image</a></h1>
<h2 id="about-the-container-image"><a class="header" href="#about-the-container-image">About the Container Image</a></h2>
<p>Firecracker uses a <a href="https://www.docker.com/">Docker container</a> to standardize
the build process. This also fixes the build tools and dependencies to specific
versions. Every once in a while, something needs to be updated. To do this, a
new container image needs to be built locally, then published to the <a href="https://aws.amazon.com/ecr/">AWS ECR</a>
registry. The Firecracker CI suite must also be updated to use the new image.</p>
<h2 id="prerequisites-2"><a class="header" href="#prerequisites-2">Prerequisites</a></h2>
<ol>
<li>Access to the
<a href="https://gallery.ecr.aws/firecracker/fcuvm"><code>fcuvm</code> ECR repository</a>.</li>
<li>The <code>docker</code> package installed locally. You should already have this if
you've ever built Firecracker from source.</li>
<li>Access to both an <code>x86_64</code> and <code>aarch64</code> machines to build the container
images.</li>
<li>Ensure <code>aws --version</code> is &gt;=1.17.10.</li>
</ol>
<h2 id="steps"><a class="header" href="#steps">Steps</a></h2>
<h3 id="optional-update-poetrylock"><a class="header" href="#optional-update-poetrylock"><strong>[optional]</strong> Update <code>poetry.lock</code></a></h3>
<p>This step is optional but recommended, to be on top of Python package changes.</p>
<pre><code class="language-sh">./tools/devtool shell --privileged
poetry update --lock --directory tools/devctr/
</code></pre>
<p>This will change <code>poetry.lock</code>, which you can commit with your changes.</p>
<h3 id="x86_64-1"><a class="header" href="#x86_64-1"><code>x86_64</code></a></h3>
<ol>
<li>
<p>Login to the Docker organization in a shell. Make sure that your account has
access to the repository:</p>
<pre><code class="language-bash">aws ecr-public get-login-password --region us-east-1 \
| docker login --username AWS --password-stdin public.ecr.aws
</code></pre>
<p>For non-TTY devices, although not recommended a less secure approach can be
used:</p>
<pre><code class="language-bash">docker login --username AWS --password \
$(aws ecr-public get-login-password --region us-east-1) public.ecr.aws
</code></pre>
</li>
<li>
<p>Navigate to the Firecracker directory. Verify that you have the latest
container image locally.</p>
<pre><code class="language-bash">docker images
REPOSITORY                         TAG     IMAGE ID        CREATED         SIZE
public.ecr.aws/firecracker/fcuvm   v26     8d00deb17f7a    2 weeks ago     2.41GB
</code></pre>
</li>
<li>
<p>Make your necessary changes, if any, to the
<a href="https://docs.docker.com/engine/reference/builder/">Dockerfile</a>. There's
one for all the architectures in the Firecracker source tree.</p>
</li>
<li>
<p>Commit the changes, if any.</p>
</li>
<li>
<p>Build a new container image with the updated Dockerfile.</p>
<pre><code class="language-bash"> tools/devtool build_devctr
</code></pre>
</li>
<li>
<p>Verify that the new image exists.</p>
<pre><code class="language-bash">docker images
REPOSITORY                         TAG       IMAGE ID         CREATED       SIZE
public.ecr.aws/firecracker/fcuvm   latest    1f9852368efb     2 weeks ago   2.36GB
public.ecr.aws/firecracker/fcuvm   v26       8d00deb17f7a     2 weeks ago   2.41GB
</code></pre>
</li>
<li>
<p>Tag the new image with the next available version <code>X</code> and the architecture
you're on. Note that this will not always be &quot;current version in devtool + 1&quot;,
as sometimes that version might already be used on feature branches. Always
check the &quot;Image Tags&quot; on <a href="https://gallery.ecr.aws/firecracker/fcuvm">the fcuvm repository</a>
to make sure you do not accidentally overwrite an existing image.</p>
<p>As a sanity check, run:</p>
<pre><code class="language-bash">docker pull public.ecr.aws/firecracker/fcuvm:vX
</code></pre>
<p>and verify that you get an error message along the lines of</p>
<pre><code>Error response from daemon: manifest for public.ecr.aws/firecracker/fcuvm:vX not
found: manifest unknown: Requested image not found
</code></pre>
<p>This means the version you've chosen does not exist yet, and you are good to go.</p>
<pre><code class="language-bash">docker tag 1f9852368efb public.ecr.aws/firecracker/fcuvm:v27_x86_64

docker images
REPOSITORY                         TAG          IMAGE ID       CREATED
public.ecr.aws/firecracker/fcuvm   latest       1f9852368efb   1 week ago
public.ecr.aws/firecracker/fcuvm   v27_x86_64   1f9852368efb   1 week ago
public.ecr.aws/firecracker/fcuvm   v26          8d00deb17f7a   2 weeks ago
</code></pre>
</li>
<li>
<p>Push the image.</p>
<pre><code class="language-bash">docker push public.ecr.aws/firecracker/fcuvm:v27_x86_64
</code></pre>
</li>
</ol>
<h3 id="aarch64"><a class="header" href="#aarch64"><code>aarch64</code></a></h3>
<p>Login to the <code>aarch64</code> build machine.</p>
<p>Steps 1-4 are identical across architectures, change <code>x86_64</code> to <code>aarch64</code>.</p>
<p>Then continue with the above steps:</p>
<ol>
<li>
<p>Build a new container image with the updated Dockerfile.</p>
<pre><code class="language-bash">tools/devtool build_devctr
</code></pre>
</li>
<li>
<p>Verify that the new image exists.</p>
<pre><code class="language-bash">docker images
REPOSITORY                         TAG        IMAGE ID            CREATED
public.ecr.aws/firecracker/fcuvm   latest     1f9852368efb        2 minutes ago
public.ecr.aws/firecracker/fcuvm   v26        8d00deb17f7a        2 weeks ago
</code></pre>
</li>
<li>
<p>Tag the new image with the next available version <code>X</code> and the architecture
you're on. Note that this will not always be &quot;current version in devtool + 1&quot;,
as sometimes that version might already be used on feature branches. Always
check the &quot;Image Tags&quot; on <a href="https://gallery.ecr.aws/firecracker/fcuvm">the fcuvm repository</a>
to make sure you do not accidentally overwrite an existing image.</p>
<p>As a sanity check, run:</p>
<pre><code class="language-bash">docker pull public.ecr.aws/firecracker/fcuvm:vX
</code></pre>
<p>and verify that you get an error message along the lines of</p>
<pre><code>Error response from daemon: manifest for public.ecr.aws/firecracker/fcuvm:vX not
found: manifest unknown: Requested image not found
</code></pre>
<p>This means the version you've chosen does not exist yet, and you are good to go.</p>
<pre><code class="language-bash">docker tag 1f9852368efb public.ecr.aws/firecracker/fcuvm:v27_aarch64

docker images
REPOSITORY                         TAG            IMAGE ID
public.ecr.aws/firecracker/fcuvm   latest         1f9852368efb
public.ecr.aws/firecracker/fcuvm   v27_aarch64    1f9852368efb
public.ecr.aws/firecracker/fcuvm   v26            8d00deb17f7a
</code></pre>
</li>
<li>
<p>Push the image.</p>
<pre><code class="language-bash">docker push public.ecr.aws/firecracker/fcuvm:v27_aarch64
</code></pre>
</li>
<li>
<p>Create a manifest to point the latest container version to each specialized
image, per architecture.</p>
<pre><code class="language-bash">docker manifest create public.ecr.aws/firecracker/fcuvm:v27 \
    public.ecr.aws/firecracker/fcuvm:v27_x86_64 public.ecr.aws/firecracker/fcuvm:v27_aarch64

docker manifest push public.ecr.aws/firecracker/fcuvm:v27
</code></pre>
</li>
<li>
<p>Update the image tag in the
<a href="https://github.com/firecracker-microvm/firecracker/blob/main/tools/devtool"><code>devtool</code> script</a>.
Commit and push the change.</p>
<pre><code class="language-bash">PREV_TAG=v26
CURR_TAG=v27
sed -i &quot;s%DEVCTR_IMAGE_TAG=\&quot;$PREV_TAG\&quot;%DEVCTR_IMAGE_TAG=\&quot;$CURR_TAG\&quot;%&quot; tools/devtool
</code></pre>
</li>
</ol>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<p>Check out the
<a href="https://github.com/rust-vmm/rust-vmm-container"><code>rust-vmm-container</code> readme</a>
for additional troubleshooting steps and guidelines.</p>
<h3 id="i-cant-push-the-manifest"><a class="header" href="#i-cant-push-the-manifest">I can't push the manifest</a></h3>
<pre><code class="language-bash">docker manifest is only supported when experimental cli features are enabled
</code></pre>
<p>See
<a href="https://medium.com/@mauridb/docker-multi-architecture-images-365a44c26be6">this article</a>
for explanations and fix.</p>
<h3 id="how-to-test-the-image-after-pushing-it-to-the-docker-registry"><a class="header" href="#how-to-test-the-image-after-pushing-it-to-the-docker-registry">How to test the image after pushing it to the Docker registry</a></h3>
<p>Either fetch and run it locally on another machine than the one you used to
build it, or clean up any artifacts from the build machine and fetch.</p>
<pre><code class="language-bash">docker system prune -a

docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE

tools/devtool shell
[Firecracker devtool] About to pull docker image public.ecr.aws/firecracker/fcuvm:v15
[Firecracker devtool] Continue?
</code></pre>
<h3 id="i-dont-have-access-to-the-aws-ecr-registry"><a class="header" href="#i-dont-have-access-to-the-aws-ecr-registry">I don't have access to the AWS ECR registry</a></h3>
<pre><code class="language-bash">docker push public.ecr.aws/firecracker/fcuvm:v27
The push refers to repository [public.ecr.aws/firecracker/fcuvm]
e2b5ee0c4e6b: Preparing
0fbb5fd5f156: Preparing
...
a1aa3da2a80a: Waiting
denied: requested access to the resource is denied
</code></pre>
<p>Only a Firecracker maintainer can update the container image. If you are one,
ask a member of the team to add you to the AWS ECR repository and retry.</p>
<h3 id="i-pushed-the-wrong-tag"><a class="header" href="#i-pushed-the-wrong-tag">I pushed the wrong tag</a></h3>
<p>Tags can be deleted from the <a href="https://aws.amazon.com/ecr/">AWS ECR interface</a>.</p>
<p>Also, pushing the same tag twice will overwrite the initial content.</p>
<h3 id="i-did-everything-right-and-nothing-works-anymore"><a class="header" href="#i-did-everything-right-and-nothing-works-anymore">I did everything right and nothing works anymore</a></h3>
<p>If you see unrelated <code>Python</code> errors, it's likely because the dev container
pulls <code>Python 3</code> at build time. <code>Python 3</code> means different minor versions on
different platforms, and is not backwards compatible. So it's entirely possible
that <code>docker build</code> has pulled in unwanted <code>Python</code> dependencies.</p>
<p>To include <strong>only your</strong> changes, an alternative to the method described above
is to make the changes <em>inside</em> the container, instead of in the <code>Dockerfile</code>.</p>
<p>Let's say you want to update
<a href="https://github.com/RustSec/cargo-audit"><code>cargo-audit</code></a> (random example).</p>
<ol>
<li>
<p>Enter the container as <code>root</code>.</p>
<pre><code class="language-bash">tools/devtool shell -p
</code></pre>
</li>
<li>
<p>Make the changes locally. Do not exit the container.</p>
<pre><code class="language-bash">cargo install cargo-audit --force
</code></pre>
</li>
<li>
<p>Find your running container.</p>
<pre><code class="language-bash">docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED
e9f0487fdcb9        fcuvm:v14       &quot;bash&quot;              53 seconds ago
</code></pre>
</li>
<li>
<p>Commit the modified container to a new image. Use the <code>container ID</code>.</p>
<pre><code class="language-bash">docker commit e9f0487fdcb9 fcuvm:v15_x86_64
</code></pre>
<pre><code class="language-bash">docker image ls
REPOSITORY      TAG                 IMAGE ID            CREATED
fcuvm           v15_x86_64          514581e654a6        18 seconds ago
fcuvm           v14                 c8581789ead3        2 months ago
</code></pre>
</li>
<li>
<p>Repeat for <code>aarch64</code>.</p>
</li>
<li>
<p>Create and push the manifest.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="device"><a class="header" href="#device">Device</a></h1>
<p>The Device-API following functionality matrix indicates which devices are
required for an API call to be usable.</p>
<p><strong>O</strong> - Optional: The device (column) <strong>is not required</strong> for a Firecracker
microVM API call to succeed. If the device (column) is omitted from a uVM
definition, a call to one of the <a href="device-api.html#api-endpoints">API Endpoints</a> will succeed.</p>
<p><strong>R</strong> - Required: The device (column) <strong>is required</strong> for a Firecracker microVM
API call to succeed. If the device (column) is omitted from a uVM definition,
a call to one of the <a href="device-api.html#api-endpoints">API Endpoints</a> will fail with a
400 - BadRequest - HTTP response.</p>
<h2 id="api-endpoints"><a class="header" href="#api-endpoints">API Endpoints</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Endpoint</th><th style="text-align: center">keyboard</th><th style="text-align: center">serial console</th><th style="text-align: center">virtio-block</th><th style="text-align: center">vhost-user-block</th><th style="text-align: center">virtio-net</th><th style="text-align: center">virtio-vsock</th><th style="text-align: center">virtio-rng</th></tr></thead><tbody>
<tr><td><code>boot-source</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>cpu-config</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>drives/{id}</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>logger</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>machine-config</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>metrics</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>mmds</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>mmds/config</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>network-interfaces/{id}</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>snapshot/create</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>snapshot/load</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>vm</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>vsock</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>entropy</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td></tr>
</tbody></table>
</div>
<h2 id="input-schema"><a class="header" href="#input-schema">Input Schema</a></h2>
<p>All input schema fields can be found in the <a href="https://swagger.io">Swagger</a>
specification: <a href="./../src/api_server/swagger/firecracker.yaml">firecracker.yaml</a>.</p>
<div class="table-wrapper"><table><thead><tr><th>Schema</th><th>Property</th><th style="text-align: center">keyboard</th><th style="text-align: center">serial console</th><th style="text-align: center">virtio-block</th><th style="text-align: center">vhost-user-block</th><th style="text-align: center">virtio-net</th><th style="text-align: center">virtio-vsock</th><th style="text-align: center">virtio-rng</th></tr></thead><tbody>
<tr><td><code>BootSource</code></td><td>boot_args</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>initrd_path</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>kernel_image_path</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>CpuConfig</code></td><td>cpuid_modifiers</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>msr_modifiers</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>reg_modifiers</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>CpuTemplate</code></td><td>enum</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>CreateSnapshotParams</code></td><td>mem_file_path</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>snapshot_path</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>snapshot_type</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>version</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>Drive</code></td><td>drive_id *</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>is_read_only</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>is_root_device *</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>partuuid *</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>path_on_host</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>rate_limiter</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>socket</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>InstanceActionInfo</code></td><td>action_type</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>LoadSnapshotParams</code></td><td>enable_diff_snapshots</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>mem_file_path</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>mem_backend</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>snapshot_path</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>resume_vm</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>Logger</code></td><td>level</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>log_path</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>show_level</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>show_log_origin</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>MachineConfiguration</code></td><td>cpu_template</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>smt</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>mem_size_mib</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>track_dirty_pages</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>vcpu_count</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>Metrics</code></td><td>metrics_path</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>MmdsConfig</code></td><td>network_interfaces</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>version</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>ipv4_address</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>NetworkInterface</code></td><td>guest_mac</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>host_dev_name</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>iface_id</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>rx_rate_limiter</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>tx_rate_limiter</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>PartialDrive</code></td><td>drive_id</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>path_on_host</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>PartialNetworkInterface</code></td><td>iface_id</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>rx_rate_limiter</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>tx_rate_limiter</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>RateLimiter</code></td><td>bandwidth</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>ops</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>TokenBucket</code> **</td><td>one_time_burst</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>refill_time</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>size</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>TokenBucket</code> **</td><td>one_time_burst</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>refill_time</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>size</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>Vm</code></td><td>state</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>Vsock</code></td><td>guest_cid</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td></tr>
<tr><td></td><td>uds_path</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td></tr>
<tr><td></td><td>vsock_id</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td></tr>
<tr><td><code>EntropyDevice</code></td><td>rate_limiter</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center"><strong>R</strong></td></tr>
</tbody></table>
</div>
<p>* <code>Drive</code>'s <code>drive_id</code>, <code>is_root_device</code> and <code>partuuid</code> can be configured
by either virtio-block or vhost-user-block devices.</p>
<p>** The <code>TokenBucket</code> can be configured with any combination of
virtio-net, virtio-block and virtio-rng devices.</p>
<h2 id="output-schema"><a class="header" href="#output-schema">Output Schema</a></h2>
<p>All output schema fields can be found in the <a href="https://swagger.io">Swagger</a>
specification: <a href="./../src/api_server/swagger/firecracker.yaml">firecracker.yaml</a>.</p>
<div class="table-wrapper"><table><thead><tr><th>Schema</th><th>Property</th><th style="text-align: center">keyboard</th><th style="text-align: center">serial console</th><th style="text-align: center">virtio-block</th><th style="text-align: center">vhost-user-block</th><th style="text-align: center">virtio-net</th><th style="text-align: center">virtio-vsock</th></tr></thead><tbody>
<tr><td><code>Error</code></td><td>fault_message</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>InstanceInfo</code></td><td>app_name</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>id</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>state</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>vmm_version</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>MachineConfiguration</code></td><td>cpu_template</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>smt</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>mem_size_mib</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>track_dirty_pages</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td></td><td>vcpu_count</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
</tbody></table>
</div>
<h2 id="instance-actions"><a class="header" href="#instance-actions">Instance Actions</a></h2>
<p>All instance actions can be found in the <a href="https://swagger.io">Swagger</a>
specification: <a href="./../src/api_server/swagger/firecracker.yaml">firecracker.yaml</a>.</p>
<div class="table-wrapper"><table><thead><tr><th>Action</th><th style="text-align: center">keyboard</th><th style="text-align: center">serial console</th><th style="text-align: center">virtio-block</th><th style="text-align: center">vhost-user-block</th><th style="text-align: center">virtio-net</th><th style="text-align: center">virtio-vsock</th></tr></thead><tbody>
<tr><td><code>FlushMetrics</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>InstanceStart</code></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
<tr><td><code>SendCtrlAltDel</code></td><td style="text-align: center"><strong>R</strong></td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td><td style="text-align: center">O</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="using-the-firecracker-entropy-device"><a class="header" href="#using-the-firecracker-entropy-device">Using the Firecracker entropy device</a></h1>
<h2 id="what-is-the-entropy-device"><a class="header" href="#what-is-the-entropy-device">What is the entropy device</a></h2>
<p>An entropy device is a <a href="https://docs.oasis-open.org/virtio/virtio/v1.2/cs01/virtio-v1.2-cs01.html#x1-3050004"><code>virtio-rng</code> device</a> that provides guests with
&quot;high-quality randomness for guest use&quot;. Guests issue requests in the form of a
buffer that will be filled with random bytes from the device. The source of
random bytes that the device will use to fill the buffers is an implementation
decision.</p>
<p>On the guest side, the kernel uses random bytes received through the device
as an extra source of entropy. Moreover, the guest VirtIO driver exposes the
<code>/dev/hwrng</code> character device. User-space applications can use this device to
request random bytes from the device.</p>
<h2 id="firecracker-implementation"><a class="header" href="#firecracker-implementation">Firecracker implementation</a></h2>
<p>Firecracker offers the option of attaching a single <code>virtio-rng</code> device. Users
can configure it through the <code>/entropy</code> API endpoint. The request body includes
a single (optional) parameter for configuring a rate limiter.</p>
<p>For example, users can configure the entropy device with a bandwidth rate
limiter of 10KB/sec like this:</p>
<pre><code class="language-console">curl --unix-socket $socket_location -i \
    -X PUT 'http://localhost/entropy' \
    -H 'Accept: application/json' \
    -H 'Content-Type: application/json' \
    -d &quot;{
        \&quot;rate_limiter\&quot;: {
            \&quot;bandwidth\&quot;: {
                \&quot;size\&quot;: 1000,
                \&quot;one_time_burst\&quot;: 0,
                \&quot;refill_time\&quot;: 100
            }
        }
    }&quot;
</code></pre>
<p>If a configuration file is used for configuring a microVM, the same setup can
be achieved by adding a section like this:</p>
<pre><code class="language-json">&quot;entropy&quot;: {
    &quot;rate_limiter&quot;: {
        &quot;bandwidth&quot; {
            &quot;size&quot;: 1000,
            &quot;one_time_burst&quot;: 0,
            &quot;refill_time&quot;: 100
        }
    }
}
</code></pre>
<p>On the host side, Firecracker relies on <a href="https://docs.rs/aws-lc-rs/latest/aws_lc_rs/index.html"><code>aws-lc-rs</code></a> to retrieve the random bytes.
<code>aws-lc-rs</code> uses the <a href="https://github.com/aws/aws-lc"><code>AWS-LC</code> cryptographic library</a>.</p>
<h2 id="prerequisites-3"><a class="header" href="#prerequisites-3">Prerequisites</a></h2>
<p>In order to use the entropy device, users must use a kernel with the
<code>virtio-rng</code> front-end driver compiled in or loaded as a module. The relevant
kernel configuration option is <code>CONFIG_HW_RANDOM_VIRTIO</code> (which depends on
<code>CONFIG_HW_RANDOM</code> and <code>CONFIG_VIRTIO</code>).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="formal-verification-in-firecracker"><a class="header" href="#formal-verification-in-firecracker">Formal Verification in Firecracker</a></h1>
<p>According to Firecracker’s <a href="https://github.com/firecracker-microvm/firecracker/blob/main/docs/design.md#threat-containment">threat
model</a>,
all vCPUs are considered to be running potentially malicious code from the
moment they are started. This means Firecracker can make no assumptions about
well-formedness of data passed to it by the guest, and have to operate <em>safely</em>
no matter what input it is faced with. Traditional testing methods alone cannot
guarantee about the general absence of safety issues, as for this we would need
to write and run every possible unit test, exercising every possible code path -
a prohibitively large task.</p>
<p>To partially address these limitations, Firecracker is additionally using
formal verification to go further in verifying that safety issues such as
buffer overruns, panics, use-after-frees or integer overflows cannot occur
in critical components. We employ
<a href="https://github.com/model-checking/kani/">Kani</a>, a formal verification tool
written specifically for Rust, which allows us to express functional properties
(such as any user-specified assertion) in familiar Rust-style by replacing
concrete values in unit tests with <code>kani::any()</code>. For more details on how Kani
works, and what properties it can verify, check out its official <a href="https://model-checking.github.io/kani/">Kani
book</a> or try out this
<a href="https://model-checking.github.io/kani/kani-tutorial.html">tutorial</a>.</p>
<p>We aim to have Kani harnesses for components that directly interact with data
from the guest, such as the TCP/IP stack powering our microVM Metadata Service
(MMDS) integration, or which are difficult to test traditionally, such as our
I/O Rate Limiter. Our Kani harnesses live in <code>verification</code> modules that are
tagged with <code>#[cfg(kani)]</code>, similar to how unit tests in Rust are usually
structured.</p>
<p>Note that for some harnesses, Kani uses a “bounded” approach, where the inputs
are restricted based on some assumptions (e.g. the size of an Ethernet frame
being 1514 bytes). <strong>Harnesses are only as strong as the assumptions they make,
so all guarantees from the harness are only valid based on the set of
assumptions we have in our Kani harnesses.</strong> Generally, they should strive to
<em>over-approximate</em>, meaning it is preferred they cover some “impossible”
situations instead of making too strong assumptions that cause them to
exclude realistic scenarios.</p>
<h2 id="how-to-run-kani-harnesses"><a class="header" href="#how-to-run-kani-harnesses">How to run Kani harnesses</a></h2>
<p>To ensure that no incoming code changes cause regressions on formally verified
properties, <strong>all Kani harnesses are run on every pull request in our CI.</strong> To
check whether the harnesses all work for your pull request, check out the
“Kani” <a href="https://buildkite.com/">Buildkite</a> step.</p>
<p>To run our harnesses locally, you can either enter our CI docker container
via <code>./tools/devtool shell -p</code>, or by <a href="https://model-checking.github.io/kani/install-guide.html#installing-the-latest-version">installing
Kani</a>
locally.  Note that the first invocation
of Kani post-installation might take a while, due to it setting up some
dependencies.</p>
<p>Individual harnesses can then be executed using <code>cargo kani</code> similarly to how
<code>cargo test</code> can run individual unit tests, the only difference being that the
harness needs to be specified via <code>--harness</code>. Note, however, that many harnesses
require significant memory, and might result in OOM conditions.</p>
<h2 id="an-example-harness"><a class="header" href="#an-example-harness">An example harness</a></h2>
<p>The following is adapted from our Rate Limiter harness suite. It aims to verify
that creation of a rate-limiting policy upholds all <a href="https://model-checking.github.io/kani/tutorial-kinds-of-failure.html">Kani supported safety
invariants</a>
(which can roughly be summarized as “everything that leads to a panic in a
debug build”), as well as results in a valid policy. A first attempt might look
something like this:</p>
<pre><code>#[kani::proof]
fn verify_token_bucket_new() {
    let token_budget = kani::any();
    let complete_refill_time_ms = kani::any();

    // Checks if the `TokenBucket` is created with invalid inputs, the result
    // is always `None`.
    match TokenBucket::new(token_budget, 0, complete_refill_time_ms) {
        None =&gt; assert!(size == 0 || complete_refill_time_ms == 0),
        Some(bucket) =&gt; assert!(bucket.is_valid()),
    }
}
</code></pre>
<p>The <code>#[kani::proof]</code> attribute tells us that the function is a harness to be
picked up by the Kani compiler. It is the Kani equivalent of <code>#[test]</code>. Lines
3-5 indicate that we want to verify that policy creation works for arbitrarily
sized token buckets and arbitrary refill times. <strong>This is the key difference to
a unit test</strong>, where we would be using concrete values instead (e.g. <code>let token_budget = 10;</code>). Note that Kani will not produce an executable, but
instead <em>statically</em> verifies that code does not violate invariants. We do not
actually execute the creation code for all possible inputs.</p>
<p>The final match statement tells us the property we want to verify, which is
“<em>bucket creation only fails if size of refill time are zero</em>”. In all other
cases, we assert <code>new</code> to give us a valid bucket. We mapped these properties
with assertions. If the verification fails, then that is because one of our
properties do not hold.</p>
<p>Now that we understand the code in the harness, let's try to verify
<code>TokenBucket::new</code> with the Kani!</p>
<p>If we run <code>cargo kani --harness verify_token_bucket_new</code> we will be greeted by</p>
<pre><code>SUMMARY: ** 1 of 147 failed Failed Checks: attempt to multiply with overflow
File: &quot;src/rate_limiter/src/lib.rs&quot;, line 136, in TokenBucket::new

VERIFICATION:- FAILED
Verification Time: 0.21081695s
</code></pre>
<p>In this particular case, Kani has found a safety issue related to an integer
overflow! Due to <code>complete_refill_time_ms</code> getting converted from milliseconds
to nanoseconds in the constructor, we have to take into consideration that the
nanosecond value might not fit into a <code>u64</code> anymore. Here, the finding is
benign, as no one would reasonably configure a <code>ratelimiter</code> with a replenish
time of 599730287.457 <em>years</em>. A <a href="https://github.com/firecracker-microvm/firecracker/commit/0db2a130ca4eeffeca9a46e7b6bd45c1bc1c9e21">quick
check</a>
in the constructor fixes it. However, we will also have to adjust our harness!
Rerunning the harness from above now yields:</p>
<pre><code>SUMMARY: ** 1 of 149 failed Failed Checks: assertion failed: size == 0
                                            || complete_refill_time_ms == 0
File: &quot;src/rate_limiter/src/lib.rs&quot;, line 734, in verification::verify_token_bucket_new

VERIFICATION:- FAILED
Verification Time: 0.21587047s
</code></pre>
<p>This makes sense: There are now more scenarios in which we explicitly fail
construction. Changing our failure property from <code>size == 0 || complete_refill_time_ms == 0</code> to <code>size == 0 || complete_refill_time_ms == 0 || complete_refill_time &gt;= u64::MAX / 1_000_000</code> in the harness will account for
this change, and rerunning the harness will now tell us that no more issues are
found:</p>
<pre><code>SUMMARY: ** 0 of 150 failed

VERIFICATION:- SUCCESSFUL
Verification Time: 0.19135727s
</code></pre>
<h2 id="faq"><a class="header" href="#faq">FAQ</a></h2>
<p><strong>Q:</strong> What is the Kani verifier?<br />
<strong>A:</strong> The <a href="https://github.com/model-checking/kani">Kani Rust
Verifier</a> is a bit-precise model
checker for Rust. Kani is particularly useful for verifying unsafe code blocks
in Rust, where the “<a href="https://doc.rust-lang.org/stable/book/ch19-01-unsafe-rust.html#unsafe-superpowers">unsafe
superpowers</a>&quot;
are unchecked by the compiler.</p>
<p><strong>Q:</strong> What safety properties does Kani verify?<br />
<strong>A:</strong> Kani verifies memory
safety properties (e.g., invalid-pointer dereferences, out-of-bounds array
access), user-specified assertions (i.e., <code>assert!(...)</code>), the absence of
<code>panic!()</code>s (e.g., <code>unwrap()</code> on <code>None</code> values), and the absence of some types of
unexpected behavior (e.g., arithmetic overflows). For a full overview, see the
<a href="https://model-checking.github.io/kani/tutorial-kinds-of-failure.html">Kani
documentation</a>.</p>
<p><strong>Q:</strong> Do we expect all contributors to write harnesses for newly introduced
code?<br />
<strong>A:</strong> No. Kani is complementary to unit testing, and we do not have
target for “proof coverage”. We employ formal verification in especially
critical code areas. Generally we do not expect someone who might not be
familiar with formal tools to contribute harnesses. We do expect all
contributed code to pass verification though, just like we expect it to pass
unit test!</p>
<p><strong>Q:</strong> How should I report issues related to any Firecracker harnesses?<br />
<strong>A:</strong>
Our Kani harnesses verify safety critical invariants. If you discover a flaw in
a harness, please report it using the <a href="https://github.com/firecracker-microvm/firecracker/blob/main/SECURITY.md">security issue disclosure
process</a>.</p>
<p><strong>Q:</strong> How do I know which properties I should prove in the Kani harness?<br />
<strong>A:</strong> Generally, these are given by some sort of specification. This can
either be the function contract described in its document (e.g. what relation
between input and output do callers expect?), or even something formal such as
the TCP/IP standard. Don't forget to mention the specification in your proof
harness!</p>
<p><strong>Q:</strong> Where do I debug a broken proof?<br />
<strong>A:</strong> Check out the Kani book section
on <a href="https://model-checking.github.io/kani/debugging-verification-failures.html">debugging verification failures</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="creating-and-using-an-initrd-for-firecracker"><a class="header" href="#creating-and-using-an-initrd-for-firecracker">Creating and using an initrd for Firecracker</a></h1>
<h2 id="creating"><a class="header" href="#creating">Creating</a></h2>
<h3 id="based-on-alpine-or-suse"><a class="header" href="#based-on-alpine-or-suse">Based on alpine or suse</a></h3>
<p>You can use the script found <a href="https://github.com/marcov/firecracker-initrd">here</a>
to generate an initrd either based on alpine or suse linux.</p>
<p>The script extracts the init system from each distribution and creates a
initrd.</p>
<h3 id="custom"><a class="header" href="#custom">Custom</a></h3>
<p>Use this option for creating an initrd if you're building your own init or if
you need any specific files / logic in your initrd.</p>
<pre><code class="language-bash">mkdir initrd
cp /path/to/your/init initrd/init
# copy everything else you need in initrd/
cd initrd
find . -print0 | cpio --null --create --verbose --format=newc &gt; initrd.cpio
</code></pre>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<p>When setting your boot source, add a <code>initrd_path</code> property like so:</p>
<pre><code class="language-shell">curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT 'http://localhost/boot-source'   \
    -H 'Accept: application/json'           \
    -H 'Content-Type: application/json'     \
    -d &quot;{
        \&quot;kernel_image_path\&quot;: \&quot;/path/to/kernel\&quot;,
        \&quot;boot_args\&quot;: \&quot;console=ttyS0 reboot=k panic=1 pci=off\&quot;,
        \&quot;initrd_path\&quot;: \&quot;/path/to/initrd.cpio\&quot;
    }&quot;
</code></pre>
<h3 id="notes"><a class="header" href="#notes">Notes</a></h3>
<ul>
<li>You should not use a drive with <code>is_root_device: true</code> when using an initrd</li>
<li>Make sure your kernel configuration has <code>CONFIG_BLK_DEV_INITRD=y</code></li>
<li>If you don't want to place your init at the root of your initrd, you can add
<code>rdinit=/path/to/init</code> to your <code>boot_args</code> property</li>
<li>If you intend to <code>pivot_root</code> in your init, it won't be possible because the
initrd is mounted as a rootfs and cannot be unmounted. You will need to use
<code>switch_root</code> instead.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-firecracker-jailer"><a class="header" href="#the-firecracker-jailer">The Firecracker Jailer</a></h1>
<h2 id="disclaimer"><a class="header" href="#disclaimer">Disclaimer</a></h2>
<p>The jailer is a program designed to isolate the Firecracker process in
order to enhance Firecracker's security posture. It is meant to address the
security needs of Firecracker only and is not intended to work with other
binaries. Additionally, each jailer binary should be used with a statically
linked Firecracker binary (with the default musl toolchain) of the same
version. Experimental gnu builds are not supported.</p>
<h2 id="jailer-usage"><a class="header" href="#jailer-usage">Jailer Usage</a></h2>
<p>The jailer is invoked in this manner:</p>
<pre><code class="language-bash">jailer --id &lt;id&gt; \
       --exec-file &lt;exec_file&gt; \
       --uid &lt;uid&gt; \
       --gid &lt;gid&gt;
       [--parent-cgroup &lt;relative_path&gt;]
       [--cgroup-version &lt;cgroup-version&gt;]
       [--cgroup &lt;cgroup&gt;]
       [--chroot-base-dir &lt;chroot_base&gt;]
       [--netns &lt;netns&gt;]
       [--resource-limit &lt;resource=value&gt;]
       [--daemonize]
       [--new-pid-ns]
       [--...extra arguments for Firecracker]
</code></pre>
<ul>
<li><code>id</code> is the unique VM identification string, which may contain alphanumeric
characters and hyphens. The maximum <code>id</code> length is currently 64 characters.</li>
<li><code>exec_file</code> is the path to the Firecracker binary that will be exec-ed by the
jailer. The filename must include the string <code>firecracker</code>. This is enforced
because the interaction with the jailer is Firecracker specific.</li>
<li><code>uid</code> and <code>gid</code> are the uid and gid the jailer switches to as it execs the
target binary.</li>
<li><code>parent-cgroup</code> is used to allow the placement of microvm cgroups in custom
nested hierarchies. By specifying this parameter, the jailer will create a
new cgroup named <code>id</code> for the microvm in the <code>&lt;cgroup_base&gt;/&lt;parent_cgroup&gt;</code>
subfolder. <code>cgroup_base</code> is the cgroup controller root for <code>cgroup v1</code> (e.g.
<code>/sys/fs/cgroup/cpu</code>) or the unified controller hierarchy for <code>cgroup v2</code> (
e.g. <code>/sys/fs/cgroup/unified</code>. <code>&lt;parent_cgroup&gt;</code> is a relative path within that
hierarchy. For example, if <code>--parent-cgroup all_uvms/external_uvms</code> is specified,
the jailer will write all cgroup parameters specified through <code>--cgroup</code> in
<code>/sys/fs/cgroup/&lt;controller_name&gt;/all_uvms/external_uvms/&lt;id&gt;</code>. By default, the
parent cgroup is <code>exec-file</code>.
If there are no <code>--cgroup</code> parameters specified and <code>--group-version=2</code> was
passed, then the jailer will move the process to the specified cgroup.</li>
<li><code>cgroup-version</code> is used to select which type of cgroup hierarchy to use for
the creation of cgroups. The default value is &quot;1&quot; which means that cgroups
specified with the <code>cgroup</code> argument will be created within a v1 hierarchy.
Supported options are &quot;1&quot; for cgroup-v1 and &quot;2&quot; for cgroup-v2.</li>
<li><code>cgroup</code> cgroups can be passed to the jailer to let it set the values
when the microVM process is spawned. The <code>--cgroup</code> argument must follow this format:
<code>&lt;cgroup_file&gt;=&lt;value&gt;</code> (e.g <code>cpuset.cpus=0</code>). This argument can be used multiple
times to set multiple cgroups. This is useful to avoid providing privileged permissions
to another process for setting the cgroups before or after the jailer is executed.
The <code>--cgroup</code> flag can help as well to set Firecracker process cgroups
before the VM starts running, with no need to create the entire cgroup
hierarchy manually (which requires privileged permissions).</li>
<li><code>chroot_base</code> represents the base folder where chroot jails are built. The
default is <code>/srv/jailer</code>.</li>
<li><code>netns</code> represents the path to a network namespace handle. If present, the
jailer will use this to join the associated network namespace.</li>
<li>For extra security and control over resource usage, <code>resource-limit</code> can be
used to set bounds to the process resources. The <code>--resource-limit</code> argument
must follow this format: <code>&lt;resource&gt;=&lt;value&gt;</code> (e.g <code>no-file=1024</code>) and can be
used multiple times to set multiple bounds. Current available resources that
can be limited using this argument are:
<ul>
<li><code>fsize</code>: The maximum size in bytes for files created by the process.</li>
<li><code>no-file</code>: Specifies a value one greater than the maximum file descriptor
number that can be opened by this process.</li>
</ul>
</li>
</ul>
<p>Here is an example on how to set multiple resource limits using this argument:</p>
<pre><code class="language-bash">--resource-limit fsize=250000000 --resource-limit no-file=1024
</code></pre>
<ul>
<li>When present, the <code>--daemonize</code> flag causes the jailer to call <code>setsid()</code> and
redirect all three standard I/O file descriptors to <code>/dev/null</code>.</li>
<li>When present, the <code>--new-pid-ns</code> flag causes the jailer to spawn the provided
binary into a new PID namespace.
It makes use of the libc <code>clone()</code> function with the <code>CLONE_NEWPID</code> flag.
As a result, the jailer and
the process running the exec file have different PIDs. The PID of the child
process is stored in the jail root directory inside <code>&lt;exec_file_name&gt;.pid</code>.</li>
<li>The jailer adheres to the &quot;end of command options&quot; convention, meaning
all parameters specified after <code>--</code> are forwarded to Firecracker. For
example, this can be paired with the <code>--config-file</code> Firecracker argument to
specify a configuration file when starting Firecracker via the jailer (the
file path and the resources referenced within must be valid relative to a
jailed Firecracker).
Please note the jailer already passes <code>--id</code> parameter to the
Firecracker process.</li>
</ul>
<h2 id="jailer-operation"><a class="header" href="#jailer-operation">Jailer Operation</a></h2>
<p>After starting, the Jailer goes through the following operations:</p>
<ul>
<li>Validate <strong>all provided paths</strong> and the VM <code>id</code>.</li>
<li>Close all open file descriptors based on <code>/proc/&lt;jailer-pid&gt;/fd</code> except
input, output and error.</li>
<li>Cleanup all environment variables received from the parent process.</li>
<li>Create the <code>&lt;chroot_base&gt;/&lt;exec_file_name&gt;/&lt;id&gt;/root</code> folder, which will be
henceforth referred to as <code>chroot_dir</code>. <code>exec_file_name</code> is the
last path component of <code>exec_file</code> (for example, that would be <code>firecracker</code>
for <code>/usr/bin/firecracker</code>). Nothing is done if the path already
exists (it should not, since <code>id</code> is supposed to be unique).</li>
<li>Copy <code>exec_file</code> to
<code>&lt;chroot_base&gt;/&lt;exec_file_name&gt;/&lt;id&gt;/root/&lt;exec_file_name&gt;</code>. This ensures the
new process will not share memory with any other Firecracker process.</li>
<li>Set resource bounds for current process and its children through
<code>--resource-limit</code> argument, by calling <code>setrlimit()</code> system call with the
specific resource argument. If no limits are provided, the jailer bounds
<code>no-file</code> to a maximum default value of 2048.</li>
<li>Create the <code>cgroup</code> sub-folders. The jailer can use either <code>cgroup v1</code>
or <code>cgroup v2</code>. On most systems, this is mounted by default in <code>/sys/fs/cgroup</code>
(should be mounted by the user otherwise). The jailer will parse
<code>/proc/mounts</code> to detect where each of the controllers required in <code>--cgroup</code>
can be found (multiple controllers may share the same path). For each identified
location (referred to as <code>&lt;cgroup_base&gt;</code>), the jailer creates the
<code>&lt;cgroup_base&gt;/&lt;parent_cgroup&gt;/&lt;id&gt;</code> subfolder, and writes the current pid
to <code>&lt;cgroup_base&gt;/&lt;parent_cgroup&gt;/&lt;id&gt;/tasks</code>. Also, the value passed for each
<code>&lt;cgroup_file&gt;</code> is written to the file. If <code>--node</code> is used the corresponding
values are written to the appropriate <code>cpuset.mems</code> and <code>cpuset.cpus</code> files.</li>
<li>Call <code>unshare()</code> into a new mount namespace, use <code>pivot_root()</code> to switch
the old system root mount point with a new one base in <code>chroot_dir</code>, switch
the current working directory to the new root, unmount the old root mount
point, and call <code>chroot</code> into the current directory.</li>
<li>Use <code>mknod</code> to create a <code>/dev/net/tun</code> equivalent inside the jail.</li>
<li>Use <code>mknod</code> to create a <code>/dev/kvm</code> equivalent inside the jail.</li>
<li>Use <code>chown</code> to change ownership of the <code>chroot_dir</code> (root path <code>/</code> as seen
by the jailed firecracker), <code>/dev/net/tun</code>, <code>/dev/kvm</code>. The ownership is
changed to the provided <code>uid:gid</code>.</li>
<li>If <code>--netns &lt;netns&gt;</code> is present, attempt to join the specified network
namespace.</li>
<li>If <code>--daemonize</code> is specified, call <code>setsid()</code> and redirect <code>STDIN</code>,
<code>STDOUT</code>, and <code>STDERR</code> to <code>/dev/null</code>.</li>
<li>If <code>--new-pid-ns</code> is specified, call <code>clone()</code> with <code>CLONE_NEWPID</code> flag
to spawn a new process within a new PID namespace.
The new process will assume the role of init(1) in the new namespace.
The parent will store child's PID inside <code>&lt;exec_file_name&gt;.pid</code>, while the child
drops privileges and <code>exec()</code>s into the <code>&lt;exec_file_name&gt;</code>, as described below.</li>
<li>Drop privileges via setting the provided <code>uid</code> and <code>gid</code>.</li>
<li>Exec into <code>&lt;exec_file_name&gt; --id=&lt;id&gt; --start-time-us=&lt;opaque&gt; --start-time-cpu-us=&lt;opaque&gt;</code> (and also forward
any extra arguments provided to the jailer after <code>--</code>, as mentioned in
the <strong>Jailer Usage</strong> section), where:
<ul>
<li><code>id</code>: (<code>string</code>) - The <code>id</code> argument provided to jailer.</li>
<li><code>opaque</code>: (<code>number</code>) time calculated by the jailer that it spent doing
its work.</li>
</ul>
</li>
</ul>
<h2 id="example-run-and-notes"><a class="header" href="#example-run-and-notes">Example Run and Notes</a></h2>
<p>Let’s assume Firecracker is available as <code>/usr/bin/firecracker</code>, and the jailer
can be found at <code>/usr/bin/jailer</code>. We pick the <strong>unique id
551e7604-e35c-42b3-b825-416853441234</strong>, and we choose to run on <strong>NUMA node
0</strong> (in order to isolate the process in the 0th NUMA node we need to set <code>cpuset.mems=0</code>
and <code>cpuset.cpus</code> equals to the CPUs of that NUMA node), using <strong>uid 123</strong>,
and <strong>gid 100</strong>. For this example, we are content with the default <code>/srv/jailer</code>
chroot base dir.</p>
<p>We start by running:</p>
<pre><code class="language-bash">/usr/bin/jailer --id 551e7604-e35c-42b3-b825-416853441234
--cgroup cpuset.mems=0 --cgroup cpuset.cpus=$(cat /sys/devices/system/node/node0/cpulist)
--exec-file /usr/bin/firecracker --uid 123 --gid 100 \
--netns /var/run/netns/my_netns --daemonize
</code></pre>
<p>After opening the file descriptors mentioned in the previous section, the
jailer will create the following resources (and all their prerequisites, such
as the path which contains them):</p>
<ul>
<li><code>/srv/jailer/firecracker/551e7604-e35c-42b3-b825-416853441234/root/firecracker</code>
(copied from <code>/usr/bin/firecracker</code>)</li>
</ul>
<p>We are going to refer to
<code>/srv/jailer/firecracker/551e7604-e35c-42b3-b825-416853441234/root</code>
as <code>&lt;chroot_dir&gt;</code>.</p>
<p>Let’s also assume the, <strong>cpuset</strong> cgroups are mounted at
<code>/sys/fs/cgroup/cpuset</code>. The jailer will create the following subfolder
(which will inherit settings from the parent cgroup):</p>
<ul>
<li><code>/sys/fs/cgroup/cpuset/firecracker/551e7604-e35c-42b3-b825-416853441234</code></li>
</ul>
<p>It’s worth noting that, whenever a folder already exists, nothing will be done,
and we move on to the next directory that needs to be created. This should only
happen for the common <code>firecracker</code> subfolder (but, as for creating the chroot
path before, we do not issue an error if folders directly associated with the
supposedly unique <code>id</code> already exist).</p>
<p>The jailer then writes the current pid to
<code>/sys/fs/cgroup/cpuset/firecracker/551e7604-e35c-42b3-b825-416853441234/tasks</code>,
It also writes <code>0</code> to
<code>/sys/fs/cgroup/cpuset/firecracker/551e7604-e35c-42b3-b825-416853441234/cpuset.mems</code>,
And the corresponding CPUs to
<code>/sys/fs/cgroup/cpuset/firecracker/551e7604-e35c-42b3-b825-416853441234/cpuset.cpus</code>.</p>
<p>Since the <code>--netns</code> parameter is specified in our example, the jailer opens
<code>/var/run/netns/my_netns</code> to get a file descriptor <code>fd</code>, uses
<code>setns(fd, CLONE_NEWNET)</code> to join the associated network namespace, and then
closes <code>fd</code>.</p>
<p>The <code>--daemonize</code> flag is also present, so the jailers opens <code>/dev/null</code> as
<strong>RW</strong> and keeps the associate file descriptor as <code>dev_null_fd</code> (we do this
before going inside the jail), to be used later.</p>
<p>Build the chroot jail. First, the jailer uses <code>unshare()</code> to enter a new mount
namespace, and changes the propagation of all mount points in the new namespace
to private using <code>mount(NULL, “/”, NULL, MS_PRIVATE | MS_REC, NULL)</code>, as a
prerequisite to <code>pivot_root()</code>. Another required operation is to bind mount
<code>&lt;chroot_dir&gt;</code> on top of itself using <code>mount(&lt;chroot_dir&gt;, &lt;chroot_dir&gt;, NULL, MS_BIND, NULL)</code>. At this point, the jailer creates the folder
<code>&lt;chroot_dir&gt;/old_root</code>, changes the current directory to <code>&lt;chroot_dir&gt;</code>,
and calls <code>syscall(SYS_pivot_root, “.”, “old_root”)</code>. The final steps of
building the jail are unmounting <code>old_root</code> using <code>umount2(“old_root”, MNT_DETACH)</code>, deleting <code>old_root</code> with <code>rmdir</code>, and finally calling
<code>chroot(“.”)</code> for good measure. From now, the process is jailed in
<code>&lt;chroot_dir&gt;</code>.</p>
<p>Create the special file <code>/dev/net/tun</code>, using <code>mknod(“/dev/net/tun”, S_IFCHR | S_IRUSR | S_IWUSR, makedev(10, 200))</code>, and then call <code>chown(“/dev/net/tun”, 123, 100)</code>, so Firecracker can use it after dropping privileges. This is
required to use multiple TAP interfaces when running jailed. Do the same for
<code>/dev/kvm</code>.</p>
<p>Change ownership of <code>&lt;chroot_dir&gt;</code> to <code>uid:gid</code> so that Firecracker can create
its API socket there.</p>
<p>Since the <code>--daemonize</code> flag is present, call <code>setsid()</code> to join a new
session, a new process group, and to detach from the controlling terminal.
Then, redirect standard file descriptors to <code>/dev/null</code> by calling
<code>dup2(dev_null_fd, STDIN)</code>, <code>dup2(dev_null_fd, STDOUT)</code>, and <code>dup2(dev_null_fd, STDERR)</code>. Close <code>dev_null_fd</code>, because it is no longer necessary.</p>
<p>Finally, the jailer switches the <code>uid</code> to <code>123</code>, and <code>gid</code> to <code>100</code>, and execs</p>
<pre><code class="language-console">./firecracker \
  --id=&quot;551e7604-e35c-42b3-b825-416853441234&quot; \
  --start-time-us=&lt;opaque&gt; \
  --start-time-cpu-us=&lt;opaque&gt;
</code></pre>
<p>Now firecracker creates the socket at
<code>/srv/jailer/firecracker/551e7604-e35c-42b3-b825-416853441234/root/&lt;api-sock&gt;</code>
to interact with the VM.</p>
<p>Note: default value for <code>&lt;api-sock&gt;</code> is <code>/run/firecracker.socket</code>.</p>
<h3 id="observations"><a class="header" href="#observations">Observations</a></h3>
<ul>
<li>The user must create hard links for (or copy) any resources which will be
provided to the VM via the API (disk images, kernel images, named pipes, etc)
inside the jailed root folder. Also, permissions must be properly managed for
these resources; for example the user which Firecracker runs as must have
both <strong>read and write permissions</strong> to the backing file for a RW block
device.</li>
<li>By default the VMs are not asigned to any NUMA node or pinned to any CPU.
The user must manage any fine tuning of resource partitioning via
cgroups, by using the <code>--cgroup</code> command line argument.</li>
<li>It’s up to the user to handle cleanup after running the jailer. One way to do
this involves registering handlers with the cgroup <code>notify_on_release</code>
mechanism, while being wary about potential race conditions (the instance
crashing before the subscription process is complete, for example).</li>
<li>For extra resilience, the <code>--new-pid-ns</code> flag enables the Jailer to exec the
binary file in a new PID namespace, in order to become a pseudo-init process.
Alternatively, the user can spawn the jailer in a new PID namespace via a
combination of <code>clone()</code> with the <code>CLONE_NEWPID</code> flag and <code>exec()</code>.</li>
<li>We run the jailer as the <code>root</code> user; it actually requires a more restricted
set of capabilities, but that's to be determined as features stabilize.</li>
<li>The jailer can only log messages to stdout/err for now, which is why the
logic associated with <code>--daemonize</code> runs towards the end, instead of the very
beginning. We are working on adding better logging capabilities.</li>
</ul>
<h2 id="caveats-1"><a class="header" href="#caveats-1">Caveats</a></h2>
<ul>
<li>
<p>If all the cgroup controllers are bunched up on a single mount point using
the &quot;all&quot; option, our current program logic will complain it cannot detect
individual controller mount points.</p>
</li>
<li>
<p><a href="https://github.com/firecracker-microvm/firecracker/issues/4287">#4287</a> When
starting a jailer with <code>--parent-cgroup</code> specified but no cgroup flags
specified, then the rules in the parent cgroup folder are ignored. To
work around, use a dummy cgroup parameter like <code>--cgroup=memory.max=max</code>.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firecracker-logger-configuration"><a class="header" href="#firecracker-logger-configuration">Firecracker logger Configuration</a></h1>
<p>For the logging capability, Firecracker uses a single Logger object.
The Logger can be configured either by sending a <code>PUT</code> API Request to
the <code>/logger</code> path or by command line. You can configure the Logger
only once (by using one of these options) and once configured, you
can not update it.</p>
<h2 id="prerequisites-4"><a class="header" href="#prerequisites-4">Prerequisites</a></h2>
<p>In order to configure the Logger, first you have to create the resource
that will be used for logging:</p>
<pre><code class="language-bash"># Create the required named pipe:
mkfifo logs.fifo

# The logger also works with usual files:
touch logs.file
</code></pre>
<h2 id="using-the-api-socket-for-configuration"><a class="header" href="#using-the-api-socket-for-configuration">Using the API socket for configuration</a></h2>
<p>You can configure the Logger by sending the following API command:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT &quot;http://localhost/logger&quot; \
    -H &quot;accept: application/json&quot; \
    -H &quot;Content-Type: application/json&quot; \
    -d &quot;{
             &quot;log_path&quot;: &quot;logs.fifo&quot;,
             &quot;level&quot;: &quot;Warning&quot;,
             &quot;show_level&quot;: false,
             &quot;show_log_origin&quot;: false
    }&quot;
</code></pre>
<p>Details about the required and optional fields can be found in the
<a href="../src/api_server/swagger/firecracker.yaml">swagger definition</a>.</p>
<h2 id="using-command-line-parameters-for-configuration"><a class="header" href="#using-command-line-parameters-for-configuration">Using command line parameters for configuration</a></h2>
<p>If you want to configure the Logger on startup and without using the
API socket, you can do that by passing the parameter <code>--log-path</code> to
the Firecracker process:</p>
<pre><code class="language-bash">./firecracker --api-sock /tmp/firecracker.socket --log-path
&lt;path_to_the_logging_fifo_or_file&gt;
</code></pre>
<p>The other Logger fields have, in this case, the default values:
<code>Level -&gt; Warning</code>, <code>show_level -&gt; false</code>, <code>show_log_origin -&gt; false</code>.
For configuring these too, you can also pass the following optional
parameters: <code>--level &lt;log_level&gt;</code>, <code>--show-level</code>, <code>--show-log-origin</code>:</p>
<pre><code class="language-bash">./firecracker --api-sock /tmp/firecracker.socket --log-path
logs.fifo --level Error --show-level --show-log-origin
</code></pre>
<h2 id="reading-from-the-logging-destination"><a class="header" href="#reading-from-the-logging-destination">Reading from the logging destination</a></h2>
<p>The <code>logs.fifo</code> pipe will store the human readable logs, e.g. errors,
warnings etc.(depending on the level).</p>
<p>If the path provided is a named pipe, you can use the script below to
read from it:</p>
<pre><code class="language-shell">logs=logs.fifo

while true
do
    if read line &lt;$logs; then
        echo $line
    fi
done

echo &quot;Reader exiting&quot;

</code></pre>
<p>Otherwise, if the path points to a normal file, you can simply do:</p>
<pre><code class="language-shell script">cat logs.file
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firecracker-metrics-configuration"><a class="header" href="#firecracker-metrics-configuration">Firecracker Metrics Configuration</a></h1>
<p>For the metrics capability, Firecracker uses a single Metrics system. This
system can be configured either by: a) sending a <code>PUT</code> API Request to the
<code>/metrics</code> path: or b) using the <code>--metrics-path</code> CLI option.</p>
<p>Note the metrics configuration is <strong>not</strong> part of the guest configuration and is
not restored from a snapshot.</p>
<h2 id="prerequisites-5"><a class="header" href="#prerequisites-5">Prerequisites</a></h2>
<p>In order to configure the Metrics, first you have to create the resource
that will be used for storing the metrics:</p>
<pre><code class="language-bash"># Create the required named pipe:
mkfifo metrics.fifo

# The Metrics system also works with usual files:
touch metrics.file
</code></pre>
<h2 id="configuring-the-system-via-cli"><a class="header" href="#configuring-the-system-via-cli">Configuring the system via CLI</a></h2>
<p>When launching Firecracker, use the CLI option to set the metrics file.</p>
<pre><code class="language-bash">./firecracker --metrics-path metrics.fifo
</code></pre>
<h2 id="configuring-the-system-via-api"><a class="header" href="#configuring-the-system-via-api">Configuring the system via API</a></h2>
<p>You can configure the Metrics system by sending the following API command:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT &quot;http://localhost/metrics&quot; \
    -H &quot;accept: application/json&quot; \
    -H &quot;Content-Type: application/json&quot; \
    -d &quot;{
             \&quot;metrics_path\&quot;: \&quot;metrics.fifo\&quot;
    }&quot;
</code></pre>
<p>Details about this configuration can be found in the
<a href="../src/api_server/swagger/firecracker.yaml">swagger definition</a>.</p>
<p>The metrics are written to the <code>metrics_path</code> in JSON format.</p>
<h2 id="flushing-the-metrics"><a class="header" href="#flushing-the-metrics">Flushing the metrics</a></h2>
<p>The metrics get flushed in two ways:</p>
<ul>
<li>without user intervention every 60 seconds;</li>
<li>upon user demand, by issuing a <code>FlushMetrics</code> request. You can
find how to use this request in the <a href="api_requests/actions.html">actions API</a>.</li>
</ul>
<p>If the path provided is a named pipe, you can use the script below to
read from it:</p>
<pre><code class="language-shell">metrics=metrics.fifo

while true
do
    if read line &lt;$metrics; then
        echo $line
    fi
done

echo &quot;Reader exiting&quot;

</code></pre>
<p>Otherwise, if the path points to a normal file, you can simply do:</p>
<pre><code class="language-shell script">cat metrics.file
</code></pre>
<h2 id="metrics-emitted-by-firecracker"><a class="header" href="#metrics-emitted-by-firecracker">Metrics emitted by Firecracker</a></h2>
<p>The metrics emitted by Firecracker are in JSON format.
Below are the keys present in each metrics json object emitted by Firecracker:</p>
<pre><code>&quot;api_server&quot;
&quot;balloon&quot;
&quot;block&quot;
&quot;deprecated_api&quot;
&quot;entropy&quot;
&quot;get_api_requests&quot;
&quot;i8042&quot;
&quot;latencies_us&quot;
&quot;logger&quot;
&quot;mmds&quot;
&quot;net&quot;
&quot;patch_api_requests&quot;
&quot;put_api_requests&quot;
&quot;rtc&quot;
&quot;seccomp&quot;
&quot;signals&quot;
&quot;uart&quot;
&quot;vcpu&quot;
&quot;vhost_user_block&quot;
&quot;vmm&quot;
&quot;vsock&quot;
</code></pre>
<p>Below table explains where Firecracker metrics are defined :</p>
<div class="table-wrapper"><table><thead><tr><th>Metrics key</th><th>Device</th><th>Additional comments</th></tr></thead><tbody>
<tr><td>balloon</td><td><a href="../src/vmm/src/devices/virtio/balloon/metrics.rs">BalloonDeviceMetrics</a></td><td>Respresent metrics for the Balloon device.</td></tr>
<tr><td>block</td><td><a href="../src/vmm/src/devices/virtio/virtio_block/metrics.rs">BlockDeviceMetrics</a></td><td>Respresent aggregate metrics for Virtio Block device.</td></tr>
<tr><td>block_{block_drive_id}</td><td><a href="../src/vmm/src/devices/virtio/virtio_block/metrics.rs">BlockDeviceMetrics</a></td><td>Respresent Virtio Block device metrics for the endpoint <code>&quot;/drives/{drive_id}&quot;</code> e.g. <code>&quot;block_rootfs&quot;:</code> represent metrics for the endpoint <code>&quot;/drives/rootfs&quot;</code></td></tr>
<tr><td>i8042</td><td><a href="../src/vmm/src/devices/legacy/i8042.rs">I8042DeviceMetrics</a></td><td>Respresent Metrics specific to the i8042 device.</td></tr>
<tr><td>net</td><td><a href="../src/vmm/src/devices/virtio/net/metrics.rs">NetDeviceMetrics</a></td><td>Respresent aggregate metrics for Virtio Net device.</td></tr>
<tr><td>net_{iface_id}</td><td><a href="../src/vmm/src/devices/virtio/net/metrics.rs">NetDeviceMetrics</a></td><td>Respresent Virtio Net device metrics for the endpoint <code>&quot;/network-interfaces/{iface_id}&quot;</code> e.g. <code>net_eth0</code> represent metrics for the endpoint <code>&quot;/network-interfaces/eth0&quot;</code></td></tr>
<tr><td>rtc</td><td><a href="../src/vmm/src/devices/legacy/serial.rs">RTCDeviceMetrics</a></td><td>Respresent Metrics specific to the RTC device. <code>Note</code>: this is emitted only on <code>aarch64</code>.</td></tr>
<tr><td>uart</td><td><a href="../src/vmm/src/devices/legacy/serial.rs">SerialDeviceMetrics</a></td><td>Respresent Metrics specific to the serial device.</td></tr>
<tr><td>vhost_user_{dev}_{dev_id}</td><td><a href="../src/vmm/src/devices/virtio/vhost_user_metrics.rs">VhostUserDeviceMetrics</a></td><td>Respresent Vhost-user device metrics for the device <code>dev</code> and device id <code>dev_id</code>. e.g. <code>&quot;vhost_user_block_rootfs&quot;:</code> represent metrics for vhost-user block device having the endpoint <code>&quot;/drives/rootfs&quot;</code></td></tr>
<tr><td>vsock</td><td><a href="../src/vmm/src/devices/virtio/vsock/metrics.rs">VsockDeviceMetrics</a></td><td>Respresent Metrics specific to the vsock device.</td></tr>
<tr><td>entropy</td><td><a href="../src/vmm/src/devices/virtio/rng/metrics.rs">EntropyDeviceMetrics</a></td><td>Respresent Metrics specific to the entropy device.</td></tr>
<tr><td>&quot;api_server&quot;<br>&quot;deprecated_api&quot;<br>&quot;get_api_requests&quot;<br>&quot;latencies_us&quot;<br>&quot;logger&quot;<br>&quot;mmds&quot;<br>&quot;patch_api_requests&quot;<br>&quot;put_api_requests&quot;<br>&quot;seccomp&quot;<br>&quot;signals&quot;<br>&quot;vcpu&quot;<br>&quot;vmm&quot;</td><td><a href="../src/vmm/src/logger/metrics.rs">metrics.rs</a></td><td>Rest of the metrics are defined in the same file metrics.rs.</td></tr>
</tbody></table>
</div>
<p>Note:
Firecracker emits all the above metrics regardless of the presense of
that component i.e. even if <code>vsock</code> device is not attached to the
Microvm, Firecracker will still emit the Vsock metrics with key as
<code>vsock</code> and value of all metrics defined in <code>VsockDeviceMetrics</code> as
<code>0</code>.</p>
<h3 id="units-for-firecracker-metrics"><a class="header" href="#units-for-firecracker-metrics">Units for Firecracker metrics:</a></h3>
<p>Units for Firecracker metrics are embedded in their name.<br/>
Below pseudo code should be to extract units from Firecracker metrics name:<br/>
Note: An example of full_key for below logic is <code>&quot;vcpu.exit_io_in_agg.min_us&quot;</code></p>
<pre><code>    if substring &quot;_bytes&quot; or &quot;_bytes_count&quot; is present in any subkey of full_key
        Unit is &quot;Bytes&quot;
    else substring &quot;_ms&quot; is present in any subkey of full_key
        Unit is &quot;Milliseconds&quot;
    else substring &quot;_us&quot; is present in any subkey of full_key
        Unit is &quot;Microseconds&quot;
    else
        Unit is &quot;Count&quot;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="seccomp-in-firecracker"><a class="header" href="#seccomp-in-firecracker">Seccomp in Firecracker</a></h1>
<p>Seccomp filters are used by default to limit the host system calls Firecracker
can use. The default filters only allow the bare minimum set of system calls
and parameters that Firecracker needs in order to function correctly.</p>
<p>The filters are loaded in the Firecracker process, on a per-thread basis,
as follows:</p>
<ul>
<li>VMM (main) - right before executing guest code on the VCPU threads;</li>
<li>API - right before launching the HTTP server;</li>
<li>VCPUs - right before executing guest code.</li>
</ul>
<p><strong>Note</strong>: On experimental GNU targets, there are no default seccomp filters
installed, since they are not intended for production use.</p>
<p>Firecracker uses JSON files for expressing the filter rules and relies on the
<a href="seccompiler.html">seccompiler</a> tool for all the seccomp functionality.</p>
<h2 id="default-filters-recommended"><a class="header" href="#default-filters-recommended">Default filters (recommended)</a></h2>
<p>At build time, the default target-specific JSON file is compiled into the
serialized binary file, using seccompiler-bin, and gets embedded in the
Firecracker binary.</p>
<p>This process is performed automatically, when building the executable.</p>
<p>To minimise the overhead of succesive builds, the compiled filter file is
cached in the build folder and is only recompiled if modified.</p>
<p>You can find the default seccomp filters under <code>resources/seccomp</code>.</p>
<p>For a certain release, the default JSON filters used to build Firecracker are also
included in the respective release archive, viewable on the
<a href="https://github.com/firecracker-microvm/firecracker/releases">releases page</a>.</p>
<h2 id="custom-filters-advanced-users-only"><a class="header" href="#custom-filters-advanced-users-only">Custom filters (advanced users only)</a></h2>
<p><strong>Note 1</strong>: This feature overrides the default filters and can be dangerous.
Filter misconfiguration can result in abruptly terminating the process or
disabling the seccomp security boundary altogether.
We recommend using the default filters instead.</p>
<p><strong>Note 2</strong>: The user is fully responsible for managing the filter files.
We recommend using integrity checks whenever transferring/downloading files,
for example checksums, as well as for the Firecracker binary or other artifacts,
in order to mitigate potential man-in-the-middle attacks.</p>
<p>Firecracker exposes a way for advanced users to override the default filters
with fully customisable alternatives, leveraging the same JSON/seccompiler
tooling, at startup time.</p>
<p>Via Firecracker's optional <code>--seccomp-filter</code> parameter, one can supply
the path to a custom filter file compiled with seccompiler-bin.</p>
<p>Potential use cases:</p>
<ul>
<li>Users of experimentally-supported targets (like GNU libc builds) may be able
to use this feature to implement seccomp filters without needing to have a
custom build of Firecracker.</li>
<li>Faced with a <em>theoretical</em> production issue, due to a syscall that was
issued by the Firecracker process, but not allowed by the seccomp policy,
one may use a custom filter in order to quickly mitigate the issue. This
can speed up the resolution time, by not needing to build and deploy a new
Firecracker binary.
However, as the note above states, this needs to be thoroughly tested and
should not be a long-term solution.</li>
</ul>
<h2 id="disabling-seccomp-not-recommended"><a class="header" href="#disabling-seccomp-not-recommended">Disabling seccomp (not recommended)</a></h2>
<p>Firecracker also has support for a <code>--no-seccomp</code> parameter, which disables all
seccomp filtering.
It can be helpful when quickly prototyping changes in Firecracker that use new
system calls.</p>
<p>Do <strong>not</strong> use in production.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="seccompiler---overview-and-user-guide"><a class="header" href="#seccompiler---overview-and-user-guide">Seccompiler - overview and user guide</a></h1>
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>Seccompiler-bin is a tool that compiles seccomp filters expressed as JSON files
into serialized, binary BPF code that is directly consumed by Firecracker,
at build or launch time.</p>
<p>Seccompiler-bin uses a custom <a href="seccompiler.html#json-file-format">JSON file structure</a>,
detailed further below, that the filters must adhere to.</p>
<p>Besides the seccompiler-bin executable, seccompiler also exports a library
interface, with helper functions for deserializing and installing the binary
filters.</p>
<h2 id="usage-1"><a class="header" href="#usage-1">Usage</a></h2>
<h3 id="seccompiler-bin"><a class="header" href="#seccompiler-bin">Seccompiler-bin</a></h3>
<p>To view the seccompiler-bin command line arguments, pass the <code>--help</code> parameter
to the executable.</p>
<p>Example usage:</p>
<pre><code class="language-bash">./seccompiler-bin
    --target-arch &quot;x86_64&quot;  # The CPU arch where the BPF program will run.
                            # Supported architectures: x86_64, aarch64.
    --input-file &quot;x86_64_musl.json&quot; # File path of the JSON input.
    --output-file &quot;bpf_x86_64_musl&quot; # Optional path of the output file.
                                    # [default: &quot;seccomp_binary_filter.out&quot;]
    --basic # Optional, creates basic filters, discarding any parameter checks.
            # (Deprecated).
</code></pre>
<h3 id="seccompiler-library"><a class="header" href="#seccompiler-library">Seccompiler library</a></h3>
<p>To view the library documentation, navigate to the seccompiler source code, in
<code>firecracker/src/seccompiler/src</code> and run <code>cargo doc --lib --open</code>.</p>
<h2 id="where-is-seccompiler-implemented"><a class="header" href="#where-is-seccompiler-implemented">Where is seccompiler implemented?</a></h2>
<p>Seccompiler is implemented as another package in the Firecracker cargo
workspace. The code is located at <code>firecracker/src/seccompiler/src</code>.</p>
<h2 id="supported-platforms"><a class="header" href="#supported-platforms">Supported platforms</a></h2>
<p>Seccompiler-bin is supported on the
<a href="../README.html#supported-platforms">same platforms as Firecracker</a>.</p>
<h2 id="release-policy"><a class="header" href="#release-policy">Release policy</a></h2>
<p>Seccompiler-bin follows Firecracker's <a href="RELEASE_POLICY.html">release policy</a> and
version (it's released at the same time, with the same version number and
adheres to the same support window).</p>
<h2 id="json-file-format"><a class="header" href="#json-file-format">JSON file format</a></h2>
<p>A JSON file expresses the seccomp policy for the entire Firecracker process. It
contains multiple filters, one per each thread category and is specific to just
one target platform.</p>
<p>This means that Firecracker has a JSON file for each supported target
(currently determined by the arch-libc combinations). You can view them in
<code>resources/seccomp</code>.</p>
<p>At the top level, the file requires an object that maps thread categories
(vmm, api and vcpu) to seccomp filters:</p>
<pre><code>{
    &quot;vmm&quot;: {
       &quot;default_action&quot;: {
            &quot;errno&quot; : -1
       },
       &quot;filter_action&quot;: &quot;allow&quot;,
       &quot;filter&quot;: [...]
    },
    &quot;api&quot;: {...},
    &quot;vcpu&quot;: {...},
}
</code></pre>
<p>The associated filter is a JSON object containing the <code>default_action</code>,
<code>filter_action</code> and <code>filter</code>.</p>
<p>The <code>default_action</code> represents the action we have to execute if none of the
rules in <code>filter</code> matches, and <code>filter_action</code> is what gets executed if a rule
in the filter matches
(e.g: <code>&quot;Allow&quot;</code> in the case of implementing an allowlist).</p>
<p>An <strong>action</strong> is the JSON representation of the following enum:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum SeccompAction {
    Allow, // Allows syscall.
    Errno(u32), // Returns from syscall with specified error number.
    Kill, // Kills calling process.
    Log, // Same as allow but logs call.
    Trace(u32), // Notifies tracing process of the caller with respective number.
    Trap, // Sends `SIGSYS` to the calling process.
}
<span class="boring">}</span></code></pre></pre>
<p>The <code>filter</code> property specifies the set of rules that would trigger a match.
This is an array containing multiple <strong>or-bound SyscallRule</strong> <strong>objects</strong>
(if one of them matches, the corresponding action gets triggered).</p>
<p>The <strong>SyscallRule</strong> object is used for adding a rule to a syscall.
It has an optional <code>args</code> property that is used to specify a vector of
and-bound conditions that the syscall arguments must satisfy in order for the
rule to match.</p>
<p>In the absence of the <code>args</code> property, the corresponding action will get
triggered by any call that matches that name, irrespective of the argument
values.</p>
<p>Here is the structure of the object:</p>
<pre><code>{
    &quot;syscall&quot;: &quot;accept4&quot;, // mandatory, the syscall name
    &quot;comment&quot;: &quot;Used by vsock &amp; api thread&quot;, // optional, for adding meaningful comments
    &quot;args&quot;: [...] // optional, vector of and-bound conditions for the parameters
}
</code></pre>
<p>Note that the file format expects syscall names, not arch-specific numbers, for
increased usability. This is not true, however for the syscall arguments, which
are expected as base-10 integers.</p>
<p>In order to allow a syscall with multiple alternatives for the same parameters,
you can write multiple syscall rule objects at the filter-level, each with its
own rules.</p>
<p>Note that, when passing the deprecated <code>--basic</code> flag to seccompiler-bin, all
<code>args</code> fields of the <code>SeccompRule</code>s are ignored.</p>
<p>A <strong>condition object</strong> is made up of the following mandatory properties:</p>
<ul>
<li><code>index</code> (0-based index of the syscall argument we want to check)</li>
<li><code>type</code> (<code>dword</code> or <code>qword</code>, which specifies the argument size - 4 or 8
bytes respectively)</li>
<li><code>op</code>, which is one of <code>eq, ge, gt, ge, lt, masked_eq, ne</code> (the operator used
for comparing the parameter to <code>val</code>)</li>
<li><code>val</code> is the integer value being checked against</li>
</ul>
<p>As mentioned eariler, we don’t support any named parameters, but only numeric
constants in the JSON file. You may however add an optional <code>comment</code> property
to each condition object. This way, you can provide meaning to each numeric
value, much like when using named parameters, like so:</p>
<pre><code>{
    &quot;syscall&quot;: &quot;accept4&quot;,
    &quot;args&quot;: [
        {
            &quot;index&quot;: 3,
            &quot;type&quot;: &quot;dword&quot;,
            &quot;op&quot;: &quot;eq&quot;,
            &quot;val&quot;: 1,
            &quot;comment&quot;: &quot;libc::AF_UNIX&quot;
        }
    ]
}
</code></pre>
<p>To see example filters, look over Firecracker's JSON filters in
<code>resources/seccomp</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tracing"><a class="header" href="#tracing">Tracing</a></h1>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>Firecracker implements a framework for instrumentation based tracing.</p>
<p>Instrumentation based tracing as defined by
<a href="https://www.usenix.org/legacy/publications/library/proceedings/coots99/full_papers/liang/liang_html/node9.html">Sheng Liang on usenix.org</a>:</p>
<blockquote>
<p>There are two ways to obtain profiling information: either statistical
sampling or code instrumentation. Statistical sampling is less
disruptive to program execution, but cannot provide completely
accurate information. Code instrumentation, on the other hand, may be
more disruptive, but allows the profiler to record all the events it
is interested in. Specifically in CPU time profiling, statistical
sampling may reveal, for example, the relative percentage of time
spent in frequently-called methods, whereas code instrumentation can
report the exact number of time each method is invoked.</p>
</blockquote>
<p>The focus with tracing in Firecracker is to improve debug-ability.</p>
<p>Enabling tracing adds logs output on each functions entry and exit.
This assists debugging problems that relate to deadlocks or high
latencies by quickly identifying elongated function calls.</p>
<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<p>Firecracker implements instrumentation based tracing via
<a href="https://github.com/rust-lang/log"><code>log</code></a> and
<a href="https://github.com/JonathanWoollett-Light/log-instrument"><code>log_instrument</code></a>,
outputting a <code>Trace</code> level log when entering and exiting every function.</p>
<p>It is disabled by default at compile-time. Tracing functionality has no
impact on the release binary.</p>
<p>You can use <code>cargo run --bin clippy-tracing --</code> to build and run the
latest version in the repo or you can run
<code>cargo install --path src/clippy-tracing</code> to install the binary then use
<code>clippy-tracing</code> to run this binary.</p>
<p>You can run <code>clippy-tracing --help</code> for help.</p>
<p>To enable tracing in Firecracker, add instrumentation with:</p>
<pre><code>clippy-tracing \
  --action fix \
  --path ./src \
  --exclude benches \
  --exclude virtio/gen,bindings.rs,net/gen \
  --exclude log-instrument-macros/,log-instrument/,clippy-tracing/ \
  --exclude vmm_config/logger.rs,logger/,signal_handler.rs,time.rs
</code></pre>
<p><code>--exclude</code> can be used to avoid adding instrumentation to specific
files, here it is used to avoid adding instrumentation in:</p>
<ul>
<li>tests.</li>
<li>bindings.</li>
<li>the instrumentation tooling.</li>
<li>logger functionality that may form an infinite loop.</li>
</ul>
<p>After adding instrumentation re-compile with <code>--features tracing</code>:</p>
<pre><code>cargo build --features tracing
</code></pre>
<p>This will result in an increase in the binary size (~100kb) and a
significant regression in performance (&gt;10x). To mitigate the
performance impact you can filter the tracing output as described in the
next section.</p>
<h2 id="filtering"><a class="header" href="#filtering">Filtering</a></h2>
<p>You can filter tracing output both at run-time and compile-time.
This can be used to mitigate the performance impact of logging many
traces.</p>
<p>Run-time filtering is implemented with the <code>/logger</code> API call, this can
significantly mitigate the impact on execution time but cannot mitigate
the impact on memory usage. Execution time impact is mitigated by
avoiding constructing and writing the trace log, it still needs to check
the condition in every place it would output a log. Memory usage impact
is not mitigated as the instrumentation remains in the binary unchanged.</p>
<p>Compile-time filtering is a manual process using the
<a href="https://github.com/JonathanWoollett-Light/clippy-tracing"><code>clippy-tracing</code></a>
tool. This can almost entirely mitigate the impact on execution time and
the impact on memory usage.</p>
<h3 id="run-time"><a class="header" href="#run-time">Run-time</a></h3>
<p>You can filter by module path and/or file path at runtime, e.g.:</p>
<pre><code class="language-bash">curl -X PUT --unix-socket &quot;${API_SOCKET}&quot; \
    --data &quot;{
        \&quot;level\&quot;: \&quot;Trace\&quot;,
        \&quot;module\&quot;: \&quot;api_server::request\&quot;,
    }&quot; \
    &quot;http://localhost/logger&quot;
</code></pre>
<p>Instrumentation logs are <code>Trace</code> level logs, at runtime the level must
be set to <code>Trace</code> to see them. The module filter applied here ensures
only logs from the <code>request</code> modules within the <code>api_server</code> crate will
be output.</p>
<p>This will mitigate most of the performance regression.</p>
<h3 id="compile-time"><a class="header" href="#compile-time">Compile-time</a></h3>
<p>Specific environments can restrict run-time configuration. In these
environments it becomes necessary to support targeted tracing without
run-time re-configuration, for this compile-time filtering must be used.</p>
<p>To reproduce the same filtering as run-time at compile-time, you can use
<a href="../src/clippy-tracing"><code>clippy-tracing</code></a>
at compile-time like:</p>
<pre><code class="language-bash"># Remove all instrumentation.
clippy-tracing --action strip --path ./src
# Adds instrumentation to the specific file/s.
clippy-tracing --action fix --path ./src/api_server/src/request
# Build Firecracker.
cargo build --features tracing
</code></pre>
<p>Then at run-time:</p>
<pre><code class="language-bash">curl -X PUT --unix-socket &quot;${API_SOCKET}&quot; \
    --data &quot;{
        \&quot;level\&quot;: \&quot;Trace\&quot;,
    }&quot; \
    &quot;http://localhost/logger&quot;
</code></pre>
<p>The instrumentation has been stripped from all files other than those at
<code>./src/api_server/src/request</code> so we do not need to apply a run-time
filter. Runtime filtering could be applied but in this case it yields no
additional benefit.</p>
<h2 id="example"><a class="header" href="#example">Example</a></h2>
<p>In this example we start Firecracker with tracing then make a simple API
call.</p>
<h3 id="api-call"><a class="header" href="#api-call">API call</a></h3>
<pre><code>~/Projects/firecracker$ sudo curl -X GET --unix-socket &quot;/run/firecracker.socket&quot; &quot;http://localhost/&quot;
{&quot;id&quot;:&quot;anonymous-instance&quot;,&quot;state&quot;:&quot;Not started&quot;,&quot;vmm_version&quot;:&quot;1.6.0-dev&quot;,&quot;app_name&quot;:&quot;Firecracker&quot;}
</code></pre>
<h3 id="firecracker"><a class="header" href="#firecracker">Firecracker</a></h3>
<pre><code>~/Projects/firecracker$ sudo ./firecracker/build/cargo_target/release/firecracker --level Trace
2023-10-13T14:15:38.851263983 [anonymous-instance:main] Running Firecracker v1.6.0-dev
2023-10-13T14:15:38.851316122 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;single_value
2023-10-13T14:15:38.851322264 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;value_of
2023-10-13T14:15:38.851325119 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;value_of
2023-10-13T14:15:38.851328776 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;single_value
2023-10-13T14:15:38.851331351 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;flag_present
2023-10-13T14:15:38.851335809 [anonymous-instance:main] ThreadId(1)::main::main_exec::flag_present&gt;&gt;value_of
2023-10-13T14:15:38.851338254 [anonymous-instance:main] ThreadId(1)::main::main_exec::flag_present&lt;&lt;value_of
2023-10-13T14:15:38.851342091 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;flag_present
2023-10-13T14:15:38.851345638 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;single_value
2023-10-13T14:15:38.851349245 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;value_of
2023-10-13T14:15:38.851352721 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;value_of
2023-10-13T14:15:38.851355827 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;single_value
2023-10-13T14:15:38.851359444 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;from_args
2023-10-13T14:15:38.851362931 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;from_args
2023-10-13T14:15:38.851366207 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;get_filters
2023-10-13T14:15:38.851368401 [anonymous-instance:main] ThreadId(1)::main::main_exec::get_filters&gt;&gt;get_default_filters
2023-10-13T14:15:38.851372068 [anonymous-instance:main] ThreadId(1)::main::main_exec::get_filters::get_default_filters&gt;&gt;deserialize_binary
2023-10-13T14:15:38.851380033 [anonymous-instance:main] ThreadId(1)::main::main_exec::get_filters::get_default_filters&lt;&lt;deserialize_binary
2023-10-13T14:15:38.851383990 [anonymous-instance:main] ThreadId(1)::main::main_exec::get_filters::get_default_filters&gt;&gt;filter_thread_categories
2023-10-13T14:15:38.851388098 [anonymous-instance:main] ThreadId(1)::main::main_exec::get_filters::get_default_filters&lt;&lt;filter_thread_categories
2023-10-13T14:15:38.851391845 [anonymous-instance:main] ThreadId(1)::main::main_exec::get_filters&lt;&lt;get_default_filters
2023-10-13T14:15:38.851394360 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;get_filters
2023-10-13T14:15:38.851398077 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;single_value
2023-10-13T14:15:38.851400462 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;value_of
2023-10-13T14:15:38.851403507 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;value_of
2023-10-13T14:15:38.851410961 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;single_value
2023-10-13T14:15:38.851414107 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;single_value
2023-10-13T14:15:38.851417955 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;value_of
2023-10-13T14:15:38.851420650 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;value_of
2023-10-13T14:15:38.851426130 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;single_value
2023-10-13T14:15:38.851428434 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;flag_present
2023-10-13T14:15:38.851430949 [anonymous-instance:main] ThreadId(1)::main::main_exec::flag_present&gt;&gt;value_of
2023-10-13T14:15:38.851434766 [anonymous-instance:main] ThreadId(1)::main::main_exec::flag_present&lt;&lt;value_of
2023-10-13T14:15:38.851438133 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;flag_present
2023-10-13T14:15:38.851440577 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;flag_present
2023-10-13T14:15:38.851444575 [anonymous-instance:main] ThreadId(1)::main::main_exec::flag_present&gt;&gt;value_of
2023-10-13T14:15:38.851447941 [anonymous-instance:main] ThreadId(1)::main::main_exec::flag_present&lt;&lt;value_of
2023-10-13T14:15:38.851450005 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;flag_present
2023-10-13T14:15:38.851453772 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;arguments
2023-10-13T14:15:38.851456488 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;arguments
2023-10-13T14:15:38.851458902 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;single_value
2023-10-13T14:15:38.851462679 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;value_of
2023-10-13T14:15:38.851466587 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;value_of
2023-10-13T14:15:38.851470324 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;as_single_value
2023-10-13T14:15:38.851473239 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;as_single_value
2023-10-13T14:15:38.851476896 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;single_value
2023-10-13T14:15:38.851479521 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;arguments
2023-10-13T14:15:38.851485062 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;arguments
2023-10-13T14:15:38.851488398 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;single_value
2023-10-13T14:15:38.851491925 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;value_of
2023-10-13T14:15:38.851494900 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;value_of
2023-10-13T14:15:38.851496934 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;single_value
2023-10-13T14:15:38.851499689 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;single_value
2023-10-13T14:15:38.851502374 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;value_of
2023-10-13T14:15:38.851504629 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;value_of
2023-10-13T14:15:38.851507234 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;as_single_value
2023-10-13T14:15:38.851508897 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;as_single_value
2023-10-13T14:15:38.851510630 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;single_value
2023-10-13T14:15:38.851513576 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;single_value
2023-10-13T14:15:38.851515559 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;value_of
2023-10-13T14:15:38.851517503 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;value_of
2023-10-13T14:15:38.851520068 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;single_value
2023-10-13T14:15:38.851521731 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;single_value
2023-10-13T14:15:38.851525628 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;value_of
2023-10-13T14:15:38.851529045 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;value_of
2023-10-13T14:15:38.851533153 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;single_value
2023-10-13T14:15:38.851536339 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;single_value
2023-10-13T14:15:38.851538883 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&gt;&gt;value_of
2023-10-13T14:15:38.851542330 [anonymous-instance:main] ThreadId(1)::main::main_exec::single_value&lt;&lt;value_of
2023-10-13T14:15:38.851544704 [anonymous-instance:main] ThreadId(1)::main::main_exec&lt;&lt;single_value
2023-10-13T14:15:38.851548572 [anonymous-instance:main] ThreadId(1)::main::main_exec&gt;&gt;run_with_api
2023-10-13T14:15:38.851664621 [anonymous-instance:main] ThreadId(1)::main::main_exec::run_with_api&gt;&gt;new
2023-10-13T14:15:38.851672586 [anonymous-instance:main] ThreadId(1)::main::main_exec::run_with_api&lt;&lt;new
2023-10-13T14:15:38.851677876 [anonymous-instance:main] ThreadId(1)::main::main_exec::run_with_api&gt;&gt;init
2023-10-13T14:15:38.851684739 [anonymous-instance:main] ThreadId(1)::main::main_exec::run_with_api&lt;&lt;init
2023-10-13T14:15:38.851724064 [anonymous-instance:main] ThreadId(1)::main::main_exec::run_with_api&gt;&gt;build_microvm_from_requests
2023-10-13T14:15:38.851728171 [anonymous-instance:main] ThreadId(1)::main::main_exec::run_with_api::build_microvm_from_requests&gt;&gt;default
2023-10-13T14:15:38.851731888 [anonymous-instance:main] ThreadId(1)::main::main_exec::run_with_api::build_microvm_from_requests&lt;&lt;default
2023-10-13T14:15:38.851734634 [anonymous-instance:main] ThreadId(1)::main::main_exec::run_with_api::build_microvm_from_requests&gt;&gt;new
2023-10-13T14:15:38.851737830 [anonymous-instance:main] ThreadId(1)::main::main_exec::run_with_api::build_microvm_from_requests&lt;&lt;new
2023-10-13T14:15:38.851748550 [anonymous-instance:fc_api] ThreadId(2)&gt;&gt;new
2023-10-13T14:15:38.851761404 [anonymous-instance:fc_api] ThreadId(2)&lt;&lt;new
2023-10-13T14:15:38.851764861 [anonymous-instance:fc_api] ThreadId(2)&gt;&gt;run
2023-10-13T14:15:38.851775200 [anonymous-instance:fc_api] ThreadId(2)::run&gt;&gt;apply_filter
2023-10-13T14:15:38.851823462 [anonymous-instance:fc_api] ThreadId(2)::run&lt;&lt;apply_filter
2023-10-13T14:15:55.422397039 [anonymous-instance:fc_api] ThreadId(2)::run&gt;&gt;handle_request
2023-10-13T14:15:55.422417909 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request&gt;&gt;try_from
2023-10-13T14:15:55.422420554 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::try_from&gt;&gt;describe
2023-10-13T14:15:55.422424551 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::try_from&lt;&lt;describe
2023-10-13T14:15:55.422426395 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::try_from&gt;&gt;log_received_api_request
2023-10-13T14:15:55.422429270 [anonymous-instance:fc_api] The API server received a Get request on &quot;/&quot;.
2023-10-13T14:15:55.422431354 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::try_from&lt;&lt;log_received_api_request
2023-10-13T14:15:55.422433298 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::try_from&gt;&gt;parse_get_instance_info
2023-10-13T14:15:55.422435211 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::try_from::parse_get_instance_info&gt;&gt;new_sync
2023-10-13T14:15:55.422437165 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::try_from::parse_get_instance_info::new_sync&gt;&gt;new
2023-10-13T14:15:55.422439289 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::try_from::parse_get_instance_info::new_sync&lt;&lt;new
2023-10-13T14:15:55.422441123 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::try_from::parse_get_instance_info&lt;&lt;new_sync
2023-10-13T14:15:55.422444459 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::try_from&lt;&lt;parse_get_instance_info
2023-10-13T14:15:55.422446833 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request&lt;&lt;try_from
2023-10-13T14:15:55.422448837 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request&gt;&gt;into_parts
2023-10-13T14:15:55.422450921 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request&lt;&lt;into_parts
2023-10-13T14:15:55.422453967 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request&gt;&gt;serve_vmm_action_request
2023-10-13T14:15:55.422472552 [anonymous-instance:main] ThreadId(1)::main::main_exec::run_with_api::build_microvm_from_requests&gt;&gt;handle_preboot_request
2023-10-13T14:15:55.422480477 [anonymous-instance:main] ThreadId(1)::main::main_exec::run_with_api::build_microvm_from_requests&lt;&lt;handle_preboot_request
2023-10-13T14:15:55.422488963 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::serve_vmm_action_request&gt;&gt;convert_to_response
2023-10-13T14:15:55.422492289 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::serve_vmm_action_request::convert_to_response&gt;&gt;success_response_with_data
2023-10-13T14:15:55.422493983 [anonymous-instance:fc_api] The request was executed successfully. Status code: 200 OK.
2023-10-13T14:15:55.422498331 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::serve_vmm_action_request::convert_to_response::success_response_with_data&gt;&gt;serialize
2023-10-13T14:15:55.422501387 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::serve_vmm_action_request::convert_to_response::success_response_with_data::serialize&gt;&gt;fmt
2023-10-13T14:15:55.422506086 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::serve_vmm_action_request::convert_to_response::success_response_with_data::serialize&lt;&lt;fmt
2023-10-13T14:15:55.422509171 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::serve_vmm_action_request::convert_to_response::success_response_with_data&lt;&lt;serialize
2023-10-13T14:15:55.422511776 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::serve_vmm_action_request::convert_to_response&lt;&lt;success_response_with_data
2023-10-13T14:15:55.422514371 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request::serve_vmm_action_request&lt;&lt;convert_to_response
2023-10-13T14:15:55.422516385 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request&lt;&lt;serve_vmm_action_request
2023-10-13T14:15:55.422518719 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request&gt;&gt;take_deprecation_message
2023-10-13T14:15:55.422520533 [anonymous-instance:fc_api] ThreadId(2)::run::handle_request&lt;&lt;take_deprecation_message
2023-10-13T14:15:55.422522847 [anonymous-instance:fc_api] ThreadId(2)::run&lt;&lt;handle_request
2023-10-13T14:15:55.422525422 [anonymous-instance:fc_api] Total previous API call duration: 132 us.

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="using-the-firecracker-virtio-vsock-device"><a class="header" href="#using-the-firecracker-virtio-vsock-device">Using the Firecracker Virtio-vsock Device</a></h1>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ul>
<li><a href="vsock.html#prerequisites">Prerequisites</a></li>
<li><a href="vsock.html#firecracker-virtio-vsock-design">Firecracker Virtio-vsock Design</a></li>
<li><a href="vsock.html#setting-up-the-virtio-vsock-device">Setting up the Virtio-vsock Device</a></li>
<li><a href="vsock.html#examples">Examples</a></li>
<li><a href="vsock.html#known-issues">Known Issues</a></li>
</ul>
<h2 id="prerequisites-6"><a class="header" href="#prerequisites-6">Prerequisites</a></h2>
<p>This document assumes the reader is familiar with running Firecracker and
issuing API commands over its API socket. For a more details on how to run
Firecracker, check out the <a href="getting-started.html">getting started guide</a>.</p>
<p>Familiarity with socket programming, in particular Unix sockets, is also
assumed.</p>
<h3 id="kernel-configs"><a class="header" href="#kernel-configs">Kernel configs</a></h3>
<ul>
<li>Host kernel config has: <code>CONFIG_VHOST_VSOCK=m</code></li>
<li>Guest kernel config has: <code>CONFIG_VIRTIO_VSOCKETS=y</code></li>
</ul>
<p>To confirm that vsock can be used, run below command inside guest:</p>
<pre><code class="language-bash">ls /dev/vsock
</code></pre>
<p>and confirm that the <code>/dev/vsock</code> device is available.</p>
<p>Reference the guest kernel configuration that Firecracker is
using in its CI can be found <a href="../resources/guest_configs/">here</a>.</p>
<h2 id="firecracker-virtio-vsock-design"><a class="header" href="#firecracker-virtio-vsock-design">Firecracker Virtio-vsock Design</a></h2>
<p>The Firecracker vsock device aims to provide full virtio-vsock support to
software running inside the guest VM, while bypassing vhost kernel code on the
host. To that end, Firecracker implements the virtio-vsock device model, and
mediates communication between AF_UNIX sockets (on the host end) and AF_VSOCK
sockets (on the guest end).</p>
<p>In order to provide channel multiplexing the guest <code>AF_VSOCK</code> ports are mapped
1:1 to <code>AF_UNIX</code> sockets on the host. The virtio-vsock device must be
configured with a path to an <code>AF_UNIX</code> socket on the host (e.g.
<code>/path/to/v.sock</code>). There are two scenarios to be considered, depending on
where the connection is initiated.</p>
<h3 id="host-initiated-connections"><a class="header" href="#host-initiated-connections">Host-Initiated Connections</a></h3>
<p>When a microvm having a vsock device attached is started, Firecracker will
begin listening on an AF_UNIX socket (e.g. <code>/path/to/v.sock</code>). When the host
needs to initiate a connection, it should connect to that Unix socket, then
send a connect command, in text form, specifying the destination AF_VSOCK port:
&quot;CONNECT PORT\n&quot;. Where PORT is the decimal port number, and &quot;\n&quot; is EOL (ASCII
0x0A). Following that, the same connection will be forwarded by Firecracker to
the guest software listening on that port, thus establishing the requested
channel. If the connection has been established, Firecracker will send an
acknowledgement message to the connecting end (host-side), in the form
&quot;OK PORT\n&quot;, where <code>PORT</code> is the vsock port number assigned to
the host end. If no one is listening, Firecracker will terminate the host
connection.</p>
<p>Client A initiates connection to Server A in <a href="vsock.html#vsock-connections">figure below</a>:</p>
<ol>
<li>Host: At VM configuration time, add a virtio-vsock device, with some path
specified in <code>uds_path</code>;</li>
<li>Guest: create an AF_VSOCK socket and <code>listen()</code> on <code>&lt;port_num&gt;</code>;</li>
<li>Host: <code>connect()</code> to AF_UNIX at <code>uds_path</code>.</li>
<li>Host: <code>send()</code> &quot;CONNECT <code>&lt;port_num&gt;</code>\n&quot;.</li>
<li>Guest: <code>accept()</code> the new connection.</li>
<li>Host: <code>read()</code> &quot;OK <code>&lt;assigned_hostside_port&gt;</code>\n&quot;.</li>
</ol>
<p>The channel is established between the sockets obtained at steps 3 (host)
and 5 (guest).</p>
<h3 id="guest-initiated-connections"><a class="header" href="#guest-initiated-connections">Guest-Initiated Connections</a></h3>
<p>When the virtio-vsock device model in Firecracker detects a connection request
coming from the guest (a VIRTIO_VSOCK_OP_REQUEST packet), it tries to forward
the connection to an AF_UNIX socket listening on the host, at
<code>/path/to/v.sock_PORT</code> (or whatever path was configured via the <code>uds_path</code>
property of the vsock device), where <code>PORT</code> is the destination port (in
decimal), as specified in the connection request packet. If no such socket
exists, or no one is listening on it, a connection cannot be established, and a
VIRTIO_VSOCK_OP_RST packet will be sent back to the guest.</p>
<p>Client B initiates connection to Server B in <a href="vsock.html#vsock-connections">figure below</a>:</p>
<ol>
<li>Host: At VM configuration time, add a virtio-vsock device, with some
<code>uds_path</code> (e.g. <code>/path/to/v.sock</code>).</li>
<li>Host: create and listen on an AF_UNIX socket at <code>/path/to/v.sock_PORT</code>.</li>
<li>Guest: create an AF_VSOCK socket and connect to <code>HOST_CID</code> (i.e. integer
value 2) and <code>PORT</code>;</li>
<li>Host: <code>accept()</code> the new connection.</li>
</ol>
<p>The channel is established between the sockets obtained at steps 4 (host)
and 3 (guest).</p>
<p><img src="images/vsock-connections.png?raw=true" alt="Vsock Connections" title="Vsock Connections" /></p>
<h2 id="setting-up-the-virtio-vsock-device"><a class="header" href="#setting-up-the-virtio-vsock-device">Setting up the virtio-vsock device</a></h2>
<p>The virtio-vsock device will require a CID, and the path to a backing
AF_UNIX socket:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
  -X PUT 'http://localhost/vsock' \
  -H 'Accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
      &quot;guest_cid&quot;: 3,
      &quot;uds_path&quot;: &quot;./v.sock&quot;
  }'
</code></pre>
<p>Once the microvm is started, Firecracker will create and start listening on the
AF_UNIX socket at <code>uds_path</code>. Incoming connections will get forwarded to the
guest microvm, and translated to AF_VSOCK. The destination port is expected to
be specified by sending the text command &quot;CONNECT <code>&lt;port_num&gt;</code>\n&quot;, immediately
after the AF_UNIX connection is established. Connections initiated from within
the guest will be forwarded to AF_UNIX sockets expected to be listening at
<code>./v.sock_&lt;port_num&gt;</code>. I.e. a guest connection to port 52 will get forwarded to
<code>./v.sock_52</code>.</p>
<h2 id="examples-1"><a class="header" href="#examples-1">Examples</a></h2>
<p>The examples below assume a running microvm, with a vsock device configured as
shown <a href="vsock.html#setting-up-the-virtio-vsock-device">above</a> and
<a href="http://www.dest-unreach.org/socat/">socat</a> version 1.7.4.0 or later.</p>
<h3 id="connecting-from-host-to-guest"><a class="header" href="#connecting-from-host-to-guest">Connecting From Host to Guest</a></h3>
<p>First, make sure the vsock port is bound and listened to on the guest side.
Say, port 52:</p>
<pre><code class="language-bash">socat VSOCK-LISTEN:52,fork -
</code></pre>
<p>On the host side, connect to <code>./v.sock</code> and issue a connection request to that
port:</p>
<pre><code class="language-bash">$ socat - UNIX-CONNECT:./v.sock
CONNECT 52
</code></pre>
<p><code>socat</code> will display the connection acknowledgement message:</p>
<pre><code class="language-console">OK 1073741824
</code></pre>
<p>The connection should now be established (in the above example, between
<code>socat</code> on the guest and the host side).</p>
<h3 id="connecting-from-guest-to-host"><a class="header" href="#connecting-from-guest-to-host">Connecting From Guest To Host</a></h3>
<p>First make sure the AF_UNIX corresponding to your desired port is listened to
on the host side:</p>
<pre><code class="language-bash">socat - UNIX-LISTEN:./v.sock_52
</code></pre>
<p>On the guest side, create an AF_VSOCK socket and connect it to the previously
chosen port on the host (CID=2):</p>
<pre><code class="language-bash">socat - VSOCK-CONNECT:2:52
</code></pre>
<h2 id="known-issues"><a class="header" href="#known-issues">Known issues</a></h2>
<p>Vsock snapshot support is currently limited. Please see
<a href="snapshotting/snapshot-support.html#vsock-device-limitation">Snapshotting vsock limitation</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-request"><a class="header" href="#api-request">API Request</a></h1>
<p>TODO</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="actions-api-request"><a class="header" href="#actions-api-request">Actions API Request</a></h1>
<p>Firecracker microVMs can execute actions that can be triggered via <code>PUT</code>
requests on the <code>/actions</code> resource.</p>
<p>Details about the required fields can be found in the
<a href="../../src/api_server/swagger/firecracker.yaml">swagger definition</a>.</p>
<h2 id="instancestart"><a class="header" href="#instancestart">InstanceStart</a></h2>
<p>The <code>InstanceStart</code> action powers on the microVM and starts the guest OS. It
does not have a payload. It can only be successfully called once.</p>
<h3 id="instancestart-example"><a class="header" href="#instancestart-example">InstanceStart Example</a></h3>
<pre><code class="language-bash">curl --unix-socket ${socket} -i \
     -X PUT &quot;http://localhost/actions&quot; \
     -d '{ &quot;action_type&quot;: &quot;InstanceStart&quot; }'
</code></pre>
<h2 id="flushmetrics"><a class="header" href="#flushmetrics">FlushMetrics</a></h2>
<p>The <code>FlushMetrics</code> action flushes the metrics on user demand.</p>
<h3 id="flushmetrics-example"><a class="header" href="#flushmetrics-example">FlushMetrics Example</a></h3>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT &quot;http://localhost/actions&quot; \
    -d '{ &quot;action_type&quot;: &quot;FlushMetrics&quot; }'
</code></pre>
<h2 id="intel-and-amd-only-sendctrlaltdel"><a class="header" href="#intel-and-amd-only-sendctrlaltdel">[Intel and AMD only] SendCtrlAltDel</a></h2>
<p>This action will send the CTRL+ALT+DEL key sequence to the microVM. By
convention, this sequence has been used to trigger a soft reboot and, as such,
most Linux distributions perform an orderly shutdown and reset upon receiving
this keyboard input. Since Firecracker exits on CPU reset, <code>SendCtrlAltDel</code>
can be used to trigger a clean shutdown of the microVM.</p>
<p>For this action, Firecracker emulates a standard AT keyboard, connected via an
i8042 controller. Driver support for both these devices needs to be present in
the guest OS. For Linux, that means the guest kernel needs
<code>CONFIG_SERIO_I8042</code> and <code>CONFIG_KEYBOARD_ATKBD</code>.</p>
<p><strong>Note1</strong>: at boot time, the Linux driver for i8042 spends
a few tens of milliseconds probing the device. This can be disabled by using
these kernel command line parameters:</p>
<pre><code class="language-console">i8042.noaux i8042.nomux i8042.nopnp i8042.dumbkbd
</code></pre>
<p><strong>Note2</strong> This action is only supported on <code>x86_64</code> architecture.</p>
<h3 id="sendctrlaltdel-example"><a class="header" href="#sendctrlaltdel-example">SendCtrlAltDel Example</a></h3>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT &quot;http://localhost/actions&quot; \
    -d '{ &quot;action_type&quot;: &quot;SendCtrlAltDel&quot; }'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="block-device-caching-strategies"><a class="header" href="#block-device-caching-strategies">Block device caching strategies</a></h1>
<p>Firecracker offers the possiblity of choosing the block device caching
strategy. Caching strategy affects the path data written from inside the
microVM takes to the host persistent storage.</p>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How it works</a></h2>
<p>When installing a block device through a PUT /drives API call, users can choose
the caching strategy by inserting a <code>cache_type</code> field in the JSON body of the
request. The available cache types are:</p>
<ul>
<li><code>Unsafe</code></li>
<li><code>Writeback</code></li>
</ul>
<h3 id="unsafe-mode-default"><a class="header" href="#unsafe-mode-default">Unsafe mode (default)</a></h3>
<p>When configuring the block caching strategy to <code>Unsafe</code>, the device will not
advertise the VirtIO <code>flush</code> feature to the guest driver.</p>
<h3 id="writeback-mode"><a class="header" href="#writeback-mode">Writeback mode</a></h3>
<p>When configuring the block caching strategy to <code>Writeback</code>, the device will
advertise the VirtIO <code>flush</code> feature to the guest driver. If negotiated when
activating the device, the guest driver will be able to send flush requests
to the device. When the device executes a flush request, it will perform an
<code>fsync</code> syscall on the backing block file, committing all data in the host
page cache to disk.</p>
<h2 id="supported-use-cases"><a class="header" href="#supported-use-cases">Supported use cases</a></h2>
<p>The caching strategy should be used in order to make a trade-off:</p>
<ul>
<li><code>Unsafe</code>
<ul>
<li>enhances performance as fewer syscalls and IO operations are performed when
running workloads</li>
<li>sacrifices data integrity in situations where the host simply loses the
contents of the page cache without committing them to the backing storage
(such as a power outage)</li>
<li>recommended for use cases with ephemeral storage, such as serverless
environments</li>
</ul>
</li>
<li><code>Writeback</code>
<ul>
<li>ensures that once a flush request was acknowledged by the host, the data
is committed to the backing storage</li>
<li>sacrifices performance, from boot time increases to greater
emulation-related latencies when running workloads</li>
<li>recommended for use cases with low power environments, such as embedded
environments</li>
</ul>
</li>
</ul>
<h2 id="how-to-configure-it"><a class="header" href="#how-to-configure-it">How to configure it</a></h2>
<p>Example sequence that configures a block device with a caching strategy:</p>
<pre><code class="language-bash">curl --unix-socket ${socket} -i \
     -X PUT &quot;http://localhost/drives/dummy&quot; \
     -H &quot;accept: application/json&quot; \
     -H &quot;Content-Type: application/json&quot; \
     -d &quot;{
             \&quot;drive_id\&quot;: \&quot;dummy\&quot;,
             \&quot;path_on_host\&quot;: \&quot;${drive_path}\&quot;,
             \&quot;is_root_device\&quot;: false,
             \&quot;is_read_only\&quot;: false,
             \&quot;cache_type\&quot;: \&quot;Writeback\&quot;
         }&quot;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="block-device-io-engine"><a class="header" href="#block-device-io-engine">Block device IO engine</a></h1>
<p>For all Firecracker versions prior to v1.0.0, the emulated block device uses a
synchronous IO engine for executing the device requests, based on blocking
system calls.</p>
<p>Firecracker 1.0.0 adds support for an asynchronous block device IO engine.</p>
<blockquote>
<p>[!WARNING]
Support is currently in <strong>developer preview</strong>. See
<a href="block-io-engine.html#developer-preview-status">this section</a> for more info.</p>
</blockquote>
<p>The <code>Async</code> engine leverages <a href="https://kernel.dk/io_uring.pdf"><code>io_uring</code></a> for
executing requests in an async manner, therefore getting overall higher
throughput by taking better advantage of the block device hardware, which
typically supports queue depths greater than 1.</p>
<p>The block IO engine is configured via the PUT /drives API call (pre-boot only),
with the <code>io_engine</code> field taking two possible values:</p>
<ul>
<li><code>Sync</code> (default)</li>
<li><code>Async</code> (in <a href="../RELEASE_POLICY.html">developer preview</a>)</li>
</ul>
<p>The <code>Sync</code> variant is the default, in order to provide backwards compatibility
with older Firecracker versions.</p>
<p><strong>Note</strong> <a href="./block-vhost-user.html">vhost-user block device</a> is another option
for block IO that requires an external backend process.</p>
<h2 id="example-configuration"><a class="header" href="#example-configuration">Example configuration</a></h2>
<pre><code class="language-bash">curl --unix-socket ${socket} -i \
     -X PUT &quot;http://localhost/drives/rootfs&quot; \
     -H &quot;accept: application/json&quot; \
     -H &quot;Content-Type: application/json&quot; \
     -d &quot;{
             \&quot;drive_id\&quot;: \&quot;rootfs\&quot;,
             \&quot;path_on_host\&quot;: \&quot;${drive_path}\&quot;,
             \&quot;is_root_device\&quot;: true,
             \&quot;is_read_only\&quot;: false,
             \&quot;io_engine\&quot;: \&quot;Sync\&quot;
         }&quot;
</code></pre>
<h2 id="host-requirements"><a class="header" href="#host-requirements">Host requirements</a></h2>
<p>Firecracker requires a minimum host kernel version of 5.10.51 for the <code>Async</code>
IO engine.</p>
<p>This requirement is based on the availability of the <code>io_uring</code> subsystem, as
well as a couple of features and bugfixes that were added in newer kernel
versions.</p>
<p>If a block device is configured with the <code>Async</code> io_engine on a host kernel
older than 5.10.51, the API call will return a 400 Bad Request, with a
suggestive error message.</p>
<h2 id="performance-considerations"><a class="header" href="#performance-considerations">Performance considerations</a></h2>
<p>The performance is strictly tied to the host kernel version. The gathered data
may not be relevant for modified/newer kernels than 5.10.</p>
<h3 id="device-creation"><a class="header" href="#device-creation">Device creation</a></h3>
<p>When using the <code>Async</code> variant, there is added latency on device creation (up
to ~110 ms), caused by the extra io_uring system calls performed by
Firecracker.
This translates to higher latencies on either of these operations:</p>
<ul>
<li>API call duration for block device config</li>
<li>Boot time for VMs started via JSON config files</li>
<li>Snapshot restore time</li>
</ul>
<p>For use-cases where the lowest latency on the aforementioned operations is
desired, it is recommended to use the <code>Sync</code> IO engine.</p>
<h3 id="block-iops-and-efficiency"><a class="header" href="#block-iops-and-efficiency">Block IOPS and efficiency</a></h3>
<p>The <code>Async</code> engine performance potential is showcased when the block device
backing files are placed on a physical disk that supports efficient parallel
execution of requests, like an NVME drive.
It's also recommended to evenly distribute the backing files across the
available drives of a host, to limit contention in high-density scenarios.</p>
<p>The performance measurements we've done were made on NVME drives, and we've
discovered that:</p>
<p>For <strong>read</strong> workloads which operate on data that is not present in the
host page cache, the performance improvement for <code>Async</code> is about 1.5x-3x in
overall efficiency (IOPS per CPU load) and up to 30x in total IOPS.</p>
<p>For <strong>write</strong> workloads, the <code>Async</code> engine brings an improvement of about
20-45% in total IOPS but performs worse than the <code>Sync</code> engine in total
efficiency (IOPS per CPU load).
This means that while Firecracker will achieve better performance, it will be
at the cost of consuming more CPU for the kernel workers. In this case, the VMM
cpu load is also reduced, which should translate into performance increase in
hybrid workloads (block+net+vsock).</p>
<p>Whether or not using the <code>Async</code> engine is a good idea performance-wise depends
on the workloads and the amount of spare CPU available on a host.
According to our NVME experiments, io_uring will always bring performance
improvements (granted that there are enough available CPU resources).</p>
<p>It is recommended that users perform some tests with examples of expected
workloads and measure the efficiency as (IOPS/CPU load).</p>
<h2 id="developer-preview-status"><a class="header" href="#developer-preview-status">Developer preview status</a></h2>
<p>View the <a href="../RELEASE_POLICY.html">release policy</a> for information about developer
preview terminology.</p>
<p>The <code>Async</code> io_engine is not yet suitable for production use. It will be made
available for production once Firecracker has support for a host kernel that
implements mitigation mechanisms for the following threats:</p>
<h3 id="threat-1-pid-exhaustion"><a class="header" href="#threat-1-pid-exhaustion">Threat 1: PID exhaustion</a></h3>
<p>The number of io_uring kernel workers assigned to one Firecracker block device
is upper-bounded by:</p>
<pre><code>(1 + NUMA_COUNT * min(size_of_ring, 4 * NUMBER_OF_CPUS)
</code></pre>
<p>This formula is derived from the 5.10 linux kernel code, while <code>size_of_ring</code>
is hardcoded to <code>128</code> in Firecracker.</p>
<p>Depending on the number of microVMs that can concurrently live on a host and
the number of block devices configured for each microVM, the kernel PID limit
may be reached, resulting in failure to create any new process.</p>
<p>Kernels starting with 5.15 expose a configuration option for customising this
upper bound. Once possible, we plan on exposing this in the Firecracker drive
configuration interface.</p>
<h3 id="threat-2-worker-thread-resource-consumption"><a class="header" href="#threat-2-worker-thread-resource-consumption">Threat 2: worker thread resource consumption</a></h3>
<p>The io_uring kernel workers are spawned in the root cgroup of the system.
They don’t inherit the Firecracker cgroup, cannot be moved out of the root
cgroup and their names don't contain any information about the microVM's PID.
This makes it impossible to attribute a worker to a specific Firecracker VM
and limit the CPU and memory consumption of said workers via cgroups.</p>
<p>Starting with kernel 5.12 (currently unsupported), the Firecracker cgroup is
inherited by the io_uring workers.</p>
<h3 id="path-to-ga"><a class="header" href="#path-to-ga">Path to GA</a></h3>
<p>We plan on marking the Async engine as production ready once an LTS linux
kernel including mitigations for the aforementioned mitigations is released and
support for it is added in Firecracker.</p>
<p>Read more about Firecracker's <a href="../kernel-policy.html">kernel support policy</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vhost-user-block-device"><a class="header" href="#vhost-user-block-device">Vhost-user block device</a></h1>
<blockquote>
<p>[!WARNING]
Support is currently in <strong>developer preview</strong>. See
<a href="block-vhost-user.html#developer-preview-status">this section</a> for more info.</p>
</blockquote>
<p>As an alternative to <a href="block-io-engine.html">file-backed block device</a> <code>Sync</code> and
<code>Async</code> engines, Firecracker supports a vhost-user block device.</p>
<p>There is a good introduction of how a vhost-user block device works
in general at <a href="https://archive.fosdem.org/2023/schedule/event/sds_vhost_user_blk">FOSDEM23</a>.</p>
<p><a href="https://qemu-project.gitlab.io/qemu/interop/vhost-user.html">Vhost-user</a>
is a userspace protocol that allows to delegate Virtio queue processing
to another userspace process on the host, as opposed to performing this task
within Firecracker's VMM thread.</p>
<p>In the vhost-user architecture, the VMM acts as a vhost-user frontend and
it is responsible for:</p>
<ul>
<li>connecting to the backend via a Unix domain socket (UDS)</li>
<li>feature negotiation with the backend and the guest</li>
<li>handling device configuration requests from the guest</li>
<li>sharing sufficient information about the guest memory and Virtio queues
with the backend</li>
</ul>
<p>The vhost-user backend receives the information from the frontend and performs
handling of IO requests from the guest.</p>
<p>The UDS socket is only used for control plane purposes
and does not participate in the data plane.</p>
<p>Firecracker only implements a vhost-user frontend. Users are free
to choose from <a href="block-vhost-user.html#backends">existing open source backends</a> or implement their
own.</p>
<h2 id="topology"><a class="header" href="#topology">Topology</a></h2>
<p>Each vhost-user device connects to its own UDS socket. There is no way for
multiple devices to share a single socket, as there is no way to differentiate
messages related to devices at the vhost-user protocol level.</p>
<p>Each device can be served by a separate backend or a single backend can serve
multiple devices.</p>
<h2 id="interactions-with-the-backend"><a class="header" href="#interactions-with-the-backend">Interactions with the backend</a></h2>
<p>There are three points when the vhost-user frontend communicates with
the backend:</p>
<ol>
<li>Device initialisation. When a vhost-user device is created, Firecracker
connects to the corresponding UDS socket and negotiates Virtio and Vhost
features with backend and retrieves device configuration.</li>
<li>Device activation. When the guest driver finishes setting up the device,
Firecracker shares memory tables and Virtio queue information with the backend.
As a part of this, Firecracker shares file descriptors for guest's memory
regions, as well as file descriptors for queue notifications.</li>
<li>Config update. When receving a <a href="./patch-block.html#updating-vhost-user-block-devices-after-boot"><code>PATCH</code> request</a>
on a vhost-user backed drive, Firecracker rerequests the device config
from the backend in order to make the new config available to the guest.</li>
</ol>
<h2 id="advantages"><a class="header" href="#advantages">Advantages</a></h2>
<p>While vhost-user block is considered an optimisation to Firecracker IO, a naive
implementation of the backend is not going to improve performance.</p>
<p>The major advantage of using a vhost-user device is that the backend can
implement custom processing logic. It can use intelligent algorithms to serve
block requests, eg by fetching the block device data over the network or using
sophisticated readahead logic. In such cases, the performance improvement will
be coming from the fact that the custom logic is implemented in the same
process that handles Virtio queues, which reduces the number of required
context switches.</p>
<h2 id="backends"><a class="header" href="#backends">Backends</a></h2>
<p>There are a number of open source implementations of a vhost-user backend
available for reference that can help developing a custom backend:</p>
<ol>
<li><a href="https://github.com/qemu/qemu/tree/master/contrib/vhost-user-blk">Qemu backend</a></li>
<li><a href="https://github.com/cloud-hypervisor/cloud-hypervisor/tree/main/vhost_user_block">Cloud Hypervisor backend</a></li>
<li><a href="https://github.com/google/crosvm/blob/main/devices/src/virtio/vhost/user/device/block.rs">crosvm backend</a></li>
<li><a href="https://github.com/spdk/spdk/blob/master/lib/vhost/vhost_blk.c">SPDK backend</a></li>
</ol>
<h2 id="security-considerations"><a class="header" href="#security-considerations">Security considerations</a></h2>
<h3 id="guest-memory-sharing"><a class="header" href="#guest-memory-sharing">Guest memory sharing</a></h3>
<p>By design, a vhost-user frontend must share file descriptors
of all guest memory regions to the backend. In order to achive that,
guest memory is created as a <a href="https://man7.org/linux/man-pages/man2/memfd_create.2.html">memfd</a>
and mapped as <code>MAP_SHARED</code>.</p>
<h4 id="file-descriptor-in-procfs"><a class="header" href="#file-descriptor-in-procfs">File descriptor in procfs</a></h4>
<p>An open <code>memfd</code> is reflected in <code>procfs</code> as any other open file descriptor:</p>
<pre><code class="language-shell">$ ls -l /proc/{pid}/fd | grep memfd
lrwx------ 1 1234 1234 64 Nov  2 13:39 32 -&gt; /memfd:guest_mem (deleted)
</code></pre>
<p>Any process on the host that has access to this file in <code>procfs</code> will be able
to map the file descriptor and observe runtime behaviour of the guest.</p>
<p>At the moment, Firecracker does not close the <code>memfd</code>, because it must remain open
until all the configured vhost-user devices have been activated and their info
shared with the backends. This kind of tracking is not implemented in Firecracker,
but may be implemented in the future. Meanwhile, users need to make sure that
the access to the Firecracker's <code>procfs</code> tree is restricted to trusted processes
on the host.</p>
<p>On the backend side, it is advised that the backend closes
the guest memory region file descriptors after mapping them into its own
address space.</p>
<h4 id="resource-limit-in-jailer"><a class="header" href="#resource-limit-in-jailer">Resource limit in jailer</a></h4>
<p>The Firecracker <a href="../jailer.html">jailer</a> allows to configure resource limits
for the Firecracker process. Specifically, it allows to set the maximum file
size. Since <code>memfd</code> that is used to back the guest memory is considered a file,
the file size resource limit cannot be less than the biggest guest memory
region. This does not require any special action from a user, but needs to be
taken into consideration.</p>
<h3 id="remote-code-execution-in-the-backend"><a class="header" href="#remote-code-execution-in-the-backend">Remote code execution in the backend</a></h3>
<p>It is recommended to run Firecracker using the <a href="../jailer.html">jailer</a>. Since
the vhost-user backend interacts with the guest via a Virtio queue, there is
a potential for the guest to exercise issues in the backend codebase
to trigger undesired behaviours. Users should consider running their backend
in a jailer or applying other adequate security measures to restrict it.</p>
<p><strong>Note</strong> <a href="../jailer.html">Firecracker jailer</a> is currently only capable
of running Firecracker as the binary. Vhost-user block device users are
expected to use another jailer to run the backend.</p>
<p>It is also recommended to use proactive security measures like running
a Virtio-level fuzzer in the guest during testing to make sure that the backend
correctly handles all possible classes of inputs (including invalid ones)
from the guest.</p>
<h3 id="rate-limiting--cgroups"><a class="header" href="#rate-limiting--cgroups">Rate limiting / cgroups</a></h3>
<p>Virtio block device in Firecracker has a <a href="../design.html#io-storage-networking-and-rate-limiting">rate limiting capability</a>.</p>
<p>In the vhost-user case, Firecracker does not participate in handling requests
from the guest, so rate limiting becomes backend's responsibility.</p>
<p>As an additional indirect measure, users can make use of <code>cgroups</code> settings
(either via Firecracker jailer or independently) in order to restrict host CPU
consumption of the guest, which would transitively limit guest's IO activity.</p>
<h3 id="protection-against-defects-in-the-backend-code"><a class="header" href="#protection-against-defects-in-the-backend-code">Protection against defects in the backend code</a></h3>
<p>Due to potential defects in the backend (eg mislocating Virtio queues or writes
to a wrong location in the guest memory), the guest execution may be affected.
It is advised that customers monitor guest's health periodically.</p>
<p>Additionally, in order to avoid orhpaned Firecracker processes if the backend
crashes, the backend may need to send a signal, such as <code>SIGBUS</code>,
to the Firecracker process for it to exit as well.</p>
<h3 id="backend-timeouts"><a class="header" href="#backend-timeouts">Backend timeouts</a></h3>
<p>In order to correctly handle the case where the Firecracker process exits
before it exchanges all the expected data with the backend, the backend may
need to implement a timeout for how long it waits for Firecracker to connect
and/or to exchange the data via the vhost-user protocol and exit to avoid
resource exhaustion.</p>
<h2 id="snapshot-support"><a class="header" href="#snapshot-support">Snapshot support</a></h2>
<p>At the moment, <a href="../snapshotting">snapshotting</a> is not supported for microVMs
that have vhost-user devices configured. An attempt to take a snapshot of such
a microVM will fail. It is planned to add support for that in the future.</p>
<h2 id="example-configuration-1"><a class="header" href="#example-configuration-1">Example configuration</a></h2>
<p>Run a vhost-user backend, eg Qemu backend:</p>
<pre><code class="language-bash">vhost-user-blk --socket-path=${backend_socket} --blk-file=${drive_path}
</code></pre>
<p>Firecracker API request to add a vhost-user block device:</p>
<pre><code class="language-bash">curl --unix-socket ${fc_socket} -i \
     -X PUT &quot;http://localhost/drives/scratch&quot; \
     -H &quot;accept: application/json&quot; \
     -H &quot;Content-Type: application/json&quot; \
     -d &quot;{
             \&quot;drive_id\&quot;: \&quot;scratch\&quot;,
             \&quot;socket\&quot;: \&quot;${backend_socket}\&quot;,
             \&quot;is_root_device\&quot;: false
         }&quot;
</code></pre>
<p><strong>Note</strong> Unlike Virtio block device, there is no way to configure a <code>readonly</code>
vhost-user drive on the Firecracker side. Instead, this configuration belongs
to the backend. Whenever the backend advertises the <code>VIRTIO_BLK_F_RO</code> feature,
Firecracker will accept it, and the device will act as readonly.</p>
<p><strong>Note</strong> Whenever a <code>PUT</code> request is sent to the <code>/drives</code> endpoint for
a vhost-user device with the <code>id</code> that already exists, Firecracker will close
the existing connection to the backend and will open a new one. Users may need
to restart their backend if they do so.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="updating-block-devices-after-boot"><a class="header" href="#updating-block-devices-after-boot">Updating block devices after boot</a></h1>
<h2 id="updating-virtio-block-devices-after-boot"><a class="header" href="#updating-virtio-block-devices-after-boot">Updating Virtio block devices after boot</a></h2>
<p>Firecracker offers support to update attached block devices after the microVM
has been started. This is provided via PATCH /drives API which notifies
Firecracker that the underlying block file has been changed on the host. It
should be called when the path to the block device is changed or if the file
size has been modified. It is important to note that external changes to the
block device file do not automatically trigger a notification in Firecracker
so the explicit PATCH API call is mandatory.</p>
<h3 id="how-it-works-1"><a class="header" href="#how-it-works-1">How it works</a></h3>
<p>The implementation of the PATCH /drives API does not modify the host backing
file. It only updates the emulation layer block device properties, path and
length and then triggers a virtio device reconfiguration that is handled by the
guest driver which will update the size of the raw block device.
With that being said, a sequence which performs resizing/altering of the block
underlying host file followed by a PATCH /drives API call is not an atomic
operation as the guest can also modify the block file via emulation during
the sequence, if the raw block device is mounted or accessible.</p>
<h3 id="supported-use-case"><a class="header" href="#supported-use-case">Supported use case</a></h3>
<p>This feature was designed to work with a cooperative guest in order to
effectively simulate hot plug/unplug functionality for block devices.</p>
<p>The following guarantees need to be provided:</p>
<ul>
<li>guest did not mount the device</li>
<li>guest does not read or write from the raw block device <code>/dev/vdX</code> during the
update sequence</li>
</ul>
<p>Example sequence that configures a microVM with a placeholder drive and then
updates it with the real one:</p>
<pre><code class="language-bash"># Create and set up a block device.
touch ${ro_drive_path}

curl --unix-socket ${socket} -i \
     -X PUT &quot;http://localhost/drives/scratch&quot; \
     -H &quot;accept: application/json&quot; \
     -H &quot;Content-Type: application/json&quot; \
     -d &quot;{
             \&quot;drive_id\&quot;: \&quot;scratch\&quot;,
             \&quot;path_on_host\&quot;: \&quot;${ro_drive_path}\&quot;,
             \&quot;is_root_device\&quot;: false,
             \&quot;is_read_only\&quot;: true
             \&quot;rate_limiter\&quot;: {
                \&quot;bandwidth\&quot;: {
                        \&quot;size\&quot;: 100000,
                        \&quot;one_time_burst\&quot;: 4096,
                        \&quot;refill_time\&quot;: 150
                },
                \&quot;ops\&quot;: {
                        \&quot;size\&quot;: 10,
                        \&quot;refill_time\&quot;: 250
                }
            }
         }&quot;
# Finish configuring and start the microVM. Wait for the guest to boot.

# Before mounting the block device in the guest:
# Use another backing file of different size to effectively resize the
# vm block device.
touch ${updated_ro_drive_path}
truncate --size ${new_size}M ${updated_ro_drive_path}
# Create a filesystem in it.
mkfs.ext4 ${updated_ro_drive_path}

# PATCH the block device to use the new backing file.
curl --unix-socket ${socket} -i \
     -X PATCH &quot;http://localhost/drives/scratch&quot; \
     -H &quot;accept: application/json&quot; \
     -H &quot;Content-Type: application/json&quot; \
     -d &quot;{
             \&quot;drive_id\&quot;: \&quot;scratch\&quot;,
             \&quot;path_on_host\&quot;: \&quot;${updated_ro_drive_path}\&quot;
         }&quot;

# It's now safe to mount the block device in the guest and use it
# with the updated backing file.
</code></pre>
<h3 id="data-integrity-and-other-issues"><a class="header" href="#data-integrity-and-other-issues">Data integrity and other issues</a></h3>
<p>We do not recommend using this feature outside of its supported use case scope.
If the required guarantees are not provided, data integrity and potential other
issues may arise depending on the actual use case. There are two major aspects
that need be considered here:</p>
<h4 id="atomicity-of-the-update-sequence"><a class="header" href="#atomicity-of-the-update-sequence">Atomicity of the update sequence</a></h4>
<p>If the guest has the opportunity to perform I/O against the block device during
the update sequence it can either read data while it is changed or can
overwrite data already written by a host process. For example a truncate
operation can be undone if the guest issues a write for the last sector of the
raw block device, or the guest application can become inconsistent or/and can
create inconsistency in the block device itself.</p>
<h4 id="in-flight-io-requests"><a class="header" href="#in-flight-io-requests">In flight I/O requests</a></h4>
<p>If the atomicity of the operation is guaranteed by using methods to make the
microVM quiescence during the update sequence (for example pausing the microVM)
the guest itself or block device can still become incosistent from in flight
I/O requests in the guest that will be executed after it is resumed.</p>
<h2 id="updating-vhost-user-block-devices-after-boot"><a class="header" href="#updating-vhost-user-block-devices-after-boot">Updating vhost-user block devices after boot</a></h2>
<p>Unlike with Virtio block device, with vhost-user block devices, Firecracker
does not interact with the underlying block file directly (the vhost-user
backend does). It means that changes to the file are not automatically seen
by Firecracker. There is a mechanism in the
<a href="https://qemu-project.gitlab.io/qemu/interop/vhost-user.html">vhost-user protocol</a>
for the backend to notify the frontend about changes in the device config
via <code>VHOST_USER_BACKEND_CONFIG_CHANGE_MSG</code> message. This requires an extra
UDS socket connection between the frontend and backend used for
backend-originated messages. This mechanism <strong>is not supported</strong>
by Firecracker. Instead, Firecracker makes use of the <code>PATCH /drives</code>
API request to get notified about such changes. Such an API request
only includes the required property (<code>drive_id</code>), because optional properties
are not relevant to vhost-user.</p>
<p>Example of a <code>PATCH</code> request for a vhost-user drive:</p>
<pre><code class="language-bash">curl --unix-socket ${socket} -i \
     -X PATCH &quot;http://localhost/drives/scratch&quot; \
     -H &quot;accept: application/json&quot; \
     -H &quot;Content-Type: application/json&quot; \
     -d &quot;{
             \&quot;drive_id\&quot;: \&quot;scratch\&quot;
         }&quot;
</code></pre>
<p>A <code>PATCH</code> request to a vhost-user drive will make Firecracker retrieve
the new device config from the backend and send a config change notification
to the guest.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="updating-a-network-interface"><a class="header" href="#updating-a-network-interface">Updating A Network Interface</a></h1>
<p>After the microVM is started, the rate limiters assigned to a network
interface can be updated via a <code>PATCH /network-interfaces/{id}</code> API
call.</p>
<p>E.g. for a network interface created with:</p>
<pre><code class="language-console">PUT /network-interfaces/iface_1 HTTP/1.1
Host: localhost
Content-Type: application/json
Accept: application/json

{
    &quot;iface_id&quot;: &quot;iface_1&quot;,
    &quot;host_dev_name&quot;: &quot;fctap1&quot;,
    &quot;guest_mac&quot;: &quot;06:00:c0:a8:34:02&quot;,
    &quot;rx_rate_limiter&quot;: {
        &quot;bandwidth&quot;: {
            &quot;size&quot;: 1024,
            &quot;one_time_burst&quot;: 1048576,
            &quot;refill_time&quot;: 1000
        }
    },
    &quot;tx_rate_limiter&quot;: {
        &quot;bandwidth&quot;: {
            &quot;size&quot;: 1024,
            &quot;one_time_burst&quot;: 1048576,
            &quot;refill_time&quot;: 1000
        }
    }
}
</code></pre>
<p>A <code>PATCH</code> request can be sent at any future time, to update the rate
limiters:</p>
<pre><code class="language-console">PATCH /network-interfaces/iface_1 HTTP/1.1
Host: localhost
Content-Type: application/json
Accept: application/json

{
    &quot;iface_id&quot;: &quot;iface_1&quot;,
    &quot;rx_rate_limiter&quot;: {
        &quot;bandwidth&quot;: {
            &quot;size&quot;: 1048576,
            &quot;refill_time&quot;: 1000
        },
        &quot;ops&quot;: {
            &quot;size&quot;: 2000,
            &quot;refill_time&quot;: 1000
        }
    }
}
</code></pre>
<p>The full specification of the data structures available for this call can be
found in our <a href="../../src/api_server/swagger/firecracker.yaml">OpenAPI spec</a>.</p>
<p><strong>Note</strong>: The data provided for the update is merged with the existing data.
In the above example, the RX rate limit is updated, but the TX rate limit
remains unchanged.</p>
<h2 id="removing-rate-limiting"><a class="header" href="#removing-rate-limiting">Removing Rate Limiting</a></h2>
<p>A rate limit can be disabled by providing a 0-sized token bucket. E.g.,
following the above example, the TX rate limit can be disabled with:</p>
<pre><code class="language-console">PATCH /network-interfaces/iface_1 HTTP/1.1
Host: localhost
Content-Type: application/json
Accept: application/json

{
    &quot;iface_id&quot;: &quot;iface_1&quot;,
    &quot;tx_rate_limiter&quot;: {
        &quot;bandwidth&quot;: {
            &quot;size&quot;: 0,
            &quot;refill_time&quot;: 0
        },
        &quot;ops&quot;: {
            &quot;size&quot;: 0,
            &quot;refill_time&quot;: 0
        }
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="microvm-state-serialization-benchmarks"><a class="header" href="#microvm-state-serialization-benchmarks">MicroVM state serialization benchmarks</a></h1>
<p>The benchmarks have been performed using a synthetic state snapshot that
contains 100 structs and a 10k element array.
Source code: <a href="../../src/snapshot/benches/main.rs">src/snapshot/benches/main.rs</a>.
Snapshot size: 83886 bytes.</p>
<h2 id="host-configuration"><a class="header" href="#host-configuration">Host configuration</a></h2>
<pre><code class="language-console">- Architecture:        x86_64
- CPU op-mode(s):      32-bit, 64-bit
- Byte Order:          Little Endian
- CPU(s):              4
- Thread(s) per core:  2
- Core(s) per socket:  2
- Socket(s):           1
- NUMA node(s):        1
- Vendor ID:           GenuineIntel
- CPU family:          6
- Model:               142
- Model name:          Intel(R) Core(TM) i7-7600U CPU @ 2.80GHz
- Stepping:            9
- CPU MHz:             1100.008
- CPU max MHz:         3900.0000
- CPU min MHz:         400.0000
- BogoMIPS:            5799.77
- Virtualization:      VT-x
- L1d cache:           32K
- L1i cache:           32K
- L2 cache:            256K
- L3 cache:            4096K
- NUMA node0 CPU(s):   0-3
- Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca
                       cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht
                       tmpbe syscall nx pdpe1gb rdtscp lm constant_tsc art
                       arch_perfmon pebs bts rep_good nopl xtopology
                       nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64
                       monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr
                       pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt
                       tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm
                        3dnowprefetch cpuid_fault epb invpcid_single pti ssbd
                        ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid
                        fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms
                        invpcid rtm mpx rdseed adx smap clflushopt intel_pt
                        xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln
                        pts hwp hwp_notify hwp_act_window hwp_epp md_clear
                        flush_l1d
</code></pre>
<h2 id="current-baseline"><a class="header" href="#current-baseline">Current baseline</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Test</th><th>Mean</th></tr></thead><tbody>
<tr><td>Serialize</td><td>371.38 us</td></tr>
<tr><td>Serialize + crc64</td><td>493.26 us</td></tr>
<tr><td>Deserialize</td><td>90.755 us</td></tr>
<tr><td>Deserialize + crc64</td><td>216.90 us</td></tr>
</tbody></table>
</div>
<p>Detailed criterion benchmarks available <a href="https://s3.amazonaws.com/spec.ccfc.min/perf/snapshot-0.23/report/index.html">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cpu-templates"><a class="header" href="#cpu-templates">CPU templates</a></h1>
<p>Firecracker allows users to customise how the vCPUs are represented
to the guest software by changing the following configuration:</p>
<ul>
<li>CPUID (x86_64 only)</li>
<li>MSRs (Model Specific Registers, x86_64 only)</li>
<li>ARM registers (aarch64 only)</li>
<li>vCPU features (aarch64 only)</li>
<li>KVM capabilities (both x86_64 and aarch64)</li>
</ul>
<p>A combination of the changes to the above entities is called a CPU template.</p>
<p>The functionality can be used when a user wants to mask a feature from
the guest. A real world use case for this is representing a heterogeneous
fleet (a fleet consisting of multiple CPU models) as a homogeneous fleet,
so the guests will experience a consistent feature set supported by the host.</p>
<blockquote>
<p><strong>Note</strong>
Representing one CPU vendor as another CPU vendor is not supported.</p>
</blockquote>
<blockquote>
<p><strong>Note</strong>
CPU templates shall not be used as a security protection against malicious
guests. Disabling a feature in a CPU template does not generally make it
completely unavailable to the guest. For example, disabling a feature related
to an instruction set will indicate to the guest that the feature
is not supported, but the guest may still be able to execute corresponding
instructions if it does not obey the feature bit.</p>
</blockquote>
<p>Firecracker supports two types of CPU templates:</p>
<ul>
<li>Static CPU templates - a set of built-in CPU templates for users
to choose from</li>
<li>Custom CPU templates - users can create their own CPU templates in json
format and pass them to Firecracker</li>
</ul>
<blockquote>
<p><strong>Note</strong>
Static CPU templates are deprecated starting from v1.5.0 and will be removed in
accordance with our deprecation policy. Even after the removal, custom CPU
templates are available as an improved iteration of static CPU templates. For
more information about the transition from static CPU templates to custom CPU
templates, please refer to <a href="https://github.com/firecracker-microvm/firecracker/discussions/4135">this GitHub discussion</a>.</p>
</blockquote>
<blockquote>
<p><strong>Note</strong>
CPU templates for ARM (both static and custom) require the following patch
to be available in the host kernel: <a href="https://lore.kernel.org/kvm/20230212215830.2975485-1-jingzhangos@google.com/#t">Support writable CPU ID registers from userspace</a>.
Otherwise KVM will fail to write to the ARM registers.</p>
</blockquote>
<h2 id="static-cpu-templates"><a class="header" href="#static-cpu-templates">Static CPU templates</a></h2>
<p>At the moment the following set of static CPU templates are supported:</p>
<div class="table-wrapper"><table><thead><tr><th>CPU template</th><th>CPU vendor</th><th>CPU model</th></tr></thead><tbody>
<tr><td>C3</td><td>Intel</td><td>any</td></tr>
<tr><td>T2</td><td>Intel</td><td>any</td></tr>
<tr><td>T2A</td><td>AMD</td><td>Milan</td></tr>
<tr><td>T2CL</td><td>Intel</td><td>Cascade Lake or newer</td></tr>
<tr><td>T2S</td><td>Intel</td><td>any</td></tr>
<tr><td>V1N1</td><td>ARM</td><td>Neoverse V1</td></tr>
</tbody></table>
</div>
<p>T2 and C3 templates are mapped as close as possible to AWS T2 and C3 instances
in terms of CPU features. Note that on a microVM that is lauched with the C3
template and running on processors that do not enumerate FBSDP_NO, PSDP_NO and
SBDR_SSDP_NO on IA32_ARCH_CAPABILITIES MSR, the kernel does not apply the
mitigation against MMIO stale data vulnerability.</p>
<p>The T2S template is designed to allow migrating <a href="../snapshotting/versioning.html">snapshots</a>
between hosts with Intel Skylake and Intel Cascade Lake securely by further
restricting CPU features for the guest, however this comes with a performance
penalty. Users are encouraged to carry out a performance assessment if they wish
to use the T2S template. Note that Firecracker expects the host to always be
running the latest version of the microcode.</p>
<p>The T2CL template is mapped to be close to Intel Cascade Lake.
It is not safe to use it on Intel CPUs older than Cascade Lake (such as Skylake).</p>
<p>The only AMD template is T2A. It is considered safe to be used with AMD Milan.</p>
<p>Intel T2CL and AMD T2A templates together aim to provide instruction set feature
parity between CPUs running them, so they can form a heterogeneous fleet
exposing the same instruction sets to the application.</p>
<p>The V1N1 template is designed to represent ARM Neoverse V1 as ARM Neoverse N1.</p>
<h3 id="configuring-static-cpu-templates"><a class="header" href="#configuring-static-cpu-templates">Configuring static CPU templates</a></h3>
<p>Configuration of a static CPU template is performed via the <code>/machine-config</code>
API endpoint:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i  \
  -X PUT 'http://localhost/machine-config' \
  -H 'Accept: application/json'            \
  -H 'Content-Type: application/json'      \
  -d '{
           &quot;vcpu_count&quot;: 2,
           &quot;mem_size_mib&quot;: 1024,
           &quot;cpu_template&quot;: &quot;T2CL&quot;
  }'
</code></pre>
<h2 id="custom-cpu-templates"><a class="header" href="#custom-cpu-templates">Custom CPU templates</a></h2>
<p>Users can create their own CPU templates by creating a json file containing
modifiers for CPUID, MSRs or ARM registers.</p>
<blockquote>
<p><strong>Note</strong>
Creating custom CPU templates requires expert knowledge of
CPU architectures. Custom CPU templates must be tested thoroughly before use
in production. An inappropriate configuration may lead to guest crashes or
making guests vulnerable to security attacks. For example, if a CPU template
signals a hardware vulnerability mitigation to the guest while the mitigation
is in fact not supported by the hardware, the guest may decide to disable
corresponding software mitigations which will make the guest vulnerable.</p>
</blockquote>
<blockquote>
<p><strong>Note</strong>
Having MSRs or ARM registers in the custom CPU template does
not affect access permissions that guests will have to those registers.
The access control is handled by KVM and is not influenced by CPU templates.</p>
</blockquote>
<blockquote>
<p><strong>Note</strong>
When setting guest configuration, KVM may reject setting some bits quietly.
This is user's responsibility to make sure that their custom CPU template
is applied as expected even if Firecracker does not report an error.</p>
</blockquote>
<p>In order to assist with creation and usage of CPU templates, there exists
a CPU template helper tool. More details can be found
<a href="cpu-template-helper.html">here</a>.</p>
<h3 id="configuring-custom-cpu-templates"><a class="header" href="#configuring-custom-cpu-templates">Configuring custom CPU templates</a></h3>
<p>Configuration of a custom CPU template is performed via the <code>/cpu-config</code>
API endpoint.</p>
<p>An example of configuring a custom CPU template on x86_64:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i  \
  -X PUT 'http://localhost/cpu-config' \
  -H 'Accept: application/json'            \
  -H 'Content-Type: application/json'      \
  -d '{
        &quot;kvm_capabilities&quot;: [&quot;!56&quot;],
        &quot;cpuid_modifiers&quot;: [
          {
            &quot;leaf&quot;: &quot;0x1&quot;,
            &quot;subleaf&quot;: &quot;0x0&quot;,
            &quot;flags&quot;: 0,
            &quot;modifiers&quot;: [
              {
                &quot;register&quot;: &quot;eax&quot;,
                &quot;bitmap&quot;: &quot;0bxxxx000000000011xx00011011110010&quot;
              }
            ]
          }
        ],
        &quot;msr_modifiers&quot;: [
          {
            &quot;addr&quot;: &quot;0x10a&quot;,
            &quot;bitmap&quot;: &quot;0b0000000000000000000000000000000000000000000000000000000000000000&quot;
          }
        ]
      }'
</code></pre>
<p>This CPU template will do the following:</p>
<ul>
<li>removes check for KVM capability: KVM_CAP_XCRS.
This allows Firecracker to run on old cpus. See <a href="https://github.com/firecracker-microvm/firecracker/discussions/3470">this</a>
discussion.</li>
<li>in leaf <code>0x1</code>, subleaf <code>0x0</code>, register <code>eax</code>:
<ul>
<li>clear bits <code>0b00001111111111000011100100001101</code></li>
<li>set bits <code>0b00000000000000110000011011110010</code></li>
<li>leave bits <code>0b11110000000000001100000000000000</code> intact.</li>
</ul>
</li>
<li>in MSR <code>0x10</code>, it will clear all bits.</li>
</ul>
<p>An example of configuring a custom CPU template on ARM:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i  \
  -X PUT 'http://localhost/cpu-config' \
  -H 'Accept: application/json'            \
  -H 'Content-Type: application/json'      \
  -d '{
        &quot;kvm_capabilities&quot;: [&quot;171&quot;, &quot;172&quot;],
        &quot;vcpu_features&quot;: [{ &quot;index&quot;: 0, &quot;bitmap&quot;: &quot;0b1100000&quot; }]
        &quot;reg_modifiers&quot;: [
          {
            &quot;addr&quot;: &quot;0x603000000013c020&quot;,
            &quot;bitmap&quot;: &quot;0bxxxxxxxxxxxx0000xxxxxxxxxxxx0000xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;
          }
        ]
      }'
</code></pre>
<p>This CPU template will do the following:</p>
<ul>
<li>add checks for KVM capabilities: KVM_CAP_ARM_PTRAUTH_ADDRESS and KVM_CAP_ARM_PTRAUTH_GENERIC.
These checks are to ensure that the host have capabilities needed for
the vCPU features.</li>
<li>enable additional vCPU features: KVM_ARM_VCPU_PTRAUTH_ADDRESS and KVM_ARM_VCPU_PTRAUTH_GENERIC</li>
<li>modify ARM register <code>0x603000000013c020</code>:
<ul>
<li>clear bits <code>0b0000000000001111000000000000111100000000000000000000000000000000</code></li>
<li>leave bits <code>0b1111111111110000111111111111000011111111111111111111111111111111</code>
intact.</li>
</ul>
</li>
</ul>
<p>Information about KVM capabilities can be found in the
<a href="https://elixir.bootlin.com/linux/latest/source/include/uapi/linux/kvm.h">kernel source</a>.
Information about vCPU features on aarch64 can be found in the
<a href="https://elixir.bootlin.com/linux/latest/source/arch/arm64/include/uapi/asm/kvm.h">kernel source</a>.
Information on how the ARM register addresses are constructed can be found
in the <a href="https://docs.kernel.org/virt/kvm/api.html#kvm-set-one-reg">KVM API documentation</a>.</p>
<h3 id="custom-cpu-templates-language-schema"><a class="header" href="#custom-cpu-templates-language-schema">Custom CPU templates language schema</a></h3>
<p>The full description of the custom CPU templates language can be found
<a href="schema.json">here</a>.</p>
<blockquote>
<p><strong>Note</strong>
You can also use <code>_</code> to visually separate parts of a bitmap.
So instead of writing: <code>0b0000xxxx</code>, it can be <code>0b0000_xxxx</code>.</p>
</blockquote>
<h4 id="expansion-of-contracted-bitmaps"><a class="header" href="#expansion-of-contracted-bitmaps">Expansion of contracted bitmaps</a></h4>
<p>If a contracted version of a bitmap is given, for example, <code>0b101</code> where
a 32-bit bitmap is expected, missing characters are implied to be <code>x</code>
(<code>0bxxxxxxxxxxxxxxxxxxxxxxxxxxxxx101</code>).</p>
<h4 id="cpuid-normalization-and-boot-protocol-register-settings"><a class="header" href="#cpuid-normalization-and-boot-protocol-register-settings">CPUID normalization and boot protocol register settings</a></h4>
<p>Some of the configuration set by a custom CPU template may be overwritten
by Firecracker. More details can be found <a href="cpuid-normalization.html">here</a> and
<a href="boot-protocol.html">here</a>.</p>
<h4 id="information-about-architecture-specific-settings"><a class="header" href="#information-about-architecture-specific-settings">Information about architecture-specific settings</a></h4>
<p>For detailed information when working with custom CPU templates, please
refer to hardware specifications from CPU vendors, for example:</p>
<ul>
<li><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">Intel Software Developer Manual</a></li>
<li><a href="https://www.amd.com/en/support/tech-docs?keyword=programmer%27s+manual">AMD Architecture Programmer's Manual</a></li>
<li><a href="https://developer.arm.com/documentation/ddi0487/latest">ARM Architecture Refernce Manual</a></li>
</ul>
<h2 id="a-note-about-configuration-of-both-static-and-custom-cpu-templates"><a class="header" href="#a-note-about-configuration-of-both-static-and-custom-cpu-templates">A note about configuration of both static and custom CPU templates</a></h2>
<p>If a user configured both a static CPU template (via <code>/machine-config</code>) and
a custom CPU template (via <code>/cpu-config</code>) in the same Firecracker process,
only the configuration that was performed the <em>last</em> is applied. This means
that if a static CPU template was configured first and a custom CPU template
was configured later, only the custom CPU template configuration will be
applied when starting a microVM.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="boot-protocol-register-settings"><a class="header" href="#boot-protocol-register-settings">Boot protocol register settings</a></h1>
<p>Firecracker makes certain modifications to the guest's registers
regardless of whether a CPU template is used to comply with the boot protocol.
If a CPU template is used the boot protocol settings are performed <em>after</em> the
CPU template is applied. That means that if the CPU template configures CPUID
bits used in the boot protocol settings, they will be overwritten.</p>
<p>See also: <a href="cpuid-normalization.html">CPUID normalization</a></p>
<h2 id="boot-protocol-msrs-x86_64-only"><a class="header" href="#boot-protocol-msrs-x86_64-only">Boot protocol MSRs (x86_64 only)</a></h2>
<p>On x86_64, the following MSRs are set to <code>0</code>:</p>
<ul>
<li>MSR_IA32_SYSENTER_CS</li>
<li>MSR_IA32_SYSENTER_ESP</li>
<li>MSR_IA32_SYSENTER_EIP</li>
<li>MSR_STAR</li>
<li>MSR_CSTAR</li>
<li>MSR_KERNEL_GS_BASE</li>
<li>MSR_SYSCALL_MASK</li>
<li>MSR_LSTAR</li>
<li>MSR_IA32_TSC</li>
</ul>
<p>and MSR_IA32_MISC_ENABLE is set to <code>1</code>.</p>
<h2 id="boot-protocol-arm-registers-aarch64-only"><a class="header" href="#boot-protocol-arm-registers-aarch64-only">Boot protocol ARM registers (aarch64 only)</a></h2>
<p>On aarch64, the following registers are set:</p>
<ul>
<li>PSTATE to PSR_MODE_EL1h | PSR_A_BIT | PSR_F_BIT | PSR_I_BIT | PSR_D_BIT</li>
<li>PC to kernel load address (vCPU0 only)</li>
<li>X0 to DTB/FDT address (vCPU0 only)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cpu-template-helper-tool"><a class="header" href="#cpu-template-helper-tool">CPU template helper tool</a></h1>
<p>The <code>cpu-template-helper</code> tool is a program designed to assist users with
creating and managing their custom CPU templates.</p>
<h2 id="usage-2"><a class="header" href="#usage-2">Usage</a></h2>
<p>The <code>cpu-template-helper</code> tool has two sets of commands: template-related
commands and fingerprint-related commands.</p>
<h3 id="template-related-commands"><a class="header" href="#template-related-commands">Template-related commands</a></h3>
<h4 id="dump-command"><a class="header" href="#dump-command">Dump command</a></h4>
<p>This command dumps guest CPU configuration in the custom CPU template JSON
format.</p>
<pre><code>cpu-template-helper template dump --config &lt;firecracker-config&gt; --output &lt;cpu-config&gt;
</code></pre>
<p>Users can utilize this as an entry point of a custom CPU template creation
to comprehend what CPU configuration are exposed to guests.</p>
<p>The guest CPU configuration consists of the following entities:</p>
<ul>
<li>x86_64
<ul>
<li>CPUID</li>
<li>MSRs (Model Specific Registers)</li>
</ul>
</li>
<li>aarch64
<ul>
<li>ARM registers</li>
</ul>
</li>
</ul>
<p>It retrieves the above entities exposed to a guest by applying the same preboot
process as Firecacker and capturing them in the state just before booting a
guest. More details about the preboot process can be found
<a href="boot-protocol.html">here</a> and <a href="cpuid-normalization.html">here</a>.</p>
<blockquote>
<p><strong>Note</strong>
Some MSRs and ARM registers are not included in the output, since they are not
reasonable to modify with CPU templates. The full list of them can be found in
<a href="cpu-template-helper.html#appendix">Appendix</a>.</p>
</blockquote>
<blockquote>
<p><strong>Note</strong>
Since the output depends on underlying hardware and software stack (BIOS, CPU,
kernel, Firecracker), it is required to dump guest CPU configuration on each
combination when creating a custom CPU template targetting them all.</p>
</blockquote>
<h4 id="strip-command"><a class="header" href="#strip-command">Strip command</a></h4>
<p>This command strips identical entries from multiple guest CPU configuration
files generated with the dump command.</p>
<pre><code>cpu-template-helper template strip \
    --paths &lt;cpu-config-1&gt; &lt;cpu-config-2&gt; [..&lt;cpu-config-N&gt;] \
    --suffix &lt;suffix&gt;
</code></pre>
<p>One practical use case of the CPU template feature is to provide a consistent
CPU feature set to guests running on multiple CPU models. When creating a custom
CPU template for this purpose, it is efficient to focus on the differences
in guest CPU configurations across those CPU models. Given that a dumped guest
CPU configuration typically amounts to approximately 1,000 lines, this command
considerably narrows down the scope to consider.</p>
<h4 id="verify-command"><a class="header" href="#verify-command">Verify command</a></h4>
<p>This command verifies that the given custom CPU template is applied correctly.</p>
<pre><code>cpu-template-helper template verify \
    --config &lt;firecracker-config&gt;
</code></pre>
<p>Firecracker modifies the guest CPU configuration after the CPU template is
applied. Occasionally, due to hardware and/or software limitations, KVM might
not set the given configuration. Since Firecracker does not check them at
runtime, it is required to ensure that these situations don't happen with their
custom CPU templates before deploying it.</p>
<p>The command uses the same configuration file as Firecracker and the path to the
custom CPU template file should be specified in the &quot;cpu-config&quot; field.</p>
<blockquote>
<p><strong>Note</strong>
This command does not ensure that the contents of the template are sensible.
Thus, users need to make sure that the template does not have any inconsistent
entries and does not crash guests.</p>
</blockquote>
<h3 id="fingerprint-related-commands"><a class="header" href="#fingerprint-related-commands">Fingerprint-related commands</a></h3>
<h4 id="dump-command-1"><a class="header" href="#dump-command-1">Dump command</a></h4>
<p>This command not only dumps the guest CPU configuration, but also host
information that could affect the validity of custom CPU templates.</p>
<pre><code>cpu-template-helper fingerprint dump \
    --config &lt;firecracker-config&gt; \
    --output &lt;output-path&gt;
</code></pre>
<p>Keeping the underlying hardware and software stack updated is essential for
maintaining security and leveraging new technologies. On the other hand, since
the guest CPU configuration can vary depending on the infrastructure, updating
it could lead to a situation where a custom CPU template loses its validity.
In addition, even if values of the guest CPU configuration don't change, its
internal behavior or semantics could still change. For instance, a kernel
version update may introduce changes to KVM emulation and a microcode update may
alter the behavior of CPU instructions.</p>
<p>To ensure awareness of these changes, it is strongly recommended to store the
fingerprint file at the time of creating a custom CPU template and to
continuously compare it with the current one.</p>
<h4 id="compare-command"><a class="header" href="#compare-command">Compare command</a></h4>
<p>This command compares two fingerprint files: one was taken at the time of custom
CPU template creation and the other is taken currently.</p>
<pre><code>cpu-template-helper fingerprint compare \
    --prev &lt;prev-fingerprint&gt; \
    --curr &lt;curr-fingerprint&gt; \
    --filters &lt;field-1&gt; [..&lt;field-N&gt;]
</code></pre>
<p>By continously comparing fingerprint files, users can ensure they are aware of
any changes that could require revising the custom CPU template. However, it is
worth noting that not all of these changes necessarily require a revision, and
some changes could be inconsequential to the custom CPU template depending on
its use case. To provide users with flexibility in comparing fingerprint files
based on situations or use cases, the <code>--filters</code> option allows users to select
which fields to compare.</p>
<p>As examples of when to compare fingerprint files:</p>
<ul>
<li>When bumping the Firecracker version up</li>
<li>When bumping the kernel version up</li>
<li>When applying a microcode update (or launching a new host (e.g. AWS EC2 metal
instance))</li>
</ul>
<h2 id="sample-scenario"><a class="header" href="#sample-scenario">Sample scenario</a></h2>
<p>This section gives steps of creating and managing a custom CPU template in a
sample scenario where the template is designed to provide a consistent set of
CPU features to a heterogeneous fleet consisting of multiple CPU models.</p>
<h3 id="custom-cpu-template-creation"><a class="header" href="#custom-cpu-template-creation">Custom CPU template creation</a></h3>
<ol>
<li>Run the <code>cpu-template-helper template dump</code> command on each CPU model to
retrieve guest CPU configuration.</li>
<li>Run the <code>cpu-template-helper template strip</code> command to remove identical
entries across the dumped guest CPU configuration files.</li>
<li>Examine the differences of guest CPU configuration in details, determine
which CPU features should be presented to guests and draft a custom CPU
template.</li>
<li>Run the <code>cpu-template-helper template verify</code> command to check the created
custom CPU template is applied correctly.</li>
<li>Conduct thorough testing of the template as needed to ensure that it does
not contain any inconsistent entries and does not lead to guest crashes.</li>
</ol>
<h3 id="custom-cpu-template-management"><a class="header" href="#custom-cpu-template-management">Custom CPU template management</a></h3>
<ol>
<li>Run the <code>cpu-template-helper fingerprint dump</code> command on each CPU model
at the same time when creating a custom CPU template.</li>
<li>Store the dumped fingerprint files together with the custom CPU template.</li>
<li>Run the <code>cpu-template-helper fingerprint dump</code> command to ensure the
template's validity whenever you expect changes to the underlying hardware
and software stack.</li>
<li>Run the <code>cpu-template-helper fingerprint compare</code> command to identify
changes of the underlying environment introduced after creating the template.</li>
<li>(if changes are detected) Review the identified changes, make necessary
revisions to the CPU template, and replace the fingerprint file with the new
one.</li>
</ol>
<blockquote>
<p><strong>Note</strong>
It is recommended to review the update process of the underlying stack on
your infrastructure. This can help identify points that may require the above
validation check.</p>
</blockquote>
<h2 id="appendix"><a class="header" href="#appendix">Appendix</a></h2>
<h3 id="msrs-excluded-from-guest-cpu-configuration-dump"><a class="header" href="#msrs-excluded-from-guest-cpu-configuration-dump">MSRs excluded from guest CPU configuration dump</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Register name</th><th>Index</th></tr></thead><tbody>
<tr><td>MSR_IA32_TSC</td><td>0x00000010</td></tr>
<tr><td>MSR_ARCH_PERFMON_PERFCTRn</td><td>0x000000c1 - 0x000000d2</td></tr>
<tr><td>MSR_ARCH_PERFMON_EVENTSELn</td><td>0x00000186 - 0x00000197</td></tr>
<tr><td>MSR_ARCH_PERFMON_FIXED_CTRn</td><td>0x00000309 - 0x0000030b</td></tr>
<tr><td>MSR_CORE_PERF_FIXED_CTR_CTRL</td><td>0x0000038d</td></tr>
<tr><td>MSR_CORE_PERF_GLOBAL_STATUS</td><td>0x0000038e</td></tr>
<tr><td>MSR_CORE_PERF_GLOBAL_CTRL</td><td>0x0000038f</td></tr>
<tr><td>MSR_CORE_PERF_GLOBAL_OVF_CTRL</td><td>0x00000390</td></tr>
<tr><td>MSR_K7_EVNTSELn</td><td>0xc0010000 - 0xc0010003</td></tr>
<tr><td>MSR_K7_PERFCTR0</td><td>0xc0010004 - 0xc0010007</td></tr>
<tr><td>MSR_F15H_PERF_CTLn + MSR_F15H_PERF_CTRn</td><td>0xc0010200 - 0xc001020c</td></tr>
<tr><td>MSR_IA32_VMX_BASIC</td><td>0x00000480</td></tr>
<tr><td>MSR_IA32_VMX_PINBASED_CTLS</td><td>0x00000481</td></tr>
<tr><td>MSR_IA32_VMX_PROCBASED_CTLS</td><td>0x00000482</td></tr>
<tr><td>MSR_IA32_VMX_EXIT_CTLS</td><td>0x00000483</td></tr>
<tr><td>MSR_IA32_VMX_ENTRY_CTLS</td><td>0x00000484</td></tr>
<tr><td>MSR_IA32_VMX_MISC</td><td>0x00000485</td></tr>
<tr><td>MSR_IA32_VMX_CR0_FIXEDn</td><td>0x00000486 - 0x00000487</td></tr>
<tr><td>MSR_IA32_VMX_CR4_FIXEDn</td><td>0x00000488 - 0x00000489</td></tr>
<tr><td>MSR_IA32_VMX_VMCS_ENUM</td><td>0x0000048a</td></tr>
<tr><td>MSR_IA32_VMX_PROCBASED_CTLS2</td><td>0x0000048b</td></tr>
<tr><td>MSR_IA32_VMX_EPT_VPID_CAP</td><td>0x0000048c</td></tr>
<tr><td>MSR_IA32_VMX_TRUE_PINBASED_CTLS</td><td>0x0000048d</td></tr>
<tr><td>MSR_IA32_VMX_TRUE_PROCBASED_CTLS</td><td>0x0000048e</td></tr>
<tr><td>MSR_IA32_VMX_TRUE_EXIT_CTLS</td><td>0x0000048f</td></tr>
<tr><td>MSR_IA32_VMX_TRUE_ENTRY_CTLS</td><td>0x00000490</td></tr>
<tr><td>MSR_IA32_VMX_VMFUNC</td><td>0x00000491</td></tr>
<tr><td>MSR_IA32_MCG_STATUS</td><td>0x0000017a</td></tr>
<tr><td>MSR_IA32_MCG_CTL</td><td>0x0000017b</td></tr>
<tr><td>MSR_IA32_MCG_EXT_CTL</td><td>0x000004d0</td></tr>
<tr><td>HV_X64_MSR_GUEST_OS_ID</td><td>0x40000000</td></tr>
<tr><td>HV_X64_MSR_HYPERCALL</td><td>0x40000001</td></tr>
<tr><td>HV_X64_MSR_VP_INDEX</td><td>0x40000002</td></tr>
<tr><td>HV_X64_MSR_RESET</td><td>0x40000003</td></tr>
<tr><td>HV_X64_MSR_VP_RUNTIME</td><td>0x40000010</td></tr>
<tr><td>HV_X64_MSR_VP_ASSIST_PAGE</td><td>0x40000073</td></tr>
<tr><td>HV_X64_MSR_SCONTROL</td><td>0x40000080</td></tr>
<tr><td>HV_X64_MSR_STIMER0_CONFIG</td><td>0x400000b0</td></tr>
<tr><td>HV_X64_MSR_CRASH_Pn</td><td>0x40000100 - 0x40000104</td></tr>
<tr><td>HV_X64_MSR_CRASH_CTL</td><td>0x40000105</td></tr>
<tr><td>HV_X64_MSR_REENLIGHTENMENT_CONTROL</td><td>0x40000106</td></tr>
<tr><td>HV_X64_MSR_TSC_EMULATION_CONTROL</td><td>0x40000107</td></tr>
<tr><td>HV_X64_MSR_TSC_EMULATION_STATUS</td><td>0x40000108</td></tr>
<tr><td>HV_X64_MSR_SYNDBG_CONTROL</td><td>0x400000f1</td></tr>
<tr><td>HV_X64_MSR_SYNDBG_STATUS</td><td>0x400000f2</td></tr>
<tr><td>HV_X64_MSR_SYNDBG_SEND_BUFFER</td><td>0x400000f3</td></tr>
<tr><td>HV_X64_MSR_SYNDBG_RECV_BUFFER</td><td>0x400000f4</td></tr>
<tr><td>HV_X64_MSR_SYNDBG_PENDING_BUFFER</td><td>0x400000f5</td></tr>
<tr><td>HV_X64_MSR_SYNDBG_OPTIONS</td><td>0x400000ff</td></tr>
</tbody></table>
</div>
<h3 id="arm-registers-excluded-from-guest-cpu-configuration-dump"><a class="header" href="#arm-registers-excluded-from-guest-cpu-configuration-dump">ARM registers excluded from guest CPU configuration dump</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Register name</th><th>ID</th></tr></thead><tbody>
<tr><td>Program Counter</td><td>0x6030000000100040</td></tr>
<tr><td>KVM_REG_ARM_TIMER_CNT</td><td>0x603000000013df1a</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="cpuid-normalization-x86_64-only"><a class="header" href="#cpuid-normalization-x86_64-only">CPUID normalization (x86_64 only)</a></h1>
<p>On x86_64, Firecracker makes certain modifications to the guest's CPUID
regardless of whether a CPU template is used. This is referred to as
<code>CPUID normalization</code>. If a CPU template is used the normalization is
performed <em>after</em> the CPU template is applied. That means that if the CPU
template configures CPUID bits used in the normalization process, they will
be overwritten.</p>
<p>See also: <a href="boot-protocol.html">boot protocol settings</a></p>
<h2 id="x86_64-common-cpuid-normalization"><a class="header" href="#x86_64-common-cpuid-normalization">x86_64 common CPUID normalization</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Description</th><th style="text-align: center">Leaf</th><th style="text-align: center">Subleaf</th><th style="text-align: center">Register</th><th style="text-align: center">Bits</th></tr></thead><tbody>
<tr><td>Pass through vendor ID from host</td><td style="text-align: center">0x0</td><td style="text-align: center">-</td><td style="text-align: center">EBX, ECX, EDX</td><td style="text-align: center">all</td></tr>
<tr><td>Set CLFLUSH line size</td><td style="text-align: center">0x1</td><td style="text-align: center">-</td><td style="text-align: center">EBX</td><td style="text-align: center">15:8</td></tr>
<tr><td>Set maximum number of addressable IDs for logical processors in the physical package</td><td style="text-align: center">0x1</td><td style="text-align: center">-</td><td style="text-align: center">EBX</td><td style="text-align: center">23:16</td></tr>
<tr><td>Set initial APIC ID</td><td style="text-align: center">0x1</td><td style="text-align: center">-</td><td style="text-align: center">EBX</td><td style="text-align: center">31:24</td></tr>
<tr><td>Disable PDCM (Perfmon and Debug Capability)</td><td style="text-align: center">0x1</td><td style="text-align: center">-</td><td style="text-align: center">ECX</td><td style="text-align: center">15</td></tr>
<tr><td>Enable TSC_DEADLINE</td><td style="text-align: center">0x1</td><td style="text-align: center">-</td><td style="text-align: center">ECX</td><td style="text-align: center">24</td></tr>
<tr><td>Enable HYPERVISOR</td><td style="text-align: center">0x1</td><td style="text-align: center">-</td><td style="text-align: center">ECX</td><td style="text-align: center">31</td></tr>
<tr><td>Set HTT value if the microVM's CPU count is greater than 1</td><td style="text-align: center">0x1</td><td style="text-align: center">-</td><td style="text-align: center">EDX</td><td style="text-align: center">28</td></tr>
<tr><td>Insert leaf 0xb, subleaf 0x1 filled with <code>0</code> if it is not already present</td><td style="text-align: center">0xb</td><td style="text-align: center">0x1</td><td style="text-align: center">all</td><td style="text-align: center">all</td></tr>
<tr><td>Update extended topology enumeration</td><td style="text-align: center">0xb</td><td style="text-align: center">all</td><td style="text-align: center">EAX</td><td style="text-align: center">4:0</td></tr>
<tr><td>Update extended topology enumeration</td><td style="text-align: center">0xb</td><td style="text-align: center">all</td><td style="text-align: center">EBX</td><td style="text-align: center">15:0</td></tr>
<tr><td>Update extended topology enumeration</td><td style="text-align: center">0xb</td><td style="text-align: center">all</td><td style="text-align: center">ECX</td><td style="text-align: center">15:8</td></tr>
<tr><td>Pass through L1 cache and TLB information from host</td><td style="text-align: center">0x80000005</td><td style="text-align: center">-</td><td style="text-align: center">all</td><td style="text-align: center">all</td></tr>
<tr><td>Pass through L2 cache and TLB and L3 cache information from host</td><td style="text-align: center">0x80000006</td><td style="text-align: center">-</td><td style="text-align: center">all</td><td style="text-align: center">all</td></tr>
</tbody></table>
</div>
<h2 id="intel-specific-cpuid-normalization"><a class="header" href="#intel-specific-cpuid-normalization">Intel-specific CPUID normalization</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Description</th><th style="text-align: center">Leaf</th><th style="text-align: center">Subleaf</th><th style="text-align: center">Register</th><th style="text-align: center">Bits</th></tr></thead><tbody>
<tr><td>Update deterministic cache parameters</td><td style="text-align: center">0x4</td><td style="text-align: center">all</td><td style="text-align: center">EAX</td><td style="text-align: center">31:14</td></tr>
<tr><td>Disable Intel Turbo Boost technology</td><td style="text-align: center">0x6</td><td style="text-align: center">-</td><td style="text-align: center">EAX</td><td style="text-align: center">1</td></tr>
<tr><td>Disable frequency selection</td><td style="text-align: center">0x6</td><td style="text-align: center">-</td><td style="text-align: center">ECX</td><td style="text-align: center">3</td></tr>
<tr><td>Set FDP_EXCPTN_ONLY bit</td><td style="text-align: center">0x7</td><td style="text-align: center">0x0</td><td style="text-align: center">EBX</td><td style="text-align: center">6</td></tr>
<tr><td>Set &quot;Deprecates FPU CS and FPU DS values&quot; bit</td><td style="text-align: center">0x7</td><td style="text-align: center">0x0</td><td style="text-align: center">EBX</td><td style="text-align: center">13</td></tr>
<tr><td>Disable performance monitoring</td><td style="text-align: center">0xa</td><td style="text-align: center">-</td><td style="text-align: center">EAX, EBX, ECX, EDX</td><td style="text-align: center">all</td></tr>
<tr><td>Update brand string to use a default format and real frequency</td><td style="text-align: center">0x80000002, 0x80000003, 0x80000004</td><td style="text-align: center">-</td><td style="text-align: center">EAX, EBX, ECX, EDX</td><td style="text-align: center">all</td></tr>
</tbody></table>
</div>
<h2 id="amd-specifc-cpuid-normalization"><a class="header" href="#amd-specifc-cpuid-normalization">AMD-specifc CPUID normalization</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Description</th><th style="text-align: center">Leaf</th><th style="text-align: center">Subleaf</th><th style="text-align: center">Register</th><th style="text-align: center">Bits</th></tr></thead><tbody>
<tr><td>Set IA32_ARCH_CAPABILITIES MSR as not present</td><td style="text-align: center">0x7</td><td style="text-align: center">-</td><td style="text-align: center">EDX</td><td style="text-align: center">29</td></tr>
<tr><td>Update largest extended function entry to 0x8000001f</td><td style="text-align: center">0x80000000</td><td style="text-align: center">-</td><td style="text-align: center">EAX</td><td style="text-align: center">31:0</td></tr>
<tr><td>Set topology extension bit</td><td style="text-align: center">0x80000001</td><td style="text-align: center">-</td><td style="text-align: center">ECX</td><td style="text-align: center">22</td></tr>
<tr><td>Update brand string with a default AMD value</td><td style="text-align: center">0x80000002, 0x80000003, 0x80000004</td><td style="text-align: center">-</td><td style="text-align: center">EAX, EBX, ECX, EDX</td><td style="text-align: center">all</td></tr>
<tr><td>Update number of physical threads</td><td style="text-align: center">0x80000008</td><td style="text-align: center">-</td><td style="text-align: center">ECX</td><td style="text-align: center">7:0</td></tr>
<tr><td>Update APIC ID size</td><td style="text-align: center">0x80000008</td><td style="text-align: center">-</td><td style="text-align: center">ECX</td><td style="text-align: center">15:12</td></tr>
<tr><td>Update cache topology information</td><td style="text-align: center">0x8000001d</td><td style="text-align: center">all</td><td style="text-align: center">all</td><td style="text-align: center">all</td></tr>
<tr><td>Update extended APIC ID</td><td style="text-align: center">0x8000001e</td><td style="text-align: center">-</td><td style="text-align: center">EAX, EBX, ECX</td><td style="text-align: center">all</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="mmds"><a class="header" href="#mmds">MMDS</a></h1>
<p>TODO</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="microvm-metadata-service-1"><a class="header" href="#microvm-metadata-service-1">microVM Metadata Service</a></h1>
<p>MMDS consists of three major logical components: the backend, the data store,
and the minimalist HTTP/TCP/IPv4 stack (named <em>Dumbo</em>). They all exist within
the Firecracker process, and outside the KVM boundary; the first is a part of
the API server, the data store is a global entity for a single microVM, and the
last is a part of the device model.</p>
<h2 id="the-mmds-backend"><a class="header" href="#the-mmds-backend">The MMDS backend</a></h2>
<p>Users can add/update the MMDS contents via the backend, which is accessible
through the Firecracker API. Setting the initial contents involves a <code>PUT</code>
request to the <code>/mmds</code> API resource, with a JSON body that describes the
desired data store structure and contents. Here's a JSON example:</p>
<pre><code class="language-json">{
&quot;latest&quot;: {
            &quot;meta-data&quot;: {
                &quot;ami-id&quot;: &quot;ami-12345678&quot;,
                &quot;reservation-id&quot;: &quot;r-fea54097&quot;,
                &quot;local-hostname&quot;: &quot;ip-10-251-50-12.ec2.internal&quot;,
                &quot;public-hostname&quot;: &quot;ec2-203-0-113-25.compute-1.amazonaws.com&quot;,
                &quot;network&quot;: {
                    &quot;interfaces&quot;: {
                        &quot;macs&quot;: {
                            &quot;02:29:96:8f:6a:2d&quot;: {
                                &quot;device-number&quot;: &quot;13345342&quot;,
                                &quot;local-hostname&quot;: &quot;localhost&quot;,
                                &quot;subnet-id&quot;: &quot;subnet-be9b61d&quot;
                            }
                        }
                    }
                }
            }
        }
}
</code></pre>
<p>The MMDS contents can be updated either via a subsequent <code>PUT</code> (that replaces them
entirely), or using <code>PATCH</code> requests, which feed the JSON body into the JSON Merge
Patch functionality, based on <a href="https://tools.ietf.org/html/rfc7396">RFC 7396</a>. MMDS
related API requests come from the host, which is considered a trusted environment,
so there are no checks beside the kind of validation done by HTTP server and
<code>serde-json</code> (the crate used to de/serialize JSON). The size limit for the stored
metadata is configurable and defaults to 51200 bytes. When increasing this limit,
one must take into consideration that storing and retrieving large amount of data
may induce bottlenecks for the HTTP REST API processing, which is based on
<code>micro-http</code> crate. MMDS contents can be retrieved using the Firecracker API, via
a <code>GET</code> request to the <code>/mmds</code> resource.</p>
<h2 id="the-data-store"><a class="header" href="#the-data-store">The data store</a></h2>
<p>This is a global data structure, currently referenced using a global variable,
that represents the strongly-typed version of JSON-based user input describing
the MMDS contents. It leverages the recursive
<a href="https://docs.serde.rs/serde_json/value/enum.Value.html">Value</a> type exposed by
<code>serde-json</code>. It can only be accessed from thread-safe contexts. MMDS data
store supports at the moment storing and retrieving JSON values. Data store
contents can be retrieved using the Firecracker API server from host and using
the embedded MMDS HTTP/TCP/IPv4 network stack from guest.
MMDS data store is upper bounded to the value of the <code>--mmds-size-limit</code>
command line parameter.
If left unconfigured, it will default to the value of
<code>--http-api-max-payload-size</code>, which is 51200 bytes by default.</p>
<h2 id="dumbo"><a class="header" href="#dumbo">Dumbo</a></h2>
<p>The <em>Dumbo</em> HTTP/TCP/IPv4 network stack handles guest HTTP requests heading
towards the configured MMDS IPv4 address. Before going into <em>Dumbo</em> specifics,
it's worth going through a brief description of the Firecracker network device
model. Firecracker only offers Virtio-net paravirtualized devices to guests.
Drivers running in the guest OS use ring buffers in a shared memory area to
communicate with the device model when sending or receiving frames. The device
model associates each guest network device with a TAP device on the host.
Frames sent by the guest are written to the TAP fd, and frames read from the
TAP fd are handed over to the guest.</p>
<p>The <em>Dumbo</em> stack can be instantiated once for every network device, and is
disabled by default. It can be enabled through the API request body used to
configure MMDS by specifying the ID of the network interface inside the
<code>network_interfaces</code> list. In order for the API call to succeed, the network
device must be attached beforehand, otherwise an error is returned. Once
enabled, the stack taps into the aforementioned data path. Each frame coming
from the guest is examined to determine whether it should be processed by
<em>Dumbo</em> instead of being written to the TAP fd. Also, every time there is room
in the ring buffer to hand over frames to the guest, the device model first
checks whether <em>Dumbo</em> has anything to send; if not, it resumes getting frames
from the TAP fd (when available).</p>
<p>We chose to implement our own solution, instead of leveraging existing
libraries/implementations, because responding to guest MMDS queries in the
context of Firecracker is amenable to a wide swath of simplifications.
First of all, we only need to handle <code>GET</code> and <code>PUT</code> requests, which require
a bare-bones HTTP 1.1 server, without support for most headers and more advanced
features like chunking. Also, we get to choose what subset of HTTP is used when
building responses. Moving lower in the stack, we are dealing with TCP connections
over what is essentially a point-to-point link, that seldom loses packets and does
not reorder them. This means we can do away with congestion control (we only use
flow control), complex reception logic, and support for most TCP options/features.
At this point, the layers below (Ethernet and IPv4) don't involve much more than
sanity checks of frame/packet contents.</p>
<p><em>Dumbo</em> is built using both general purpose components (which we plan to offer
as part of one or more libraries), and Firecracker MMDS specific code. The
former category consists of various helper modules used to process streams of
bytes as protocol data units (Ethernet &amp; ARP frames, IPv4 packets, and TCP
segments), a TCP handler which listens for connections while demultiplexing
incoming segments, a minimalist TCP connection endpoint implementation, and a
greatly simplified HTTP 1.1 server. The Firecracker MMDS specific code is found
in the logic which taps into the device model, and the component that parses an
HTTP request, builds a response based on MMDS contents, and finally sends back
a reply.</p>
<h3 id="mmds-network-stack"><a class="header" href="#mmds-network-stack">MMDS Network Stack</a></h3>
<p>Somewhat confusingly, this is the name of the component which taps the device
model. It has a user-configured IPv4 address (see
<a href="../../src/api_server/swagger/firecracker.yaml">Firecracker MMDS configuration API</a>)
and MAC (<code>06:01:23:45:67:01</code>) addresses. The latter is also used to respond to
ARP requests.
For every frame coming from the guest, the following steps take place:</p>
<ol>
<li>Apply a heuristic to determine whether the frame may contain an ARP request
for the MMDS IP address, or an IPv4 packet heading towards the same address.
There can be no false negatives. Frames that fail both checks are <em>rejected</em>
(deferred to the device model for regular processing).</li>
<li><em>Reject</em> invalid Ethernet frames. <em>Reject</em> valid frames if their EtherType
is neither ARP, nor IPv4.</li>
<li>(<strong>if EtherType == ARP</strong>) <em>Reject</em> invalid ARP frames. <em>Reject</em> the frame if
its target protocol address field is different from the MMDS IP address.
Otherwise, record that an ARP request has been received (the stack only
remembers the most recent request).</li>
<li>(<strong>if EtherType == IPv4</strong>) <em>Reject</em> invalid packets. <em>Reject</em> packets if
their destination address differs from the MMDS IP address. <em>Drop</em> (stop
processing without deferring to the device model) packets that do not carry
TCP segments (by looking at the protocol number field). Send the rest to the
inner TCP handler.</li>
</ol>
<p>The current implementation does not support Ethernet 802.1Q tags, and does not
handle IP fragmentation. Tagged Ethernet frames are most likely going to be
deferred to the device model for processing, because the heuristics do not take
the presence of the tag into account. Moreover, their EtherType will not appear
to be of interest. Fragmented IP packets do not get reassembled; they are
treated as independent packets.</p>
<p>Whenever the guest is able to receive a frame, the device model first requests
one from the MMDS network stack associated with the current network device.</p>
<ol>
<li>If an ARP request has been previously recorded, send an ARP reply and forget
about the request.</li>
<li>If the inner TCP handler has any packets to transmit, wrap the next one into
a frame and send it.</li>
<li>There are no MMDS related frames to send, so tell the device model to read
from the TAP fd instead.</li>
</ol>
<h3 id="tcp-handler"><a class="header" href="#tcp-handler">TCP handler</a></h3>
<p>Handles received packets that appear to carry TCP segments. Its operation is
described in the <code>dumbo</code> crate documentation. Each connection is associated
with an MMDS endpoint.</p>
<h3 id="mmds-endpoint"><a class="header" href="#mmds-endpoint">MMDS endpoint</a></h3>
<p>This component gets the byte stream from an inner TCP connection object,
identifies the boundaries of the next HTTP request, and parses it using an
HttpRequest object. For each valid <code>GET</code> request, the URI is used to identify
a key from the metadata store (like in the previous example), and a response is
built using the Firecracker implementation of HttpResponse logic, based on the
associated value, and sent back to the guest over the same connection. Each
endpoint has a fixed size receive buffer, and a variable length response buffer
(depending on the size of each response). TCP receive window semantics are used
to ensure the guest does not overrun the receive buffer during normal operation
(the connection has to drop segments otherwise). There can be at most one
response pending at any given time.</p>
<p>Here are more details describing what happens when a segment is received by an
MMDS endpoint (previously created when a SYN segment arrived at the TCP
handler):</p>
<ol>
<li>Invoke the receive functionality of the inner connection object, and append
any new data to the receive buffer.</li>
<li>If no response is currently pending, attempt to identify the end of the
first request in the receive buffer. If no such boundary can be found, and
the buffer is full, reset the inner connection (which also causes the
endpoint itself to be subsequently removed) because the guest exceeded the
maximum allowed request size.</li>
<li>If no response is pending, and we can identify a request in the receive
buffer, parse it, free up the associated buffer space (also update the
connection receive window), and build an HTTP response, which becomes the
current pending response.</li>
<li>If a FIN segment was received, and there's no pending response, call <code>close</code>
on the inner connection. If a valid RST is received at any time, mark the
endpoint for removal.</li>
</ol>
<p>When the TCP handler asks an MMDS endpoint for any segments to send, the
transmission logic of the inner connection is invoked, specifying the pending
response (when present) as the payload source. All packets coming from MMDS
have the TTL value set to 1 by default.</p>
<h3 id="connection"><a class="header" href="#connection">Connection</a></h3>
<p>Connection objects are minimalist implementation of the TCP protocol. They are
used to reassemble the byte stream which carries guest HTTP requests, and to
send back segments which contain parts of the response. More details are
available in the <code>dumbo</code> crate documentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="microvm-metadata-service-2"><a class="header" href="#microvm-metadata-service-2">microVM Metadata Service</a></h1>
<p>The Firecracker microVM Metadata Service (MMDS) is a mutable data store which
can be used for sharing information between host and guests, in a secure and
easy at hand way.</p>
<h2 id="configuring-and-activating-the-microvm-metadata-service"><a class="header" href="#configuring-and-activating-the-microvm-metadata-service">Configuring and activating the microVM Metadata Service</a></h2>
<p>By default, MMDS is not reachable from the guest operating system. At microVM
runtime, MMDS is tightly coupled with a network interface, which allows MMDS
requests. When configuring the microVM, if MMDS needs to be activated, a
network interface has to be configured to allow MMDS requests. This can be
achieved in two steps:</p>
<ol>
<li>Attach one (or more) network interfaces through an HTTP <code>PUT</code> request to
<code>/network-interfaces/${MMDS_NET_IF}</code>. The full network configuration API
can be found in the <a href="../../src/api_server/swagger/firecracker.yaml">firecracker swagger file</a>.</li>
<li>Configure MMDS through an HTTP <code>PUT</code> request to <code>/mmds/config</code> resource and
include the IDs of the network interfaces that should allow forwarding requests
to MMDS in the <code>network_interfaces</code> list. The complete MMDS API is described in
the <a href="../../src/api_server/swagger/firecracker.yaml">firecracker swagger file</a>.</li>
</ol>
<h3 id="examples-2"><a class="header" href="#examples-2">Examples</a></h3>
<p>Attaching a network device with ID <code>MMDS_NET_IF</code>:</p>
<pre><code class="language-bash">MMDS_NET_IF=eth0
curl --unix-socket /tmp/firecracker.socket -i                 \
  -X PUT 'http://localhost/network-interfaces/${MMDS_NET_IF}' \
  -H 'Accept: application/json'                               \
  -H 'Content-Type: application/json'                         \
  -d '{
      &quot;iface_id&quot;: &quot;${MMDS_NET_IF}&quot;,
      &quot;guest_mac&quot;: &quot;AA:FC:00:00:00:01&quot;,
      &quot;host_dev_name&quot;: &quot;tap0&quot;
    }'
</code></pre>
<p>Configuring MMDS to receive requests through the <code>MMDS_NET_IF</code> network
interface ID:</p>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT &quot;http://localhost/mmds/config&quot;     \
    -H &quot;Content-Type: application/json&quot;       \
    -d '{
             &quot;network_interfaces&quot;: [&quot;${MMDS_NET_IF}&quot;]
    }'
</code></pre>
<p>MMDS can be configured pre-boot only, using the Firecracker API server. Enabling
MMDS without at least a network device attached will return an error.</p>
<p>The IPv4 address used by guest applications when issuing requests to MMDS can
be customized through the same HTTP <code>PUT</code> request to <code>/mmds/config</code> resource,
by specifying the IPv4 address to the <code>ipv4_address</code> field. If the IP configuration
is not provided before booting up the guest, the MMDS IPv4 address defaults to
<code>169.254.169.254</code>.</p>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT &quot;http://localhost/mmds/config&quot;     \
    -H &quot;Content-Type: application/json&quot;       \
    -d '{
             &quot;network_interfaces&quot;: [&quot;${MMDS_NET_IF}&quot;],
             &quot;ipv4_address&quot;: &quot;${MMDS_IPV4_ADDR}&quot;
    }'
</code></pre>
<p>MMDS is tightly coupled with a network interface which is used to route MMDS
packets. To send MMDS intended packets, guest applications must insert a new
rule into the routing table of the guest OS. This new rule must forward MMDS
intended packets to a network interface which allows MMDS requests. For
example:</p>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
MMDS_NET_IF=eth0
ip route add ${MMDS_IPV4_ADDR} dev ${MMDS_NET_IF}
</code></pre>
<p>MMDS supports two methods to access the contents of the metadata store from the
guest operating system: <code>V1</code> and <code>V2</code>.
More about the particularities of the two mechanisms can be found in the
<a href="mmds-user-guide.html#retrieving-metadata-in-the-guest-operating-system">Retrieving metadata in the guest operating system</a>
section. The MMDS version used can be specified when configuring MMDS, through
the <code>version</code> field of the HTTP <code>PUT</code> request to <code>/mmds/config</code> resource.
Accepted values are <code>V1</code>(deprecated) and <code>V2</code> and the default MMDS version used
in case the <code>version</code> field is missing is <a href="mmds-user-guide.html#version-1-deprecated">Version 1</a>.</p>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT &quot;http://localhost/mmds/config&quot;     \
    -H &quot;Content-Type: application/json&quot;       \
    -d '{
             &quot;network_interfaces&quot;: [&quot;${MMDS_NET_IF}&quot;],
             &quot;version&quot;: &quot;V2&quot;,
             &quot;ipv4_address&quot;: &quot;${MMDS_IPV4_ADDR}&quot;
    }'
</code></pre>
<h2 id="inserting-and-updating-metadata"><a class="header" href="#inserting-and-updating-metadata">Inserting and updating metadata</a></h2>
<p>Inserting and updating metadata is possible through the Firecracker API server.
The metadata inserted in MMDS must be any valid JSON. A user can create or update
the MMDS data store before the microVM is started or during its operation. To
insert metadata into MMDS, an HTTP <code>PUT</code> request to the <code>/mmds</code> resource has to be
issued. This request must have a payload with metadata structured in
<a href="https://tools.ietf.org/html/rfc7159">JSON</a> format. To replace existing
metadata, a subsequent HTTP <code>PUT</code> request to the <code>/mmds</code> resource must be
issued, using as a payload the new metadata. A complete description of
metadata insertion firecracker API can be found in the
<a href="../../src/api_server/swagger/firecracker.yaml">firecracker swagger file</a>.</p>
<p>An example of an API request for inserting metadata is provided below:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT &quot;http://localhost/mmds&quot;            \
    -H &quot;Content-Type: application/json&quot;       \
    -d '{
            &quot;latest&quot;: {
                  &quot;meta-data&quot;: {
                       &quot;ami-id&quot;: &quot;ami-12345678&quot;,
                       &quot;reservation-id&quot;: &quot;r-fea54097&quot;,
                       &quot;local-hostname&quot;: &quot;ip-10-251-50-12.ec2.internal&quot;,
                       &quot;public-hostname&quot;: &quot;ec2-203-0-113-25.compute-1.amazonaws.com&quot;,
                       &quot;network&quot;: {
                            &quot;interfaces&quot;: {
                                 &quot;macs&quot;: {
                                      &quot;02:29:96:8f:6a:2d&quot;: {
                                           &quot;device-number&quot;: &quot;13345342&quot;,
                                           &quot;local-hostname&quot;: &quot;localhost&quot;,
                                           &quot;subnet-id&quot;: &quot;subnet-be9b61d&quot;
                                      }
                                 }
                            }
                       }
                  }
            }
    }'
</code></pre>
<p>To partially update existing metadata, an HTTP <code>PATCH</code> request to the <code>/mmds</code>
resource has to be issued, using as a payload the metadata patch, as
<a href="https://tools.ietf.org/html/rfc7396">JSON Merge Patch</a> functionality
describes. A complete description of updating metadata Firecracker API can be
found in the <a href="../../src/api_server/swagger/firecracker.yaml">firecracker swagger file</a>.</p>
<p>An example API for how to update existing metadata is offered below:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PATCH &quot;http://localhost/mmds&quot;          \
    -H &quot;Content-Type: application/json&quot;       \
    -d '{
            &quot;latest&quot;: {
                  &quot;meta-data&quot;: {
                       &quot;ami-id&quot;: &quot;ami-87654321&quot;,
                       &quot;reservation-id&quot;: &quot;r-79054aef&quot;,
                  }
            }
    }'
</code></pre>
<h2 id="retrieving-metadata"><a class="header" href="#retrieving-metadata">Retrieving metadata</a></h2>
<p>MicroVM metadata can be retrieved both from host and guest operating systems.
For the scope of this chapter, let's assume the data store content is the JSON
below:</p>
<pre><code class="language-json">{
    &quot;latest&quot;: {
          &quot;meta-data&quot;: {
               &quot;ami-id&quot;: &quot;ami-87654321&quot;,
               &quot;reservation-id&quot;: &quot;r-79054aef&quot;
          }
    }
}
</code></pre>
<h3 id="retrieving-metadata-in-the-host-operating-system"><a class="header" href="#retrieving-metadata-in-the-host-operating-system">Retrieving metadata in the host operating system</a></h3>
<p>To retrieve existing MMDS metadata from host operating system, an HTTP <code>GET</code>
request to the <code>/mmds</code> resource must be issued. The HTTP response returns the
existing metadata, as a JSON formatted text. A complete description of
retrieving metadata Firecracker API can be found in the
<a href="../../src/api_server/swagger/firecracker.yaml">firecracker swagger file</a>.</p>
<p>Below you can see how to retrieve metadata from the host:</p>
<pre><code class="language-bash">curl -s --unix-socket /tmp/firecracker.socket http://localhost/mmds
</code></pre>
<p>Output:</p>
<pre><code class="language-json">{
    &quot;latest&quot;: {
          &quot;meta-data&quot;: {
               &quot;ami-id&quot;: &quot;ami-87654321&quot;,
               &quot;reservation-id&quot;: &quot;r-79054aef&quot;
          }
    }
}
</code></pre>
<h3 id="retrieving-metadata-in-the-guest-operating-system"><a class="header" href="#retrieving-metadata-in-the-guest-operating-system">Retrieving metadata in the guest operating system</a></h3>
<p>Accessing the contents of the metadata store from the guest operating system
can be done using one of the following methods:</p>
<ul>
<li><code>V1</code>: simple request/response method (deprecated)</li>
<li><code>V2</code>: session-oriented method</li>
</ul>
<h4 id="version-1-deprecated"><a class="header" href="#version-1-deprecated">Version 1 (Deprecated)</a></h4>
<p><strong>Version 1 is deprecated and will be removed in the next major version change.
Version 2 should be used instead.</strong></p>
<p>To retrieve existing MMDS metadata using MMDS version 1, an HTTP <code>GET</code>
request must be issued. The requested resource can be referenced by its
corresponding <a href="https://tools.ietf.org/html/rfc6901">JSON Pointer</a>, which is
also the path of the MMDS request. The HTTP response content will contain the
referenced metadata resource.</p>
<p>The only HTTP method supported by MMDS version 1 is <code>GET</code>. Requests containing
any other HTTP method will receive <strong>405 Method Not Allowed</strong> error.</p>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
RESOURCE_POINTER_OBJ=latest/meta-data
curl -s &quot;http://${MMDS_IPV4_ADDR}/${RESOURCE_POINTER_OBJ}&quot;
</code></pre>
<h4 id="version-2"><a class="header" href="#version-2">Version 2</a></h4>
<p>Similar to <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html">IMDSv2</a>,
MMDS version 2 (<code>V2</code>) is a session oriented method, which makes use of a session
token in order to allow fetching metadata contents.</p>
<p>The session must start with an HTTP <code>PUT</code> request that generates the session token.
In order to be successful, the request must respect the following constraints:</p>
<ul>
<li>must be directed towards <code>/latest/api/token</code> path</li>
<li>must contain a <code>X-metadata-token-ttl-seconds</code> header specifying the token lifetime
in seconds. The value cannot be lower than 1 or greater than 21600 (6 hours).</li>
<li>must not contain a <code>X-Forwarded-For</code> header.</li>
</ul>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
TOKEN=`curl -X PUT &quot;http://${MMDS_IPV4_ADDR}/latest/api/token&quot; \
      -H &quot;X-metadata-token-ttl-seconds: 21600&quot;`
</code></pre>
<p>The HTTP response from MMDS is a plaintext containing the session token.</p>
<p>During the duration specified by the token's time to live value, all subsequent
<code>GET</code> requests must specify the session token through the <code>X-metadata-token</code>
header in order to fetch data from MMDS.</p>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
RESOURCE_POINTER_OBJ=latest/meta-data
curl -s &quot;http://${MMDS_IPV4_ADDR}/${RESOURCE_POINTER_OBJ}&quot; \
    -H &quot;X-metadata-token: ${TOKEN}&quot;
</code></pre>
<p>After the token expires, it becomes unusable and a new session token must be issued.</p>
<h5 id="snapshotting-considerations"><a class="header" href="#snapshotting-considerations">Snapshotting considerations</a></h5>
<p>The data store is <strong>not</strong> persisted across snapshots, in order to avoid leaking
vm-specific information that may need to be reseeded into the data store for
a new clone.</p>
<p>The MMDS version, network stack configuration and IP address used for accessing the
service are persisted across snapshot-restore.</p>
<p>If the targeted snapshot version does not support Mmds Version 2, it will not be
persisted in the snapshot (the clone will use the default, V1). Similarly, if a
snapshotted Vm state contains the Mmds version but the Firecracker version used
for restoring does not support persisting the version, the default will be used.</p>
<h3 id="mmds-formats"><a class="header" href="#mmds-formats">MMDS formats</a></h3>
<p>The response format can be JSON or IMDS. The IMDS documentation
can be found <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">here</a>.
The output format can be selected by specifying the optional <code>Accept</code> header.
Using <code>Accept: application/json</code> will format the output to JSON, while using
<code>Accept: plain/text</code> or not specifying this optional header at all will format
the output to IMDS.</p>
<p>Retrieving MMDS resources in IMDS format, other than JSON <code>string</code> and <code>object</code> types,
is not supported.</p>
<p>Below is an example on how to retrieve the <code>latest/meta-data</code> resource in
JSON format:</p>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
RESOURCE_POINTER_OBJ=latest/meta-data
curl -s -H &quot;Accept: application/json&quot; &quot;http://${MMDS_IPV4_ADDR}/${RESOURCE_POINTER_OBJ}&quot;
</code></pre>
<p>Output:</p>
<pre><code class="language-json">{
    &quot;ami-id&quot;: &quot;ami-87654321&quot;,
    &quot;reservation-id&quot;: &quot;r-79054aef&quot;
}
</code></pre>
<p>Retrieving the <code>latest/meta-data/ami-id</code> resource in JSON format:</p>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
RESOURCE_POINTER_STR=latest/meta-data/ami-id
curl -s -H &quot;Accept: application/json&quot; &quot;http://${MMDS_IPV4_ADDR}/${RESOURCE_POINTER_STR}&quot;
</code></pre>
<p>Output:</p>
<pre><code class="language-json">&quot;ami-87654321&quot;
</code></pre>
<p>Retrieving the <code>latest</code> resource in IMDS format:</p>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
RESOURCE_POINTER=latest
curl -s &quot;http://${MMDS_IPV4_ADDR}/${RESOURCE_POINTER}&quot;
</code></pre>
<p>Output:</p>
<pre><code class="language-text">meta-data/
</code></pre>
<p>Retrieving the <code>latest/meta-data/</code> resource in IMDS format:</p>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
RESOURCE_POINTER=latest/meta-data
curl -s &quot;http://${MMDS_IPV4_ADDR}/${RESOURCE_POINTER}&quot;
</code></pre>
<p>Output:</p>
<pre><code class="language-text">ami-id
reservation-id
</code></pre>
<p>Retrieving the <code>latest/meta-data/ami-id</code> resource in IMDS format:</p>
<pre><code class="language-bash">MMDS_IPV4_ADDR=169.254.170.2
RESOURCE_POINTER=latest/meta-data/ami-id
curl -s &quot;http://${MMDS_IPV4_ADDR}/${RESOURCE_POINTER}&quot;
</code></pre>
<p>Output:</p>
<pre><code class="language-text">ami-87654321
</code></pre>
<h2 id="errors"><a class="header" href="#errors">Errors</a></h2>
<p><em>200</em> - <code>Ok</code></p>
<p>The request was successfully processed and a response was successfully formed.</p>
<p><em>400</em> - <code>Bad Request</code></p>
<p>The request was malformed.</p>
<p><em>401</em> - <code>Unauthorized</code></p>
<p>Only when using MMDS <code>V2</code>. The HTTP request either lacks the session token,
or the token specified is invalid. A token is invalid if it was not
generated using an HTTP <code>PUT</code> request or if it has expired.</p>
<p><em>404</em> - <code>Not Found</code></p>
<p>The requested resource can not be found in the MMDS data store.</p>
<p><em>405</em> - <code>Method Not Allowed</code></p>
<p>The HTTP request uses a not allowed HTTP method and a response with the <code>Allow</code>
header was formed. When using MMDS <code>V1</code>, this is returned for any HTTP method
other than <code>GET</code>. When MMDS <code>V2</code> is configured, the only accepted HTTP methods
are <code>PUT</code> and <code>GET</code>.</p>
<p><em>501</em> - <code>Not Implemented</code></p>
<p>The requested HTTP functionality is not supported by MMDS or the requested
resource is not supported in IMDS format.</p>
<h2 id="appendix-1"><a class="header" href="#appendix-1">Appendix</a></h2>
<h3 id="example-use-case-credential-rotation"><a class="header" href="#example-use-case-credential-rotation">Example use case: credential rotation</a></h3>
<p>For this example, the guest expects to find some sort of credentials (say, a
secret access key) by issuing a <code>GET</code> request to
<code>http://169.254.169.254/latest/meta-data/credentials/secret-key</code>. Most similar
use cases will encompass the following sequence of steps:</p>
<ol>
<li>Some agent running on the host sends a <code>PUT</code> request with the initial
contents of the MMDS, using the Firecracker API. This most likely takes
place before the microVM starts running, but may also happen at a later
time. Guest MMDS requests which arrive prior to contents being available
receive a <em>NotFound</em> response.</li>
<li>The contents are saved to MMDS.</li>
<li>The guest sends a <code>GET</code> request for the secret key, which is intercepted by
MMDS.</li>
<li>MMDS processes the request and sends back an HTTP response with the ensembled
secret key as a JSON string.</li>
</ol>
<p>After a while, the host agent decides to rotate the secret key. It does so by
updating the data store with a new value. This can be done via a <code>PUT</code> request
to the <code>/mmds</code> API resource, which replaces everything, or with a <code>PATCH</code>
request that only touches the desired key. This effectively triggers the first
two steps again.</p>
<p>The guest reads the new secret key, going one more time through the last three
steps. This can happen after a notification from the host agent, or discovered
via periodic polling, or some other mechanism. Since access to the data store
is thread safe, the guest can only receive either the old version, or the new
version of the key, and not some intermediate state caused by the update.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="snapshotting"><a class="header" href="#snapshotting">Snapshotting</a></h1>
<p>TODO</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="handling-snapshot-memory-loading"><a class="header" href="#handling-snapshot-memory-loading">Handling snapshot memory loading</a></h1>
<p>Firecracker allows for a better management of the microVM's memory loading
by letting users choose between relying on host OS to handle the page faults
when resuming from a snapshot, or having a dedicated userspace process for
dealing with page faults, with the help of
<a href="https://www.kernel.org/doc/html/v4.18/admin-guide/mm/userfaultfd.html">Userfaultfd</a>.</p>
<h2 id="kernel"><a class="header" href="#kernel">Kernel</a></h2>
<p>When resuming a microVM from a snapshot, loading the snapshotted guest's memory
(which is file-backed) into RAM is usually kernel's responsibility and is handled
on a per-page-fault basis. Each time the guest touches a page that is not already
in Firecracker's process memory, a page fault occurs, which triggers a context
switch and IO operation in order to bring that page into RAM. Depending on the
use case, doing this for every page can be time-consuming.</p>
<h2 id="userfaultfd"><a class="header" href="#userfaultfd">Userfaultfd</a></h2>
<p>Userfaultfd is a mechanism that passes that responsibility of handling page
fault events from kernel space to user space. In order to be able to interact
with this mechanism, userspace needs to firstly obtain an userfault file descriptor
object (UFFD).</p>
<h3 id="creating-a-uffd-object"><a class="header" href="#creating-a-uffd-object">Creating a UFFD object</a></h3>
<h4 id="kernels-414-and-510"><a class="header" href="#kernels-414-and-510">Kernels 4.14 and 5.10</a></h4>
<p>For (host) kernels 4.14 and 5.10 UFFD objects are created by calling into
<a href="https://man7.org/linux/man-pages/man2/userfaultfd.2.html"><code>userfaultfd</code> syscall</a>.</p>
<h4 id="kernel-61"><a class="header" href="#kernel-61">Kernel 6.1</a></h4>
<p>For kernel 6.1, UFFD is created through the <code>/dev/userfaultfd</code> device. Access
to <code>/dev/userfaultfd</code> is managed by file system permissions, so the Firecracker
process needs to have proper permissions to create the UFFD object. When
<code>/dev/userfaultfd</code> is present on the host system, jailer makes it available
inside the jail and Firecracker process can use it without any further
configuration.</p>
<p>If a user is not using Firecracker along with the jailer, they should manage
manually permissions to <code>/dev/userfaultfd</code>. For example, on systems that rely
on access control lists (ACLs), this can be achieved by:</p>
<pre><code class="language-bash">sudo setfacl -m u:${USER}:rw /dev/userfaultfd
</code></pre>
<h3 id="registering-memory-to-be-handled-via-userfault-file-descriptors"><a class="header" href="#registering-memory-to-be-handled-via-userfault-file-descriptors">Registering memory to be handled via Userfault File Descriptors</a></h3>
<p>Next, the memory address range must be registered with the userfault file
descriptor so that the userfault object can monitor page faults occurring for
those addresses. After this, the user space process can start reading and serving
events via the userfault file descriptor. These events will contain the address
that triggered the fault. The fault-handling thread can choose to handle these
events using these <a href="https://www.kernel.org/doc/html/latest/admin-guide/mm/userfaultfd.html#resolving-userfaults">operations</a>.</p>
<p>In the flow described above, there are two userspace processes that interact
with each other in order to handle page faults: Firecracker process and the
page fault handler. Please note that users are responsible for writing the page
fault handler process to monitor userfaultfd events and handle those events.</p>
<p>Below is the interaction flow between Firecracker and the page fault handler
(designed by the users):</p>
<ul>
<li>Page fault handler binds and listens on a unix domain socket in order
to be able to communicate with the Firecracker process.</li>
</ul>
<p><img src="../images/uffd_flow1.png" alt="" /></p>
<p>Please note that when using the Jailer, the page fault handler process, UDS and
memory file must reside inside the jail. The UDS must only be accessible to
Firecracker and the page fault handler.</p>
<ul>
<li>PUT snapshot/load API call is issued towards Firecracker's API thread.
The request encapsulates in its body the path to the unix domain socket that
page fault handler listens to in order to communicate with Firecracker.</li>
<li>Firecracker process creates the userfault object and obtains the userfault
file descriptor.</li>
<li>The page fault handler privately mmaps the contents of the guest memory file.</li>
</ul>
<p><img src="../images/uffd_flow2.png" alt="" /></p>
<ul>
<li>Firecracker anonymously mmaps memory based on the memory description found
in the microVM state file and registers the memory regions with the userfault
object in order for the userfaultfd to be aware of page fault events on these
addresses. Firecracker then connects to the socket previously opened by the page
fault process.</li>
</ul>
<p><img src="../images/uffd_flow3.png" alt="" /></p>
<ul>
<li>Firecracker passes the userfault file descriptor and the guest memory layout
to the page fault handler process through the socket.</li>
</ul>
<p><img src="../images/uffd_flow4.png" alt="" /></p>
<ul>
<li>
<p>After sending the necessary information to the page fault handler, Firecracker
continues with the normal cycle to restore from snapshot. It reads from the microVM
state file the relevant serialized components and loads them into memory.</p>
</li>
<li>
<p>Page faults that occur while Firecracker is touching guest memory are handled
by the page fault handler process, which listens for events on the userfault file
descriptor that Firecracker previously sent. When a page fault event happens,
the page fault handler issues <code>UFFDIO_COPY</code> to load the previously mmaped file
contents into the correspondent memory region.</p>
</li>
</ul>
<p>After Firecracker sends the payload (i.e mem mappings and file descriptor), no
other communication happens on the UDS socket (or otherwise) between Firecracker
and the page fault handler process.</p>
<h3 id="userfaultfd-interaction-with-balloon"><a class="header" href="#userfaultfd-interaction-with-balloon">Userfaultfd interaction with balloon</a></h3>
<p>The balloon device allows the host to reclaim memory from a microVM. For more
details on balloon, please refer to <a href="../ballooning.html">this doc</a>.</p>
<p>When the balloon device asks for removal of a memory range, Firecracker calls
<code>madvise</code> with the <code>MADV_DONTNEED</code> flag in order to let the kernel know that it
can free up memory found in that specific area. On such a system call, the
userfaultfd interface sends <code>UFFD_EVENT_REMOVE</code>.</p>
<p>When implementing the logic for the page fault handler, users must identify events
of type <code>UFFD_EVENT_REMOVE</code> and handle them by zeroing out those pages. This is
because the memory is removed, but the area still remains monitored by userfaultfd.
After a cycle of inflation and deflation, page faults might happen again for memory
ranges that have been removed by balloon (and subsequently zeroed out by the page
fault handler). In such a case, the page fault handler process must zero out the
faulted page (instead of bringing it from file), as recommended by <a href="https://www.kernel.org/doc/html/latest/admin-guide/mm/userfaultfd.html#non-cooperative-userfaultfd">the userfaultfd
documentation</a>.</p>
<p>In case of a compromised balloon driver, the page fault handler can get flooded with
<code>UFFD_EVENT_REMOVE</code>. We recommend using the jailer's built-in cgroup functionality
as defense in depth, in order to limit resource usage of the Firecracker process.</p>
<h3 id="caveats-2"><a class="header" href="#caveats-2">Caveats</a></h3>
<p>If the handler process crashes while Firecracker is resuming the snapshot, Firecracker
will hang when a page fault occurs. This is because Firecracker is designed to
wait for the requested page to be made available. If the page fault handler process
is no longer around when this happens, Firecracker will wait forever. Users are
expected to monitor the page fault handler's status or gather metrics of hanged
Firecracker process and implement a recycle mechanism if necessary.</p>
<p>It is the page fault handler process's responsibility to handle any errors that
might occur and also send signals to Firecracker process to inform it of any
crashes/exits. The page fault handler can fetch Firecracker's PID through <code>getsockopt</code>
call with <code>SO_PEERCRED</code> option, which fetches credentials of the peer process that
is connected to the socket. The returned credentials contain: PID, GID and UID of
the peer process (Firecracker in the page fault handler's case).</p>
<p>We recommend that the page fault handler includes timeouts for waiting on Firecracker
to connect to the UDS or send information over the UDS, in order to account for
unexpected cases when Firecracker crashes before being able to connect/send data.</p>
<h3 id="example-1"><a class="header" href="#example-1">Example</a></h3>
<p>An example of a handler process can be found <a href="../../src/firecracker/examples/uffd/valid_handler.rs">here</a>.
The process is designed to tackle faults on a certain address by loading into
memory the entire region that the address belongs to, but users can choose any
other behavior that suits their use case best.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="network-connectivity-for-clones"><a class="header" href="#network-connectivity-for-clones">Network Connectivity for Clones</a></h1>
<p>This document presents the strategy to ensure continued network connectivity
for multiple clones created from a single Firecracker microVM snapshot.
This document also provides an overview of the scalability benchmarks we
performed.</p>
<h2 id="setup"><a class="header" href="#setup">Setup</a></h2>
<p>There are two things which prevent network connectivity from resuming
out-of-the-box for clones created from the same snapshot: Firecracker currently
saves and attempts to restore network devices using the initially
configured TAP names, and each guest will be resumed with the same
network configuration, most importantly with the same IP address(es).
To work around the former, each clone should be started within a
separate network namespace (we can have multiple TAP interfaces with the
same name, as long as they reside in distinct network namespaces).
The latter can be mitigated by leveraging <code>iptables</code> <code>SNAT</code> and <code>DNAT</code>
support. We choose a clone address (<strong>CA</strong>) for each clone, which is the
new address that’s going to represent the guest, and make it so all
packets leaving the VM have their source address rewritten to CA,
and all incoming packets with the destination address equal to CA
have it rewritten to the IP address configured inside the guest (which
remains the same for all clones). Each individual clone continues to
believe it’s using the original address, but outside the VM packets are
assigned a different one for every clone.</p>
<p>Let’s have a more detailed look at this approach. We assume each VM has
a single network interface attached. If multiple interfaces with full
connectivity are required, we simply repeat the relevant parts of this
process for each additional interface. A typical setup right before
taking a snapshot involves having a VM with a network interface backed
by a TAP device (named <code>vmtap0</code>, for example) with an IP address
(referred to as the TAP IP address, for example <code>192.168.241.1/29</code>), and
an IP address configured inside the guest for the corresponding virtio
device (referred to as the guest IP address, for example
<code>192.168.241.2/29</code>).</p>
<h3 id="network-namespaces"><a class="header" href="#network-namespaces">Network namespaces</a></h3>
<p>Attempting to restore multiple clones from the same snapshot faces the
problem of every single one of them attempting to use a TAP device with
the original name, which is not possible by default. Therefore, we need
to start each clone in a separate network namespace. This is already
possible using the netns jailer parameter, described in the
<a href="../jailer.html">documentation</a>. The specified namespace must already
exist, so we have to create it first using</p>
<pre><code class="language-bash">sudo ip netns add fc0
</code></pre>
<p>(where <code>fc0</code> is the name of the network namespace we plan to use for
this specific clone - <code>clone0</code>). A new network namespace is initially
empty, so we also have to create a new tap interface within using</p>
<pre><code class="language-bash">sudo ip netns exec fc0 ip tuntap add name vmtap0 mode tap
</code></pre>
<p>The <code>ip netns exec &lt;ns_name&gt; &lt;command&gt;</code> allows us to execute <code>command</code>
in the context of the specified network namespace (in the previous case,
the secondary command creates a new tap interface). Next we configure
the new TAP interface to match the expectations of the snapshotted guest
by running</p>
<pre><code class="language-bash">sudo ip netns exec fc0 ip addr add 192.168.241.1/29 dev vmtap0
sudo ip netns exec fc0 ip link set vmtap0 up
</code></pre>
<p>At this point we can start multiple clones, each in its separate
namespace, but they won’t have connectivity to the rest of the host,
only the respective TAP interfaces. However, interaction over the
network is still possible; for example we can connect over ssh to
clone0 using</p>
<pre><code class="language-bash">sudo ip netns exec fc0 ssh root@192.168.241.2
</code></pre>
<h3 id="veth-interfaces-to-connect-the-network-namespaces"><a class="header" href="#veth-interfaces-to-connect-the-network-namespaces"><code>veth</code> interfaces to connect the network namespaces</a></h3>
<p>In order to obtain full connectivity we have to begin by connecting the
network namespace to the rest of the host, and then solving the
<em>“same guest IP”</em> problem. The former requires the use of <code>veth</code>
pairs - <em>virtual interfaces that are link-local to each other (any
packet sent through one end of the pair is immediately received on the
other, and the other way around)</em>.
One end resides inside the network namespace, while the other is moved
into the parent namespace (the host global namespace in this case),
and packets flow in or out according to the network configuration. We
have to pick IP addresses for both ends of the veth pair. For clone
index <code>idx</code>, let’s use <code>10.&lt;idx / 30&gt;.&lt;(idx % 30) * 8&gt;.1/24</code> for the
endpoint residing in the host namespace, and the same address ending
with <code>2</code> for the other end which remains inside the clone's namespace.
Thus, for <code>clone 0</code> the former is <code>10.0.0.1</code> and the latter <code>10.0.0.2</code>.</p>
<p>The first endpoint must have an unique name on the host, for example
chosen as <code>veth(idx + 1) (so veth1 for clone 0)</code>. To create and setup
the veth pair, we use the following commands (for namespace <code>fc0</code>):</p>
<pre><code class="language-bash"># create the veth pair inside the namespace
sudo ip netns exec fc0 ip link add veth1 type veth peer name veth0
# move veth1 to the global host namespace
sudo ip netns exec fc0 ip link set veth1 netns 1

sudo ip netns exec fc0 ip addr add 10.0.0.2/24 dev veth0
sudo ip netns exec fc0 ip link set dev veth0 up

sudo ip addr add 10.0.0.1/24 dev veth1
sudo ip link set dev veth1 up

# designate the outer end as default gateway for packets leaving the namespace
sudo ip netns exec fc0 ip route add default via 10.0.0.1
</code></pre>
<h3 id="iptables-rules-for-end-to-end-connectivity"><a class="header" href="#iptables-rules-for-end-to-end-connectivity"><code>iptables</code> rules for end-to-end connectivity</a></h3>
<p>The last step involves adding the <code>iptables</code> rules which change the
source/destination IP address of packets on the fly (thus allowing all
clones to have the same internal IP). We need to choose a clone address,
which is unique on the host for each VM. In the demo, we use
<code>192.168.&lt;idx / 30&gt;.&lt;(idx % 30) * 8 + 3&gt;</code> (which is <code>192.168.0.3</code> for
<code>clone 0</code>):</p>
<pre><code class="language-bash"># for packets that leave the namespace and have the source IP address of the
# original guest, rewrite the source address to clone address 192.168.0.3
sudo ip netns exec fc0 iptables -t nat -A POSTROUTING -o veth0 \
-s 192.168.241.2 -j SNAT --to 192.168.0.3

# do the reverse operation; rewrites the destination address of packets
# heading towards the clone address to 192.168.241.2
sudo ip netns exec fc0 iptables -t nat -A PREROUTING -i veth0 \
-d 192.168.0.3 -j DNAT —to 192.168.241.2

# (adds a route on the host for the clone address)
sudo ip route add 192.168.0.3 via 10.0.0.2
</code></pre>
<p><strong>Full connectivity to/from the clone should be present at this point.</strong></p>
<p>To make sure the guest also adjusts to the new environment, you can explicitly
clear the ARP/neighbour table in the guest:</p>
<pre><code class="language-bash">ip -family inet neigh flush any
ip -family inet6 neigh flush any
</code></pre>
<p>Otherwise, packets originating from the guest might be using old Link Layer
Address for up to arp cache timeout seconds. After said timeout period,
connectivity will work both ways even without an explicit flush.</p>
<h2 id="scalability-evaluation"><a class="header" href="#scalability-evaluation">Scalability evaluation</a></h2>
<p>We ran synthetic tests to determine the impact of the addtional iptables
rules and namespaces on network performance. We compare the case where
each VM runs as regular Firecracker (gets assigned a TAP interface and a
unique IP address in the global namespace) versus the setup with a
separate network namespace for each VM (together with the veth pair and
additional rules). We refer to the former as the basic case, while the
latter is the ns case. We measure latency with the <code>ping</code> command and
throughput with <code>iperf</code>.</p>
<p>The experiments, ran on an Amazon AWS <code>m5d.metal</code> EC2 instace, go as follows:</p>
<ul>
<li>Set up 3000 network resource slots (different TAP interfaces for the
basic case, and namespaces + everything else for ns). This is mainly
to account for any difference the setup itself might make, even if
there are not as many active endpoints at any given time.</li>
<li>Start 1000 Firecracker VMs, and pick <code>N &lt; 1000</code> as the number of
active VMs that are going to generate network traffic. For ping
experiments, we ping each active VM from the host every 500ms for 30
seconds. For <code>iperf</code> experiments, we measure the average bandwidth of
connections from the host to every active VM lasting 40 seconds.
There is one separate client process per VM.</li>
<li>When <code>N = 100</code>, in the basic case we get average latencies of <code>0.315 ms (0.160/0.430 min/max)</code> for <code>ping</code>, and an average throughput of
<code>2.25 Gbps (1.62/3.21 min/max)</code> per VM for <code>iperf</code>. In the ns case,
the ping results <strong>are bumped higher by around 10-20 us</strong>, while the
<code>iperf</code> results are virtually the same on average, with a higher
minimum (1.73 Gbps) and a lower maximum (3 Gbps).</li>
<li>When <code>N = 1000</code>, we start facing desynchronizations caused by
difficulties in starting (and thus finishing) the client processes all
at the same time, which creates a wider distribution of results. In
the basic case, the average latency for ping  experiments has gone
down to 0.305 ms, the minimum decreased to 0.155 ms, but the maximum
increased to 0.640 ms. The average <code>iperf</code> per VM throughput is around
<code>440 Mbps (110/3936 min/max)</code>. In the ns case, average <code>ping</code> latency
is now <code>0.318 ms (0.170/0.650 min/max)</code>. For <code>iperf</code>, the average
throughput is very close to basic at <code>~430 Mbps</code>, while the minimum
and maximum values are lower at <code>85/3803 Mbps</code>.</li>
</ul>
<p><strong>The above measurements give a significant degree of confidence in the
scalability of the solution</strong> (subject to repeating for different values
of the experimental parameters, if necessary). The increase in latency
is almost negligible considering usual end-to-end delays. The lower
minimum throughput from the iperf measurements might be significant, but
only if that magnitude of concurrent, data-intensive transfers is likely.
Moreover, the basic measurements are close to an absolute upper bound.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="entropy-for-clones"><a class="header" href="#entropy-for-clones">Entropy for Clones</a></h1>
<p>This document provides a high level perspective on the implications
of restoring multiple VM clones from a single snapshot.
We start with an overview of the Linux random number generation (RNG)
facilities, then go through the potential issues we’ve identified related
to cloning state, and finally conclude with a series of recommendations.
It’s worth stressing that we aim to prevent stale state being a problem
only for the kernel interfaces. Some userspace applications or libraries
keep their own equivalent of entropy pools and suffer from the same potential
issues after being cloned. There is no generic solution under the current
programming model, and all we can do is recommend against their use in
pre-snapshot logic.</p>
<h2 id="background"><a class="header" href="#background">Background</a></h2>
<p>The Linux kernel exposes three main <code>RNG</code> interfaces to userspace: the
<code>/dev/random</code> and <code>/dev/urandom</code> special devices, and the <code>getrandom</code> syscall,
which are described in the <a href="http://man7.org/linux/man-pages/man7/random.7.html" title="Lala">random(7) man page</a>. Moreover, Firecracker
supports the <a href="../entropy.html"><code>virtio-rng</code></a> device which can provide additional
entropy to guest VMs. It draws its random bytes from the <a href="https://docs.rs/aws-lc-rs/latest/aws_lc_rs/index.html"><code>aws-lc-rs</code></a> crate
which wraps the <a href="https://github.com/aws/aws-lc"><code>AWS-LC</code> cryptographic library</a>.</p>
<p>Traditionally, <code>/dev/random</code> has been considered a source of “true”
randomness, with the downside that reads block when the pool of entropy
gets depleted. On the other hand, <code>/dev/urandom</code> doesn’t block, but
provides lower quality results. It turns out the distinction in output
quality is actually very hard to make. According to <a href="https://www.2uo.de/myths-about-urandom">this article</a>,
for kernel versions prior to 4.8, both devices draw their output from the same
pool, with the exception that <code>/dev/random</code> will block when the system
estimates the entropy count has decreased below a certain threshold.
The <code>/dev/urandom</code> output is considered secure for virtually all
purposes, with the caveat that using it before the system gathers
sufficient entropy for initialization may indeed produce low quality
random numbers. The <code>getrandom</code> syscall helps with this situation; it
uses the <code>/dev/urandom</code> source by default, but will block until it gets
properly initialized (the behavior can be altered via configuration flags).</p>
<p>Newer kernels (4.8+) have switched to an implementation where
<code>/dev/random</code> output comes from a pool called the blocking pool, the
output of <code>/dev/urandom</code> is given by a CSPRNG (cryptographically secure
pseudorandom number generator), and there’s also an input pool which
gathers entropy from various sources available on the system, and is
used to feed into or seed the other two components. A very detailed
description is available <a href="https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/Publications/Studies/LinuxRNG/LinuxRNG_EN.pdf">here</a>.</p>
<p>The details of this newer implementation are used to make the
recommendations present in the document. There are in-kernel interfaces
used to obtain random numbers as well, but they are similar to using
<code>/dev/urandom</code> (or <code>getrandom</code> with the default source) from userspace.</p>
<p>Whenever a VM clone is created based on a snapshot, execution resumes
precisely from the previously saved state. Getting random bytes from
either <code>/dev/random</code> or <code>/dev/urandom</code> does not lead to identical
results for different clones created from the same snapshot because
multiple parameters (such as timer data, or output from <code>CPU HWRNG</code>
instructions which are present on Ivy Bridge or newer Intel processors
and enabled in a Firecracker guest) are mixed with each result. Extra
bits are mixed in both when reading random values, and in conjunction
with entropy related events such as interrupts. Moreover, the guest kernel
will eventually receive fresh entropy from <code>virtio-rng</code>, if attached. There are
two questions here:</p>
<ul>
<li>Is the <code>CPU HWRNG</code> output always mixed in when
the feature is present (as opposed to only when the <code>CPU HWRNG</code> is trusted)?</li>
<li>Is the added noise strong enough to consider the final RNG output
sufficiently divergent from all other clones?</li>
</ul>
<p>Both these questions are particularly relevant immediately after resuming
a VM from a snapshot. After the VM gets to run for a &quot;sufficient&quot; amount of time
it should be able to gather some more entropy by itself and its state should
be sufficiently divergent that of any other clones.</p>
<p>It seems the <code>CPU HWRNG</code> is always added to mix when present. More
specifically, <a href="https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/Publications/Studies/LinuxRNG/LinuxRNG_EN.pdf">page 32 point 1 (at the top of the page)</a>
mentions using the <code>CPU HWRNG</code> when present for the entropy pool output
function. Page 34 states <em>in case a CPU random number generator is known
to the Linux-RNG, data from that hardware RNG is mixed into the entropy
pool in a second step</em>. With respect to the initialization of the random
pools and DRNG behind /dev/urandom. The discussion regarding DRNG state
on page 35 mentions <em>the key part, the counter, and the nonce are XORed
with the output of the CPU random number generator if one is present. If
it is not present, one high-resolution time stamp obtained with the
kernel function random_get_entropy word is XORed with the key part</em>.
The <code>CPU HWRNG</code> is also used for the DRNG state transition function (as
stated on page 36 point 1), and during the reseed operation (page 37
point 2). The document explicitly mentions when the <code>CPU HWRNG</code> has to be
trusted (for example, the bullet points at the end  of Section 3.3.2.3).</p>
<p>It’s not yet clear whether the noise that gets added for each clone post
restore is sufficient to consider their RNG states distinct for security
purposes. The conservative approach is to presume the stale state has a
significant influence on RNG output, so we should reinitialize both
sources based on fresh data after each restore. It would seem that
simply writing data to <code>/dev/urandom</code> is enough to muddle the entropy
pools, but the bits only get mixed with the input pool. It’s not certain
at this point whether such writes have any immediate impact on the
blocking pool, and it’s unlikely they cause the <code>CSPRNG</code> to be
automatically reseeded.</p>
<p>The standard methods of interacting with the kernel RNG sources are
documented in the <a href="http://man7.org/linux/man-pages/man4/random.4.html">random(4) man page</a>.
It states that any writes to either <code>/dev/random</code> or <code>/dev/urandom</code> are
mixed with the input entropy pool, but do not increase the current
entropy estimation. There is also an <code>ioctl</code> interface which, given the
appropriate privileges, can be used to add data to the input entropy
pool while also increasing the count, or completely empty all pools.</p>
<p>Init systems (such as <code>systemd</code> used by AL2 and other distros) might
save a random seed file after boot. For <code>systemd</code>, the path is
<code>/var/lib/systemd/random-seed</code>. Just to be on the safe side, any such
file should be deleted before taking a snapshot, to prevent its reuse
for any purposes by the guest. There’s also the
<code>/proc/sys/kernel/random/boot_id</code> special file, which gets initialized
with a random string at boot time, and is read-only afterwards. All
clones restored from the same snapshot will implicitly read the same
value from this file. If that’s not desirable, it’s possible to alter
the read result via bind mounting another file on top of
<code>/proc/sys/kernel/random/boot_id</code>.</p>
<h2 id="recommendations"><a class="header" href="#recommendations">Recommendations</a></h2>
<ul>
<li>Delete <code>/var/lib/systemd/random-seed</code>, or any equivalent files.</li>
<li>If changing the value present in <code>/proc/sys/kernel/random/boot_id</code> is
important, bind mount another file on top of it.</li>
<li>If microVMs run on machines with IvyBridge or newer Intel processors
(which provide RDRAND; in addition, RDSEED is offered starting with
Broadwell). Hardware supported reseeding is done on a cadence defined
by the Linux Kernel and should be sufficient for most cases.</li>
<li>Use <code>virtio-rng</code>. When present, the guest kernel uses the device as an
additional source of entropy.</li>
<li>To be as safe as possible, the direct approach is to do the following (before
customer code is resumed in the clone):
<ol>
<li>Open one of the special devices files (either <code>/dev/random</code> or
<code>/dev/urandom</code>). Take note that <code>RNDCLEARPOOL</code> no longer
<a href="https://elixir.bootlin.com/linux/v4.14.295/source/drivers/char/random.c#L1351">has any effect</a> on the entropy pool.</li>
<li>Issue an <code>RNDADDENTROPY</code> ioctl call (requires <code>CAP_SYS_ADMIN</code>)
to mix the provided bytes into the input
entropy pool and increase the entropy count.
This should also cause the <code>/dev/urandom</code> <code>CSPRNG</code>
to be reseeded. The bytes can be generated locally in the guest,
or obtained from the host.</li>
<li>Issue a <code>RNDRESEEDCRNG</code> ioctl call
(<a href="https://elixir.bootlin.com/linux/v4.14.295/source/drivers/char/random.c#L1355">4.14</a>, <a href="https://elixir.bootlin.com/linux/v5.10.147/source/drivers/char/random.c#L1360">5.10</a>, (requires <code>CAP_SYS_ADMIN</code>)) that specifically
causes the <code>CSPRNG</code> to be reseeded from the input pool.</li>
</ol>
</li>
</ul>
<p><strong>Annex 1 contains the source code of a C program which implements the
previous three steps.</strong> As soon as the guest kernel version switches to
4.19 (or higher), we can rely on the <code>CONFIG_RANDOM_TRUST_CPU</code> kernel
option (or the random.trust_cpu=on cmdline parameter) to have the
entropy pool automatically refilled using the <code>CPU HWRNG</code>, so step 3
would no longer be necessary. Another way around step 3 is to attach a
<code>virtio-rng</code> device. However, we cannot control when the guest kernel will
request for random bytes from the device.</p>
<h2 id="annex-1-source-code-that-clears-and-reinitializes-the-entropy-pool"><a class="header" href="#annex-1-source-code-that-clears-and-reinitializes-the-entropy-pool">Annex 1: Source code that clears and reinitializes the entropy pool</a></h2>
<pre><code class="language-cpp">#include &lt;errno.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;linux/random.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/ioctl.h&gt;

void exit_usage() {
    printf(&quot;Usage: ./rerand [&lt;hexadecimal_string&gt;]\n&quot;
           &quot;The length of the string must be a multiple of 8.\n&quot;);
    exit(EXIT_FAILURE);
}

void exit_perror(const char *msg) {
    perror(msg);
    exit(EXIT_FAILURE);
}

int main(int argc, char ** argv) {
    if (argc &gt; 2) {
        exit_usage();
    }

    size_t len = 0;
    struct rand_pool_info *info = NULL;

    if (argc == 2) {
        len = strlen(argv[1]);
        // We want len to be a multiple of 8 such that we have an easier time
        // parsing argv[1] into an array of u32s.
        if (len % 8) {
            exit_usage();
        }

        info = malloc(sizeof(struct rand_pool_info) + len / 8);
        if (info == NULL) {
            exit_perror(&quot;Could not alloc rand_pool_info struct&quot;);
        }
        // This is measured in bits IIRC.
        info-&gt;entropy_count = len * 4;
        info-&gt;buf_size = len / 8;
    }

    int fd = open(&quot;/dev/urandom&quot;, O_RDWR);
    if (fd &lt; 0) {
        exit_perror(&quot;Unable to open /dev/urandom&quot;);
    }

    if (ioctl(fd, RNDCLEARPOOL) &lt; 0) {
        exit_perror(&quot;Error issuing RNDCLEARPOOL operation&quot;);
    }

    if (argc == 1) {
        exit(EXIT_SUCCESS);
    }

    // Add the entropy bytes supplied by the user.
    char num_buf[9] = {};
    size_t pos = 0;

    while (pos &lt; len) {
        memcpy(num_buf, &amp;argv[1] + pos, 8);
        info-&gt;buf[pos / 8] = strtoul(num_buf, NULL, 16);
        pos += 8;
    }

    if (ioctl(fd, RNDADDENTROPY, info) &lt; 0) {
        exit_perror(&quot;Error issuing RNDADDENTROPY operation&quot;);
    }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="snapshot-editor"><a class="header" href="#snapshot-editor">Snapshot editor</a></h1>
<p>The <code>snapshot-editor</code> is a program for modification of Firecracker snapshots.</p>
<h2 id="prior-knowledge"><a class="header" href="#prior-knowledge">Prior knowledge</a></h2>
<p>Firecracker snapshot consists of 2 files:</p>
<ul>
<li><code>vmstate</code> file: file with Firecracker internal data such as vcpu states,
devices states etc.</li>
<li><code>memory</code> file: file with guest memory.</li>
</ul>
<h2 id="usage-3"><a class="header" href="#usage-3">Usage</a></h2>
<h3 id="edit-memory-command"><a class="header" href="#edit-memory-command"><code>edit-memory</code> command</a></h3>
<h4 id="rebase-subcommand"><a class="header" href="#rebase-subcommand"><code>rebase</code> subcommand</a></h4>
<blockquote>
<p>This command is used to merge a <code>diff</code> snapshot memory file on
top of a base memory file.</p>
<p><strong>Note</strong>
You can also use <code>rebase-snap</code> (deprecated) tool for this.</p>
<p>Arguments:</p>
<ul>
<li><code>MEMORY_PATH</code> - path to the <code>memory</code> file</li>
<li><code>DIFF_PATH</code> - path to the <code>diff</code> file</li>
</ul>
<p>Usage:</p>
<pre><code class="language-bash">snapshot-editor edit-memory rebase \
     --memory-path &lt;MEMORY_PATH&gt; \
     --diff-path &lt;DIFF_PATH&gt;
</code></pre>
<p>Example:</p>
<pre><code class="language-bash">snapshot-editor edit-memory rebase \
     --memory-path ./memory_file \
     --diff-path ./diff_file
</code></pre>
</blockquote>
<h3 id="edit-vmstate-command"><a class="header" href="#edit-vmstate-command"><code>edit-vmstate</code> command</a></h3>
<h4 id="remove-regs-subcommand-aarch64-only"><a class="header" href="#remove-regs-subcommand-aarch64-only"><code>remove-regs</code> subcommand (aarch64 only)</a></h4>
<blockquote>
<p>This command is used to remove specified registers from vcpu states inside
vmstate snapshot file.</p>
<p>Arguments:</p>
<ul>
<li><code>VMSTATE_PATH</code> - path to the <code>vmstate</code> file</li>
<li><code>OUTPUT_PATH</code> - path to the file where the output will be placed</li>
<li><code>[REGS]</code> - set of u32 values representing registers ids as they are defined
in KVM. Can be both in decimal and in hex formats.</li>
</ul>
<p>Usage:</p>
<pre><code class="language-bash">snapshot-editor edit-vmstate remove-regs \
    --vmstate-path &lt;VMSTATE_PATH&gt; \
    --output-path &lt;OUTPUT_PATH&gt; \
    [REGS]...
</code></pre>
<p>Example:</p>
<pre><code class="language-bash">./snapshot-editor edit-vmstate remove-regs \
    --vmstate-path ./vmstate_file \
    --output-path ./new_vmstate_file \
    0x1 0x2
</code></pre>
</blockquote>
<h3 id="info-vmstate-command"><a class="header" href="#info-vmstate-command"><code>info-vmstate</code> command</a></h3>
<h4 id="version-subcommand"><a class="header" href="#version-subcommand"><code>version</code> subcommand</a></h4>
<blockquote>
<p>This command is used to print version of the provided
vmstate file.</p>
<p>Arguments:</p>
<ul>
<li><code>VMSTATE_PATH</code> - path to the <code>vmstate</code> file</li>
</ul>
<p>Usage:</p>
<pre><code class="language-bash">snapshot-editor info-vmstate version --vmstate-path &lt;VMSTATE_PATH&gt;
</code></pre>
<p>Example:</p>
<pre><code class="language-bash">./snapshot-editor info-vmstate version --vmstate-path ./vmstate_file
</code></pre>
</blockquote>
<h4 id="vcpu-states-subcommand"><a class="header" href="#vcpu-states-subcommand"><code>vcpu-states</code> subcommand</a></h4>
<blockquote>
<p>This command is used to print the vCPU states inside vmstate snapshot file.</p>
<p>Arguments:</p>
<ul>
<li><code>VMSTATE_PATH</code> - path to the <code>vmstate</code> file</li>
</ul>
<p>Usage:</p>
<pre><code class="language-bash">snapshot-editor info-vmstate vcpu-states --vmstate-path &lt;VMSTATE_PATH&gt;
</code></pre>
<p>Example:</p>
<pre><code class="language-bash">./snapshot-editor info-vmstate vcpu-states --vmstate-path ./vmstate_file
</code></pre>
</blockquote>
<h4 id="vm-state-subcommand"><a class="header" href="#vm-state-subcommand"><code>vm-state</code> subcommand</a></h4>
<blockquote>
<p>This command is used to print the vmstate of snapshot file in
readable format thus, making it easier to compare vmstate of 2 snapshots.</p>
<p>Arguments:</p>
<ul>
<li><code>VMSTATE_PATH</code> - path to the <code>vmstate</code> file</li>
</ul>
<p>Usage:</p>
<pre><code class="language-bash">snapshot-editor info-vmstate vm-state --vmstate-path &lt;VMSTATE_PATH&gt;
</code></pre>
<p>Example:</p>
<pre><code class="language-bash">./snapshot-editor info-vmstate vm-state --vmstate-path ./vmstate_file
</code></pre>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firecracker-snapshotting"><a class="header" href="#firecracker-snapshotting">Firecracker Snapshotting</a></h1>
<h2 id="table-of-contents-1"><a class="header" href="#table-of-contents-1">Table of Contents</a></h2>
<ul>
<li><a href="snapshot-support.html#about-microvm-snapshotting">What is microVM snapshotting?</a></li>
<li><a href="snapshot-support.html#snapshotting-in-firecracker">Snapshotting in Firecracker</a>
<ul>
<li><a href="snapshot-support.html#supported-platforms">Supported platforms</a></li>
<li><a href="snapshot-support.html#overview">Overview</a></li>
<li><a href="snapshot-support.html#snapshot-files-management">Snapshot files management</a></li>
<li><a href="snapshot-support.html#performance">Performance</a></li>
<li><a href="snapshot-support.html#developer-preview-status">Developer preview status</a></li>
<li><a href="snapshot-support.html#limitations">Limitations</a></li>
</ul>
</li>
<li><a href="snapshot-support.html#firecracker-snapshotting-characteristics">Firecracker Snapshotting characteristics</a></li>
<li><a href="snapshot-support.html#snapshot-versioning">Snapshot versioning</a></li>
<li><a href="snapshot-support.html#snapshot-api">Snapshot API</a>
<ul>
<li><a href="snapshot-support.html#pausing-the-microvm">Pausing the microVM</a></li>
<li><a href="snapshot-support.html#creating-snapshots">Creating snapshots</a>
<ul>
<li><a href="snapshot-support.html#creating-full-snapshots">Creating full snapshots</a></li>
<li><a href="snapshot-support.html#creating-diff-snapshots">Creating diff snapshots</a></li>
</ul>
</li>
<li><a href="snapshot-support.html#resuming-the-microvm">Resuming the microVM</a></li>
<li><a href="snapshot-support.html#loading-snapshots">Loading snapshots</a></li>
</ul>
</li>
<li><a href="snapshot-support.html#provisioning-host-disk-space-for-snapshots">Provisioning host disk space for snapshots</a></li>
<li><a href="snapshot-support.html#ensure-continued-network-connectivity-for-clones">Ensure continued network connectivity for clones</a></li>
<li><a href="snapshot-support.html#snapshot-security-and-uniqueness">Snapshot security and uniqueness</a>
<ul>
<li><a href="snapshot-support.html#usage-examples">Secure and insecure usage examples</a></li>
<li><a href="snapshot-support.html#reusing-snapshotted-states-securely">Reusing snapshotted states securely</a></li>
</ul>
</li>
<li><a href="snapshot-support.html#vsock-device-limitation">Vsock device limitation</a></li>
</ul>
<h2 id="about-microvm-snapshotting"><a class="header" href="#about-microvm-snapshotting">About microVM snapshotting</a></h2>
<p>MicroVM snapshotting is a mechanism through which a running microVM and its
resources can be serialized and saved to an external medium in the form of a
<code>snapshot</code>. This snapshot can be later used to restore a microVM with its
guest workload at that particular point in time.</p>
<h2 id="snapshotting-in-firecracker"><a class="header" href="#snapshotting-in-firecracker">Snapshotting in Firecracker</a></h2>
<h3 id="supported-platforms-1"><a class="header" href="#supported-platforms-1">Supported platforms</a></h3>
<blockquote>
<p>[!WARNING]
The Firecracker snapshot feature is in <a href="../RELEASE_POLICY.html">developer preview</a>
on all CPU micro-architectures listed in <a href="../../README.html#supported-platforms">README</a>.
See <a href="snapshot-support.html#developer-preview-status">this section</a> for more info.</p>
</blockquote>
<h3 id="overview-2"><a class="header" href="#overview-2">Overview</a></h3>
<p>A Firecracker microVM snapshot can be used for loading it later in a different
Firecracker process, and the original guest workload is being simply resumed.</p>
<p>The original guest which the snapshot is created from, should see no side
effects from this process (other than the latency introduced by the snapshot
creation process).</p>
<p>Both network and vsock packet loss can be expected on guests that are resumed
from snapshots in another Firecracker process.
It is also not guaranteed that the state of the network connections survives
the process.</p>
<p>In order to make restoring possible, Firecracker snapshots save the full state
of the following resources:</p>
<ul>
<li>the guest memory,</li>
<li>the emulated HW state (both KVM and Firecracker emulated HW).</li>
</ul>
<p>The state of the components listed above is generated independently, which brings
flexibility to our snapshotting support. This means that taking a snapshot results
in multiple files that are composing the full microVM snapshot:</p>
<ul>
<li>the guest memory file,</li>
<li>the microVM state file,</li>
<li>zero or more disk files (depending on how many the guest had; these are
<strong>managed by the users</strong>).</li>
</ul>
<p>The design allows sharing of memory pages and read only disks between multiple
microVMs. When loading a snapshot, instead of loading at resume time the full
contents from file to memory, Firecracker creates a
<a href="http://man7.org/linux/man-pages/man2/mmap.2.html">MAP_PRIVATE mapping</a> of the
memory file, resulting in runtime on-demand loading of memory pages. Any subsequent
memory writes go to a copy-on-write anonymous memory mapping.
This has the advantage of very fast snapshot loading times, but comes with the cost
of having to keep the guest memory file around for the entire lifetime of the
resumed microVM.</p>
<h3 id="snapshot-files-management"><a class="header" href="#snapshot-files-management">Snapshot files management</a></h3>
<p>The Firecracker snapshot design offers a very simple interface to interact with
snapshots but provides no functionality to package or manage them on the host.</p>
<p>The <a href="../design.html#threat-containment">threat containment model</a> states
that the host, host/API communication and snapshot files are trusted by Firecracker.</p>
<p>To ensure a secure integration with the snapshot functionality, users need to secure
snapshot files by implementing authentication and encryption schemes while
managing their lifecycle or moving them across the trust boundary, like for
example when provisioning them from a repository to a host over the network.</p>
<p>Firecracker is optimized for fast load/resume, and it's designed to do some
very basic sanity checks only on the vm state file. It only verifies integrity
using a 64-bit CRC value embedded in the vm state file, but this is only
a partial measure to protect against accidental corruption, as the disk
files and memory file need to be secured as well. It is important to note that
CRC computation is validated before trying to load the snapshot. Should it
encounter failure, an error will be shown to the user and the Firecracker
process will be terminated.</p>
<h3 id="performance-1"><a class="header" href="#performance-1">Performance</a></h3>
<p>The Firecracker snapshot create/resume performance depends on the memory size,
vCPU count and emulated devices count.
The Firecracker CI runs snapshot tests on:</p>
<ul>
<li>AWS <strong>m5d.metal</strong> and <strong>m6i.metal</strong> instances for Intel</li>
<li>AWS <strong>m6g.metal</strong> and <strong>c7g.metal</strong> for ARM</li>
<li>AWS <strong>m6a.metal</strong> for AMD</li>
</ul>
<p>We are running nightly performance tests for all the enumerated platforms on
all supported kernel versions.
The baselines can be found in their <a href="../../tests/integration_tests/performance/configs/">respective config file</a>.</p>
<h3 id="developer-preview-status-1"><a class="header" href="#developer-preview-status-1">Developer preview status</a></h3>
<p>The snapshot functionality is still in developer preview due to the following:</p>
<ul>
<li>Poor entropy and replayable randomness when resuming multiple microvms from
the same snapshot. We do not recommend to use snapshotting in production if
there is no mechanism to guarantee proper secrecy and uniqueness between
guests.
Please see <a href="snapshot-support.html#snapshot-security-and-uniqueness">Snapshot security and uniqueness</a>.</li>
</ul>
<h3 id="limitations"><a class="header" href="#limitations">Limitations</a></h3>
<ul>
<li>Currently on aarch64 platforms only lower 128 bits of any register are
saved due to the limitations of <code>get/set_one_reg</code> from <code>kvm-ioctls</code> crate
that Firecracker uses to interact with KVM. This creates an issue with
newer aarch64 CPUs with support for registers with width greater than
128 bits, because these registers will be truncated before being stored
in the snapshot. This can lead to uVM failure if restored from such snapshot.
Because registers wider than 128 bits are usually used in SVE instructions,
the best way to mitigate this issue is to ensure that the software run in
uVM does not use SVE instructions during snapshot creation. An alternative
way is to use <a href="../cpu_templates/cpu-templates.html">CPU templates</a> to disable
SVE related features in uVM.</li>
<li>High snapshot latency on 5.4+ host kernels due to cgroups V1. We
strongly recommend to deploy snapshots on cgroups V2 enabled hosts for the
implied kernel versions - <a href="https://github.com/firecracker-microvm/firecracker/issues/2129">related issue</a>.</li>
<li>Guest network connectivity is not guaranteed to be preserved after resume.
For recommendations related to guest network connectivity for clones please
see <a href="network-for-clones.html">Network connectivity for clones</a>.</li>
<li>Vsock device does not have full snapshotting support.
Please see <a href="snapshot-support.html#vsock-device-limitation">Vsock device limitation</a>.</li>
<li>Snapshotting on arm64 works for both GICv2 and GICv3 enabled guests.
However, restoring between different GIC version is not possible.</li>
<li>If a <a href="../cpu_templates/cpu-templates.html">CPU template</a> is not used on x86_64,
overwrites of <code>MSR_IA32_TSX_CTRL</code> MSR value will not be preserved after
restoring from a snapshot.</li>
</ul>
<h2 id="firecracker-snapshotting-characteristics"><a class="header" href="#firecracker-snapshotting-characteristics">Firecracker Snapshotting characteristics</a></h2>
<ul>
<li>Fresh Firecracker microVMs are booted using <code>anonymous</code> memory, while microVMs
resumed from snapshot load memory on-demand from the snapshot and copy-on-write
to anonymous memory.</li>
<li>Resuming from a snapshot is optimized for speed, while taking a snapshot involves
some extra CPU cycles for synchronously writing dirty memory pages to the memory
snapshot file. Taking a snapshot of a fresh microVM, on which dirty pages tracking
is not enabled, results in the full contents of guest memory being written to the
snapshot.</li>
<li>The <em>memory file</em> and <em>microVM state file</em> are generated by Firecracker on snapshot
creation. The disk contents are <em>not</em> explicitly flushed to their backing files.</li>
<li>The API calls exposing the snapshotting functionality have clear <strong>Prerequisites</strong>
that describe the requirements on when/how they should be used.</li>
<li>The Firecracker microVM's MMDS config is included in the snapshot. However, the
data store is not persisted across snapshots.</li>
<li>Configuration information for metrics and logs are not saved to the snapshot.
These need to be reconfigured on the restored microVM.</li>
</ul>
<h2 id="snapshot-versioning"><a class="header" href="#snapshot-versioning">Snapshot versioning</a></h2>
<p>The Firecracker snapshotting implementation offers support for snapshot versioning
(<code>cross-version snapshots</code>) in the following contexts:</p>
<ul>
<li>
<p>Saving snapshots at older versions</p>
<p><strong>DEPRECATED</strong>: This feature is deprecated starting with version 1.5.0. It
will be removed in a subsequent release. After dropping support, Firecracker
will be able to create snapshots only for the version supported by the
Firecracker binary that launched the microVM and not for older versions.</p>
<p>This refers to being able to create a snapshot with any version in the
<code>[N, N + o]</code> interval, while running Firecracker version <code>N+o</code>.</p>
<p>The possibility to save snapshots at older versions might not be offered by
all Firecracker releases. Depending on the features that it introduces, a new
Firecracker release <code>v</code> might drop the possibility to save snapshots at any
versions older than <code>v</code>.</p>
<p>For example Firecracker v1.0 and v1.1 adds support for some additional virtio
features (e.g. notification suppression). These features lead the guest
drivers to behave in a very specific way and as a consequence the Firecracker
devices have to respond accordingly. As a result, the snapshots that are
created while these features are in use will not be backwards compatible with
previous versions of Firecracker since the devices that come with these older
versions do not behave in a way that’s compatible with the snapshotted guest
drivers.</p>
<p>The list of versions that break snapshot backwards compatibility: <code>1.0</code>, <code>1.1</code></p>
</li>
<li>
<p>Loading snapshots from older versions (being able to load a snapshot created
by any Firecracker version in the <code>[N, N + o]</code> interval, in a Firecracker
version <code>N+o</code>).</p>
</li>
</ul>
<p>The design supports an unlimited number of versions, the value of <code>o</code> (maximum number
of older versions that we can restore from / save a snapshot to, from the current
version) will be defined later.</p>
<h2 id="snapshot-api"><a class="header" href="#snapshot-api">Snapshot API</a></h2>
<p>Firecracker exposes the following APIs for manipulating snapshots: <code>Pause</code>, <code>Resume</code>
and <code>CreateSnapshot</code> can be called only after booting the microVM, while <code>LoadSnapshot</code>
is allowed only before boot.</p>
<h3 id="pausing-the-microvm"><a class="header" href="#pausing-the-microvm">Pausing the microVM</a></h3>
<p>To create a snapshot, first you have to pause the running microVM and its vCPUs with
the following API command:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PATCH 'http://localhost/vm' \
    -H 'Accept: application/json' \
    -H 'Content-Type: application/json' \
    -d '{
            &quot;state&quot;: &quot;Paused&quot;
    }'
</code></pre>
<p><strong>Prerequisites</strong>: The microVM is booted.
Successive calls of this request keep the microVM in the <code>Paused</code>
state.
<strong>Effects</strong>:</p>
<ul>
<li><em>on success</em>: microVM is guaranteed to be <code>Paused</code>.</li>
<li><em>on failure</em>: no side-effects.</li>
</ul>
<h3 id="creating-snapshots"><a class="header" href="#creating-snapshots">Creating snapshots</a></h3>
<p>Now that the microVM is paused, you can create a snapshot, which can be either
a <code>full</code>one or a <code>diff</code> one. Full snapshots always create a complete,
resume-able snapshot of the current microVM state and memory. Diff snapshots
save the current microVM state and the memory dirtied since the last snapshot
(full or diff). Diff snapshots are not resume-able, but can be merged into a
full snapshot. In this context, we will refer to the base as the first memory
file created by a <code>/snapshot/create</code> API call and the layer as a memory file
created by a subsequent <code>/snapshot/create</code> API call. The order in which the
snapshots were created matters and they should be merged in the same order
in which they were created. To merge a <code>diff</code> snapshot memory file on
top of a base, users should copy its content over the base. This can be done
using the <code>rebase-snap</code> (deprecated) or <code>snapshot-editor</code> tools provided with the
firecracker release:</p>
<p><code>rebase-snap</code> (deprecated) example:</p>
<pre><code class="language-bash">rebase-snap --base-file path/to/base --diff-file path/to/layer
</code></pre>
<p><code>snapshot-editor</code> example:</p>
<pre><code class="language-bash">snapshot-editor edit-memory rebase \
     --memory-path path/to/base \
     --diff-path path/to/layer
</code></pre>
<p>After executing the command above, the base would be a resumable snapshot memory
file describing the state of the memory at the moment of creation of the layer.
More layers which were created later can be merged on top of this base.</p>
<p>This process needs to be repeated for each layer until the one describing the
desired memory state is merged on top of the base, which is constantly updated
with information from previously merged layers. Please note that users should
not merge state files which resulted from <code>/snapshot/create</code> API calls and
they should use the state file created in the same call as the memory file
which was merged last on top of the base.</p>
<h4 id="creating-full-snapshots"><a class="header" href="#creating-full-snapshots">Creating full snapshots</a></h4>
<p>For creating a full snapshot, you can use the following API command:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT 'http://localhost/snapshot/create' \
    -H  'Accept: application/json' \
    -H  'Content-Type: application/json' \
    -d '{
            &quot;snapshot_type&quot;: &quot;Full&quot;,
            &quot;snapshot_path&quot;: &quot;./snapshot_file&quot;,
            &quot;mem_file_path&quot;: &quot;./mem_file&quot;,
            &quot;version&quot;: &quot;1.0.0&quot;
    }'
</code></pre>
<p>Details about the required and optional fields can be found in the
<a href="../../src/api_server/swagger/firecracker.yaml">swagger definition</a>.</p>
<p><em>Note</em>: If the files indicated by <code>snapshot_path</code> and <code>mem_file_path</code> don't
exist at the specified paths, then they will be created right before generating
the snapshot. If they exist, the files will be truncated and overwritten.</p>
<p><strong>Prerequisites</strong>: The microVM is <code>Paused</code>.</p>
<p><strong>Effects</strong>:</p>
<ul>
<li>
<p><em>on success</em>:</p>
<ul>
<li>The file indicated by <code>snapshot_path</code> (e.g. <code>/path/to/snapshot_file</code>)
contains the devices' model state and emulation state. The one indicated
by <code>mem_file_path</code>(e.g. <code>/path/to/mem_file</code>) contains a full copy of the
guest memory.</li>
<li>The generated snapshot files are immediately available to be used (current process
releases ownership). At this point, the block devices backing files should be
backed up externally by the user.
Please note that block device contents are only guaranteed to be committed/flushed
to the host FS, but not necessarily to the underlying persistent storage
(could still live in host FS cache).</li>
<li>If diff snapshots were enabled, the snapshot creation resets then the
dirtied page bitmap and marks all pages clean (from a diff snapshot point
of view).</li>
<li>If a <code>version</code> is specified, the new snapshot is saved at that version,
otherwise it will be saved at the latest snapshot version of the running
Firecracker. The version is only used for the microVM state file as it
contains internal state structures for device emulation, vCPUs and others
that can change their format from a Firecracker version to another.
Versioning is not required for the block and memory files.</li>
</ul>
</li>
<li>
<p><em>on failure</em>: no side-effects.</p>
</li>
</ul>
<p><strong>Notes</strong>:</p>
<ul>
<li>The separate block device file components of the snapshot have to be handled
by the user.</li>
<li>If specified, <code>version</code> must match the firecracker version that introduced a
snapshot version, which may differ from the running Firecracker version. For
example, if you are running on <code>1.1.2</code> and want to target version <code>1.0.4</code>, you
should specify <code>1.0.0</code>. Not specifying <code>version</code> uses the latest snapshot
version available to that version.</li>
</ul>
<h4 id="creating-diff-snapshots"><a class="header" href="#creating-diff-snapshots">Creating diff snapshots</a></h4>
<p>For creating a diff snapshot, you should use the same API command, but with
<code>snapshot_type</code> field set to <code>Diff</code>.</p>
<p><em>Note</em>: If not specified, <code>snapshot_type</code> is by default <code>Full</code>.</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT 'http://localhost/snapshot/create' \
    -H  'Accept: application/json' \
    -H  'Content-Type: application/json' \
    -d '{
            &quot;snapshot_type&quot;: &quot;Diff&quot;,
            &quot;snapshot_path&quot;: &quot;./snapshot_file&quot;,
            &quot;mem_file_path&quot;: &quot;./mem_file&quot;,
            &quot;version&quot;: &quot;1.0.0&quot;
    }'
</code></pre>
<p><strong>Prerequisites</strong>: The microVM is <code>Paused</code>.</p>
<p><em>Note</em>: On a fresh microVM, <code>track_dirty_pages</code> field should be set to <code>true</code>,
when configuring the <code>/machine-config</code> resource, while on a snapshot loaded
microVM, <code>enable_diff_snapshots</code> from <code>PUT /snapshot/load</code>request body,
should be set.</p>
<p><strong>Effects</strong>:</p>
<ul>
<li><em>on success</em>:
<ul>
<li>The file indicated by <code>snapshot_path</code> contains the devices' model state and
emulation state, same as when creating a full snapshot. The one indicated by
<code>mem_file_path</code> contains this time a <strong>diff copy</strong> of the guest memory; the
diff consists of the memory pages which have been dirtied since the last
snapshot creation or since the creation of the microVM, whichever of these
events was the most recent.</li>
<li>All the other effects mentioned in the <strong>Effects</strong> paragraph from
<strong>Creating full snapshots</strong> section apply here.</li>
</ul>
</li>
<li><em>on failure</em>: no side-effects.</li>
</ul>
<p><em>Note</em>: This is an example of an API command that enables dirty page tracking:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i  \
    -X PUT 'http://localhost/machine-config' \
    -H 'Accept: application/json'            \
    -H 'Content-Type: application/json'      \
    -d '{
            &quot;vcpu_count&quot;: 2,
            &quot;mem_size_mib&quot;: 1024,
            &quot;smt&quot;: false,
            &quot;track_dirty_pages&quot;: true
    }'
</code></pre>
<p>Enabling this support enables KVM dirty page tracking, so it comes at a cost
(which consists of CPU cycles spent by KVM accounting for dirtied pages); it
should only be used when needed.</p>
<p>Creating a snapshot will <strong>not</strong> influence state, will <strong>not</strong> stop or end the microVM,
it can be used as before, so the microVM can be resumed if you still want to
use it.
At this point, in case you plan to continue using the current microVM, you
should make sure to also copy the disk backing files.</p>
<h3 id="resuming-the-microvm"><a class="header" href="#resuming-the-microvm">Resuming the microVM</a></h3>
<p>You can resume the microVM by sending the following API command:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PATCH 'http://localhost/vm' \
    -H 'Accept: application/json' \
    -H 'Content-Type: application/json' \
    -d '{
            &quot;state&quot;: &quot;Resumed&quot;
    }'
</code></pre>
<p><strong>Prerequisites</strong>: The microVM is <code>Paused</code>.
Successive calls of this request are ignored (microVM remains
in the running state).
<strong>Effects</strong>:</p>
<ul>
<li><em>on success</em>: microVM is guaranteed to be <code>Resumed</code>.</li>
<li><em>on failure</em>: no side-effects.</li>
</ul>
<h3 id="loading-snapshots"><a class="header" href="#loading-snapshots">Loading snapshots</a></h3>
<p>If you want to load a snapshot, you can do that only <strong>before</strong> the microVM is configured
(the only resources that can be configured prior are the Logger and the Metrics systems)
by sending the following API command:</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT 'http://localhost/snapshot/load' \
    -H  'Accept: application/json' \
    -H  'Content-Type: application/json' \
    -d '{
            &quot;snapshot_path&quot;: &quot;./snapshot_file&quot;,
            &quot;mem_backend&quot;: {
                &quot;backend_path&quot;: &quot;./mem_file&quot;,
                &quot;backend_type&quot;: &quot;File&quot;
            },
            &quot;enable_diff_snapshots&quot;: true,
            &quot;resume_vm&quot;: false
    }'
</code></pre>
<p>The <code>backend_type</code> field represents the memory backend type used for loading the
snapshot. Accepted values are:</p>
<ul>
<li><code>File</code> - rely on the kernel to handle page faults when loading the contents of
the guest memory file into memory.</li>
<li><code>Uffd</code> - use a dedicated user space process to handle page faults that occur
for the guest memory range. Please refer to <a href="handling-page-faults-on-snapshot-resume.html">this</a>
for more details on handling page faults in the user space.</li>
</ul>
<p>The meaning of <code>backend_path</code> depends on the <code>backend_type</code> chosen:</p>
<ul>
<li>if using <code>File</code>, then <code>backend_path</code> should contain the path to the snapshot's
memory file to be loaded.</li>
<li>when using <code>Uffd</code>, <code>backend_path</code> refers to the path of the unix domain socket
used for communication between Firecracker and the user space process that handles
page faults.</li>
</ul>
<p>When relying on the OS to handle page faults, the command below is also accepted.
Note that <code>mem_file_path</code> field is currently under the deprecation policy.
<code>mem_file_path</code> and <code>mem_backend</code> are mutually exclusive, therefore specifying them
both at the same time will return an error.</p>
<pre><code class="language-bash">curl --unix-socket /tmp/firecracker.socket -i \
    -X PUT 'http://localhost/snapshot/load' \
    -H  'Accept: application/json' \
    -H  'Content-Type: application/json' \
    -d '{
            &quot;snapshot_path&quot;: &quot;./snapshot_file&quot;,
            &quot;mem_file_path&quot;: &quot;./mem_file&quot;,
            &quot;enable_diff_snapshots&quot;: true,
            &quot;resume_vm&quot;: false
    }'
</code></pre>
<p>Details about the required and optional fields can be found in the
<a href="../../src/api_server/swagger/firecracker.yaml">swagger definition</a>.</p>
<p><strong>Prerequisites</strong>: A full memory snapshot and a microVM state file <strong>must</strong> be
provided. The disk backing files, network interfaces backing TAPs and/or vsock
backing socket that were used for the original microVM's configuration
should be set up and accessible to the new Firecracker process (in
which the microVM is resumed). These host-resources need to be
accessible at the same relative paths to the new Firecracker process
as they were to the original one.</p>
<p><strong>Effects:</strong></p>
<ul>
<li><em>on success</em>:
<ul>
<li>The complete microVM state is loaded from snapshot into the current Firecracker
process.</li>
<li>It then resets the dirtied page bitmap and marks all pages clean (from a
diff snapshot point of view).</li>
<li>The loaded microVM is now in the <code>Paused</code> state, so it needs to be resumed
for it to run.</li>
<li>The memory file (pointed by <code>backend_path</code> when using <code>File</code> backend type,
or pointed by <code>mem_file_path</code>) <strong>must</strong> be considered immutable from Firecracker
and host point of view. It backs the guest OS memory for read access through
the page cache. External modification to this file corrupts the guest memory
and leads to undefined behavior.</li>
<li>The file indicated by <code>snapshot_path</code>, that is used to load from, is
released and no longer used by this process.</li>
<li>If <code>enable_diff_snapshots</code> is set, then diff snapshots can be taken
afterwards.</li>
<li>If <code>resume_vm</code> is set, the vm is automatically resumed if load is
successful.</li>
</ul>
</li>
<li><em>on failure</em>: A specific error is reported and then the current Firecracker process
is ended (as it might be in an invalid state).</li>
</ul>
<p><em>Notes</em>:
Please, keep in mind that only by setting to true <code>enable_diff_snapshots</code>, when
loading a snapshot, or <code>track_dirty_pages</code>, when configuring the machine on a
fresh microVM, you can then create a <code>diff</code> snapshot. Also, <code>track_dirty_pages</code>
is not saved when creating a snapshot, so you need to explicitly set
<code>enable_diff_snapshots</code> when sending <code>LoadSnapshot</code>command if you want to be
able to do diff snapshots from a loaded microVM.
Another thing that you should be aware of is the following: if a fresh microVM
can create diff snapshots, then if you create a <strong>full</strong> snapshot, the memory
file contains the whole guest memory, while if you create a <strong>diff</strong> one, that
file is sparse and only contains the guest dirtied pages.
With these in mind, some possible snapshotting scenarios are the following:</p>
<ul>
<li><code>Boot from a fresh microVM</code> -&gt; <code>Pause</code> -&gt; <code>Create snapshot</code> -&gt; <code>Resume</code> -&gt;
<code>Pause</code> -&gt; <code>Create snapshot</code> -&gt; ... ;</li>
<li><code>Boot from a fresh microVM</code> -&gt; <code>Pause</code> -&gt; <code>Create snapshot</code> -&gt; <code>Resume</code> -&gt;
<code>Pause</code> -&gt; <code>Resume</code> -&gt; ... -&gt; <code>Pause</code> -&gt; <code>Create snapshot</code> -&gt; ... ;</li>
<li><code>Load snapshot</code> -&gt; <code>Resume</code> -&gt; <code>Pause</code> -&gt; <code>Create snapshot</code> -&gt; <code>Resume</code> -&gt;
<code>Pause</code> -&gt; <code>Create snapshot</code> -&gt; ... ;</li>
<li><code>Load snapshot</code> -&gt; <code>Resume</code> -&gt; <code>Pause</code> -&gt; <code>Create snapshot</code> -&gt; <code>Resume</code> -&gt;
<code>Pause</code> -&gt; <code>Resume</code> -&gt; ... -&gt; <code>Pause</code> -&gt; <code>Create snapshot</code> -&gt; ... ;
where <code>Create snapshot</code> can refer to either a full or a diff snapshot for
all the aforementioned flows.</li>
</ul>
<p>It is also worth knowing, a microVM that is restored from snapshot will be
resumed with the guest OS wall-clock continuing from the moment of the
snapshot creation. For this reason, the wall-clock should be updated to the
current time, on the guest-side. More details on how you could do this can
be found at a <a href="../../FAQ.html#my-guest-wall-clock-is-drifting-how-can-i-fix-it">related FAQ</a>.</p>
<h2 id="provisioning-host-disk-space-for-snapshots"><a class="header" href="#provisioning-host-disk-space-for-snapshots">Provisioning host disk space for snapshots</a></h2>
<p>Depending on VM memory size, snapshots can consume a lot of disk space. Firecracker
integrators <strong>must</strong> ensure that the provisioned disk space is sufficient for normal
operation of their service as well as during failure scenarios. If the service exposes
the snapshot triggers to customers, integrators <strong>must</strong> enforce proper disk
quotas to avoid any DoS threats that would cause the service to fail or
function abnormally.</p>
<h2 id="ensure-continued-network-connectivity-for-clones"><a class="header" href="#ensure-continued-network-connectivity-for-clones">Ensure continued network connectivity for clones</a></h2>
<p>For recommendations related to continued network connectivity for multiple
clones created from a single Firecracker microVM snapshot please see <a href="network-for-clones.html">this doc</a>.</p>
<h2 id="snapshot-security-and-uniqueness"><a class="header" href="#snapshot-security-and-uniqueness">Snapshot security and uniqueness</a></h2>
<p>When snapshots are used in a such a manner that a given guest's state is resumed
from more than once, guest information assumed to be unique may in fact not be;
this information can include identifiers, random numbers and random number
seeds, the guest OS entropy pool, as well as cryptographic tokens. Without a
strong mechanism that enables users to guarantee that unique things stay unique
across snapshot restores, we consider resuming execution from the same state
more than once insecure.</p>
<p>For more information please see <a href="random-for-clones.html">this doc</a></p>
<h3 id="usage-examples"><a class="header" href="#usage-examples">Usage examples</a></h3>
<h4 id="example-1-secure-usage-currently-in-dev-preview"><a class="header" href="#example-1-secure-usage-currently-in-dev-preview">Example 1: secure usage (currently in dev preview)</a></h4>
<pre><code class="language-console">Boot microVM A -&gt; ... -&gt; Create snapshot S -&gt; Terminate
                                           -&gt; Load S in microVM B -&gt; Resume -&gt; ...
</code></pre>
<p>Here, microVM A terminates after creating the snapshot without ever resuming
work, and a single microVM B resumes execution from snapshot S. In this case,
unique identifiers, random numbers, and cryptographic tokens that are meant to
be used once are indeed only used once. In this example, we consider microVM B
secure.</p>
<h4 id="example-2-potentially-insecure-usage"><a class="header" href="#example-2-potentially-insecure-usage">Example 2: potentially insecure usage</a></h4>
<pre><code class="language-console">Boot microVM A -&gt; ... -&gt; Create snapshot S -&gt; Resume -&gt; ...
                                           -&gt; Load S in microVM B -&gt; Resume -&gt; ...
</code></pre>
<p>Here, both microVM A and B do work starting from the state stored in snapshot S.
Unique identifiers, random numbers, and cryptographic tokens that are meant to
be used once may be used twice. It doesn't matter if microVM A is terminated
before microVM B resumes execution from snapshot S or not. In this example, we
consider both microVMs insecure as soon as microVM A resumes execution.</p>
<h4 id="example-3-potentially-insecure-usage"><a class="header" href="#example-3-potentially-insecure-usage">Example 3: potentially insecure usage</a></h4>
<pre><code class="language-console">Boot microVM A -&gt; ... -&gt; Create snapshot S -&gt; ...
                                           -&gt; Load S in microVM B -&gt; Resume -&gt; ...
                                           -&gt; Load S in microVM C -&gt; Resume -&gt; ...
                                           [...]
</code></pre>
<p>Here, both microVM B and C do work starting from the state stored in snapshot S.
Unique identifiers, random numbers, and cryptographic tokens that are meant to
be used once may be used twice. It doesn't matter at which points in time
microVMs B and C resume execution, or if microVM A terminates or not after the
snapshot is created. In this example, we consider microVMs B and C insecure, and
we also consider microVM A insecure if it resumes execution.</p>
<h3 id="reusing-snapshotted-states-securely"><a class="header" href="#reusing-snapshotted-states-securely">Reusing snapshotted states securely</a></h3>
<p>We are currently working to add a functionality that will notify guest operating
systems of the snapshot event in order to enable secure reuse of snapshotted
microVM states, guest operating systems, language runtimes, and cryptographic
libraries. In some cases, user applications will need to handle the snapshot
create/restore events in such a way that the uniqueness and randomness
properties are preserved and guaranteed before resuming the workload.</p>
<p>We've started a discussion on how the Linux operating system might securely
handle being snapshotted <a href="https://lkml.org/lkml/2020/10/16/629">here</a>.</p>
<h2 id="vsock-device-limitation"><a class="header" href="#vsock-device-limitation">Vsock device limitation</a></h2>
<p>Vsock must be inactive during snapshot. Vsock device can break if snapshotted
while having active connections. Firecracker snapshots do not capture any
inflight network or vsock (through the linux unix domain socket backend)
traffic that has left or not yet entered Firecracker.</p>
<p>The above, coupled with the fact that Vsock control protocol is not resilient
to vsock packet loss, leads to Vsock device breakage when doing a snapshot while
there are active Vsock connections.</p>
<p>As a solution to the above issue, active Vsock connections prior to
snapshotting the VM are forcibly closed by sending a specific event called
<code>VIRTIO_VSOCK_EVENT_TRANSPORT_RESET</code>. The event is sent on <code>SnapshotCreate</code>.
On <code>SnapshotResume</code>, when the VM becomes active again,
the vsock driver closes all existing connections.
Listen sockets still remain active. Users wanting to build vsock applications that
use the snapshot capability have to take this into consideration. More details
about this event can be found in the official Virtio document
<a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.pdf">here</a>,
section 5.10.6.6 Device Events.</p>
<p>Firecracker handles sending the <code>reset</code> event to the vsock driver,
thus the customers are no longer responsible for closing
active connections.</p>
<h2 id="snapshot-compatibility-across-kernel-versions"><a class="header" href="#snapshot-compatibility-across-kernel-versions">Snapshot compatibility across kernel versions</a></h2>
<p>We have a mechanism in place to experiment with snapshot compatibility across
supported host kernel versions by generating snapshot artifacts through
<a href="../../tools/create_snapshot_artifact">this tool</a> and checking devices' functionality
using <a href="../../tests/integration_tests/functional/test_snapshot_restore_cross_kernel.py">this test</a>.
The microVM snapshotted is built from <a href="../../tools/create_snapshot_artifact/complex_vm_config.json">this configuration file</a>.
The test restores the snapshot and ensures that all the devices set-up
in the configuration file (network devices, disk, vsock, balloon and MMDS)
are operational post-load.</p>
<p>The tables below reflect the snapshot compatibility observed on Intel and AMD.
On ARM, snapshot restore between kernel versions is not possible due to
registers incompatibility.</p>
<h3 id="intel"><a class="header" href="#intel">Intel</a></h3>
<table>
  <tr>
    <th></th>
    <th>Snapshot taken on host 4.14</th>
    <th>Snapshot taken on host 5.10</th>
  </tr>
  <tr>
    <th>Load snapshot on host 4.14</th>
    <td style="background-color:mediumseagreen">successful</td>
    <td style="background-color:darkred">unsuccessful due to unresponsive net devices</td>
  </tr>
  <tr>
    <th>Load snapshot on host 5.10</th>
    <td style="background-color:mediumseagreen">successful</td>
    <td style="background-color:mediumseagreen">successful</td>
  </tr>
</table>
<h3 id="amd"><a class="header" href="#amd">AMD</a></h3>
<table>
  <tr>
    <th></th>
    <th>Snapshot taken on host 4.14</th>
    <th>Snapshot taken on host 5.10</th>
  </tr>
  <tr>
    <th>Load snapshot on host 4.14</th>
    <td style="background-color:mediumseagreen">successful</td>
    <td style="background-color:mediumseagreen">unsuccessful due to mismatch in MSRs</td>
  </tr>
  <tr>
    <th>Load snapshot on host 5.10</th>
    <td style="background-color:mediumseagreen">successful</td>
    <td style="background-color:mediumseagreen">successful</td>
  </tr>
</table>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firecracker-snapshot-versioning"><a class="header" href="#firecracker-snapshot-versioning">Firecracker snapshot versioning</a></h1>
<p>This document describes how Firecracker persists its state across multiple
versions, diving deep into the snapshot format, encoding, compatibility and
limitations.</p>
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>The design behind the snapshot implementation enables version tolerant save
and restore across multiple Firecracker versions which we call a version space.
For example, one can pause a microVM, save it to disk with Firecracker version
<strong>0.23.0</strong> and later load it in Firecracker version <strong>0.24.0</strong>. It also works
in reverse: Firecracker version <strong>0.23.0</strong> loads what  <strong>0.24.0</strong> saves.</p>
<p>Below is an example graph showing backward and forward snapshot compatibility.
This is the general picture, but keep in mind that when adding new features
some version translations would not be possible.</p>
<p><img src="../images/version_graph.png?raw=true" alt="Version graph" title="Version graph" /></p>
<p>A non-exhaustive list of how cross-version snapshot support can be used:</p>
<p>Example scenario #1 - load snapshot from older version:</p>
<ul>
<li>Start Firecracker v0.23 → Boot microVM → <em>Workload starts</em> → Pause →
CreateSnapshot(snap) → kill microVM</li>
<li>Start Firecracker v0.24 → LoadSnapshot → Resume → <em>Workload continues</em></li>
</ul>
<p>Example scenario #2 - load snapshot in older version:</p>
<ul>
<li>Start Firecracker v0.24 → Boot microVM → <em>Workload starts</em> → Pause →
CreateSnapshot(snap, “0.23”) → kill microVM</li>
<li>Start Firecracker v0.23 → LoadSnapshot(snap) → Resume → <em>Workload continues</em></li>
</ul>
<p>Example scenario #3 - load snapshot in older version:</p>
<ul>
<li>Start Firecracker v0.24 →  LoadSnapshot(older_snap) → Resume →
<em>Workload continues</em> → Pause → CreateSnapshot(snap, “0.23”) → kill microVM</li>
<li>Start Firecracker v0.23 → LoadSnapshot(snap) → Resume → <em>Workload continues</em></li>
</ul>
<h2 id="overview-3"><a class="header" href="#overview-3">Overview</a></h2>
<p>Firecracker persists the microVM state as 2 separate objects:</p>
<ul>
<li>a <strong>guest memory</strong> file</li>
<li>a <strong>microVM state</strong> file.</li>
</ul>
<p><em>The block devices attached to the microVM are not considered part of the
state and need to be managed separately.</em></p>
<h3 id="guest-memory"><a class="header" href="#guest-memory">Guest memory</a></h3>
<p>The guest memory file contains the microVM memory saved as a dump of all pages.</p>
<h3 id="microvm-state"><a class="header" href="#microvm-state">MicroVM state</a></h3>
<p>In the VM state file, Firecracker stores the internal state of the VMM (device
emulation, KVM and vCPUs) with 2 exceptions - serial emulation and vsock backend.</p>
<p>While we continuously improve and extend Firecracker's features by adding new
capabilities, devices or enhancements, the microVM state file may change both
structurally and semantically with each new release. The state file includes
versioning information and each Firecracker release implements distinct
save/restore logic for the supported version space.</p>
<h2 id="microvm-state-file-format"><a class="header" href="#microvm-state-file-format">MicroVM state file format</a></h2>
<p>A microVM state file is further split into four different fields:</p>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Bits</th><th>Description</th></tr></thead><tbody>
<tr><td>magic_id</td><td>64</td><td>Firecracker snapshot, architecture (x86_64/aarch64) and storage version.</td></tr>
<tr><td>version</td><td>16</td><td>The snapshot version number internally mapped 1:1 to a specific Firecracker version.</td></tr>
<tr><td>state</td><td>N</td><td>Bincode blob containing the microVM state.</td></tr>
<tr><td>crc</td><td>64</td><td>Optional CRC64 sum of magic_id, version and state fields.</td></tr>
</tbody></table>
</div>
<p><strong>Note</strong>: the last 16 bits of <code>magic_id</code> encode the storage version which specifies
the encoding used for the <code>version</code> and <code>state</code> fields. The current
implementation sets this field to 1, which identifies it as a <a href="https://github.com/servo/bincode">Serde bincode</a>
compatible encoder/decoder.</p>
<h3 id="version-tolerant-serde"><a class="header" href="#version-tolerant-serde">Version tolerant ser/de</a></h3>
<p>Firecracker reads and writes the <code>state</code> blob of the snapshot by using per
version, separate serialization and deserialization logic. This logic is mostly
autogenerated by a Rust procedural macro based on <code>struct</code> and <code>enum</code>
annotations. Basically, one can say that these structures support versioning.
The versioning logic is generated by parsing a structure's history log (encoded
using Rust annotations) and emitting Rust code.</p>
<p>Versioned serialization and deserialization is divided into two translation layers:</p>
<ul>
<li>field translator,</li>
<li>semantic translator.</li>
</ul>
<p>The <em>field translator</em> implements the logic to convert between different
versions of the same Rust POD structure: it can deserialize or serialize from
source version to target.
The translation is done field by field - the common fields are copied from
source to target, and the fields that are unique to the target are
(de)serialized with their default values.</p>
<p>The <em>semantic translator</em> is only concerned with translating the semantics of
the serialized/deserialized fields.</p>
<p>The <em>field translator</em> is generated automatically through a procedural macro,
and the <em>semantic translation methods</em> have to be annotated in the structure
by the user.</p>
<p>This block diagram illustrates the concept:</p>
<p><img src="../images/versionize.png?raw=true" alt="Versionize" title="Versionize layers" /></p>
<h2 id="vm-state-encoding"><a class="header" href="#vm-state-encoding">VM state encoding</a></h2>
<p>During research and prototyping we considered multiple storage formats. The
criteria used for comparing these are: performance, size, rust support,
specification, versioning support, community and tooling. Performance, size
and Rust support are hard requirements while all others can be the subject
of trade offs.
More info about this comparison can be found <a href="https://github.com/firecracker-microvm/firecracker/blob/9d427b33d989c3225d874210f6c2849465941dc0/docs/snapshotting/design.md#snapshot-format">here</a>.</p>
<p>Key benefits of using <em>bincode</em>:</p>
<ul>
<li>Minimal snapshot size overhead</li>
<li>Minimal CPU overhead</li>
<li>Simple implementation</li>
</ul>
<p>The current implementation relies on the <a href="https://github.com/servo/bincode">Serde bincode encoder</a>.</p>
<p>Versionize is compatible to Serde with bincode backend: structures serialized
with versionize at a specific version can be deserialized with Serde. Also
structures serialized with serde can be deserialized with versionize.</p>
<h2 id="snapshot-compatibility"><a class="header" href="#snapshot-compatibility">Snapshot compatibility</a></h2>
<h3 id="host-kernel"><a class="header" href="#host-kernel">Host kernel</a></h3>
<p>The minimum kernel version required by Firecracker snapshots is 4.14. Snapshots
can be saved and restored on the same kernel version without any issues. There
might be issues when restoring snapshots created on different host kernel
version even when using the same Firecracker version.</p>
<p>SnapshotCreate and SnapshotLoad operations across different host kernels is
considered unstable in Firecracker as the saved KVM state might have different
semantics on different kernels.</p>
<h3 id="device-model"><a class="header" href="#device-model">Device model</a></h3>
<p>The current Firecracker devices are backwards compatible up to the version that
introduces them. Ideally this property would be kept over time, but there are
situations when a new version of a device exposes new features to the guest
that do not exist in an older version. In such cases restoring a snapshot at
an older version becomes impossible without breaking the guest workload.</p>
<p>The microVM state file links some resources that are external to the snapshot:</p>
<ul>
<li>tap devices by device name,</li>
<li>block devices by block file path,</li>
<li>vsock backing Unix domain socket by socket name.</li>
</ul>
<p>To successfully restore a microVM one should check that:</p>
<ul>
<li>tap devices are available, their names match their original names since these
are the values saved in the microVM state file, and they are accessible to
the Firecracker process where the microVM is being restored,</li>
<li>block devices are set up at their original relative or absolute paths with
the proper permissions, as the Firecracker process with the restored microVM
will attempt to access them exactly as they were accessed in the original
Firecracker process,</li>
<li>the vsock backing Unix domain socket is available, its name matches the
original name, and it is accessible to the new Firecracker process.</li>
</ul>
<h3 id="cpu-model"><a class="header" href="#cpu-model">CPU model</a></h3>
<p>Firecracker microVMs snapshot functionality is available for Intel/AMD/ARM64
CPU models that support the hardware virtualizations extensions, more details
are available <a href="../../README.html#supported-platforms">here</a>. Snapshots are not
compatible across CPU architectures and even across CPU models of the same
architecture. They are only compatible if the CPU features exposed to the guest
are an invariant when saving and restoring the snapshot. The trivial scenario
is creating and restoring snapshots on hosts that have the same CPU model.</p>
<p>Restoring from an Intel snapshot on AMD (or vice-versa) is not supported.</p>
<p>It is important to note that guest workloads can still execute instructions
that are being <a href="../cpu_templates/cpu-templates.html">masked</a> by CPUID and
restoring and saving of such workloads will lead to undefined result.
Firecracker retrieves the state of a discrete list of MSRs from KVM, more
specifically, the MSRs corresponding to the guest exposed features.</p>
<h2 id="implementation-1"><a class="header" href="#implementation-1">Implementation</a></h2>
<p>To enable Firecracker cross version snapshots we have designed and built two
crates:</p>
<ul>
<li><a href="https://crates.io/crates/versionize">versionize</a> - defines the <code>Versionize</code>
trait, implements serialization of primitive types and provides a helper
class to map Firecracker versions to individual structure versions.</li>
<li><a href="https://crates.io/crates/versionize_derive">versionize_derive</a> - exports
a procedural macro that consumes structures and enums and their annotations
to produce an implementation of the <code>Versionize</code> trait.</li>
</ul>
<p>The microVM state file format is implemented in the <a href="../../src/snapshot/src/lib.rs">snapshot crate</a>
in the Firecracker repository.
All Firecracker devices implement the <a href="../../src/snapshot/src/persist.rs">Persist</a>
trait which exposes an interface that enables creating from and saving to the
microVM state.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
